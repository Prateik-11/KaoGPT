All right, everyone, we're going to get started for today. So a few announcements before we begin. The first is that homework number one is uploaded to CCLE and sorry, I think it's actually in the week one materials, not week two materials, week one materials. And it's going to be due on Wednesday April 14th, uploaded to Grayscope by 1159 PM. And then we're going to continue on today talking about ion channels and membrane potential. And so these are the corresponding readings in the Principles of Neural Science book. Again, we've uploaded that to CCLE. All right, last lecture I mentioned we are going to have Shashank who introduced himself. Shashank is the other TAMS class along with Tonguey. So Shashank, can you unmute and give a brief introduction? Yeah, it's so professional. So I'm a second year master's student in the ECLE department and currently person research in privacy preserving machine learning. And we go through topics of differential privacy and cryptographic tools like homomorphic encryption, etc.

So the idea is to like ensure privacy through the neural network computation task. One of the, I mean, most of the classes that really help me to understand neural networks are neural networks 247 by Professor Kaub. Then there is a great course on adversarial robustness of machine learning models from the computer science department. And obviously to learn more about the biological systems they try and emulate neural signal processing is a really good, give you a really good understanding of how neural networks work. So yeah, that's about me. Great, thank you, Shashank. All right. With that, I want to just ask if there are any course logistic questions. All right, then we'll get back into material. So last lecture we were talking about neurons and how neurons come in all different shapes and sizes, but they have the same fundamental operating characteristics.

Not unlike how for a transistor, they all have the same components, but you can, and you can, sorry, much like for a transistor, you can have different whips and lengths, but they all have the same components and then computational complexity and capacity come from how you hook up these neurons together. And we were beginning to talk about how the neuron is a fundamentally, fundamentally electrical system. And so we talked about how if you have a neuron and here we're showing here inside the neuron and here outside the neuron and you were to stick two electrodes in one of positive electrode and the other are ground. So I put in two electrodes, then if I could measure the voltage from inside to outside the cell, which I call the membrane potential, VM, that this is a voltage that will give you a reading of about negative 65 millivolts. All right. And we talked about how this voltage is present because we have both positive ions like sodium ions and potassium ions, as well as negative ions like chloride ions that are in the extracellular and intracellular fluid.

And there's an imbalance of these ion concentrations at rest. We're going to talk about how those concentrations are set this vector, but because there's an excess of positive charge outside and an excess of negative charge inside and positive and negative charges attract, right? Then we're going to have a sheet capacitor form where these positive and negative charges are going to try to get as close to each other as possible. All right. And so this is going to cause there to be an electric field that points into the cell. And last lecture, we had done this poll question where we said, let's say that we open up a so-called ion channel and the mechanics of the ion channel will also get into more detail this lecture. But this ion channel is unique in that it lets through just one ion. It lets through Na plus ions. And Na plus ions are more concentrated outside the cell than inside the cell. So 10x more outside than inside. We asked the question, if I were to open up this ion channel, so now that Na plus ions could flow through, we asked the question, are they going to flow into the cell or are they going to flow out of the cell?

And at the end of last lecture, we did the poll and most of you got it correct that Na plus is going to flow inside the cell. And we said that there were two reasons for this. First Na plus is a positive ion and positive charges are going to be attracted to negative charges and be repelled from other positive charges. So because this electric field points in, it's going to provide an electric driving force that pushes Na plus into the cell. And this we call the drift current. So the drift current was our electric driving force. That would push Na plus into the cell. And then we said there was one other driving force, which was a chemical equilibrium driving force. So Na plus is much more concentrated outside the cell than inside the cell. And so if I were to open up a channel to get chemical equilibrium where Na plus is equally distributed everywhere, then Na plus would want to flow down as concentration gradient to go inside the cell.

And we called this current, let me draw it in the color purple. This is called the fusion current. And it's the chemical driving force. All right. Okay, I wanted to just recap this and ask if there are any questions on this. Because this will be an important principle for the rest of today's, for some topics in later slides this lecture. All right. No questions. So then we talked about how we're going to view the action potential from multiple different levels and give some concepts about the action potential that we would unpack it bit further. And the first is that if I were to have Na plus go into the cell, right, if Na plus we're going to go into the cell through these ion channels with both the electric drift current and the diffusion chemical driving force pushing Na plus into the cell, when I have positive ions going into the cell, that's going to increase the membrane potential.

All right. So if I were to open up some Na plus channels, the resting potential, which is normally negative 65 millivolts, if I open up these ion channels because sodium flows into the cell, now that voltage is going to increase slightly. And so that voltage is going to go up a bit. And we talked about how, and again, we're going to talk about this more in today's lecture, these ion channels are also special in that if the voltage increases, they open. And these are particularly these Na plus channels. And so if Na plus flows in, it increases the voltage, Vm, and that causes other channels, which are going to open based off of the voltage increasing to also open, if these channels open, more Na plus is going to flow into the cell and the voltage is going to go higher opening up more of these channels. And this initiates this positive feedback loop that causes the voltage to skyrocket because all of this Na plus is flowing into the cell. And that is the positive rise of the action potential.

That's how the voltage of the cell goes up for this action potential. Question from Ammona. Yeah. Hi. I wanted to ask, sorry, about the previous slide is one more responsible than the other in terms of drift current or diffusion current for the Na plus to be moving into the cell? Yeah, that's a great question. So in this case, because they are both flowing in the same direction, they're both responsible. It's actually possible to compute the current that is going to arise from, or is possible to compute the voltage at which the concentration, the diffusion current and the electric field driving force cancel out. And so they both contribute in this case because they're both pushing in, we know the answer. But the buyer to give you a separate question where I said, let's say I open up now in green here, a K plus ion channel. So in this case, for a K plus ion channel, that's through potassium, we can see K plus will want to be driven in by the electric field.

And they'll want to be driven out by the diffusion because K plus is much more concentrated inside and outside. And so if I just told you I opened up this channel, you couldn't say if K plus is going to go in or out because the two currents are across each other and they both contribute. And so to actually answer this question to break this, this individuation, I would have to give you more information about the strength of those currents. And so, well, I'll show some equations later on that get it when these two aren't equal every. Yeah, thank you. Great. And a question from David. Yeah, is the opening a permeability or is there actual physical opening? The opening is believed to this still in the open area of research is believed to be a changing confirmation of these ion channels, which can be triggered by different processes that we'll describe later on today.

All right. Cool. So. This is lecture two for EC 189. I was planning to continue where we left off, which is we were going to start to talk about devices that exist that interface with the brain. Or with the central nervous system in general. Before diving back in to where we were, I wanted to just ask if there were any questions from last lecture that people want to follow up on. All right. So we were last talking about the retinal implant. The idea would be that you would wear glasses. Sorry. Before that in the retinal, in retinal blindness, what happens is that normally there are cells called rods and cones that process light that naturally comes into your eye. And those rods and cones activate a circuit in the back of the eye that ultimately sends signals from so called retinal ganglion cells to the optic nerve. And then the optic nerve carries those electrical signals that were transduced from the white in the circuit and sends that off to the brain. Where then we have our perception of what we what our eye saw. And so in retinal blindness, these circuits at the back of the eye that send signal to your optic nerve no longer work. And so the idea is, although they no longer work, it actually turns out that we have really good knowledge about how this circuit.

Actually, it's weird to see. We have really good knowledge about how this circuit actually computes and how light signals are transformed into electrical signals. And so the idea is, if we could take a video camera and video the scene, we could telemetre that information to hear this chip through our communication. And then that signal that could generate the spiking signal that we would then want to send to some electrodes that stimulate the actual retinal ganglion cells that then send electrical signals to the optic nerve. So the idea should bypass this broken circuit by recording the video and then stimulating the back of the eye, how we how it might have originally intended to how light would have originally intended to simulate it. Right. And so last lecture we asked the question, what are some problems you might see or what are some not problem, but challenges that the system might face. And so some people mentioned that it could be hard to do the surgery. It might be hard to get the signals reliably to the chip. Are there any other problems that people can think of with respect to the electrodes here? I believe you also be able to unmute yourselves and just speak, but if not, someone let me know or chat. Could it just be why we have the electrodes in the right place? That's related to it, which is you have to make sure that you're stimulating the correct cell that eventually go to the optic nerve. So in this case, the answer that I was looking for is the challenge that can come up as the following. Let's say that we have our electrode array. And there are some cells hanging up here that we're trying to stimulate.

It's not that it's very hard to precisely stimulate one cell and not the other. Sorry, I'm just noticing that my keynote is lagging by quite a bit. So let's say that I want to stimulate this cell over here. If I were to send electrical stimulation on this electrode right here, you can think of this as we're hitting a very finely tuned circuit with a hammer. When I send an electrical current into this circuit, that current, Audron Red, is going to propagate out in all directions. And it's very hard to just stimulate this one neuron that we want here without stimulating all the other neurons. And so actually a challenge of this system is how do I, I know what I want this neuron activity to be like, let's say the top neuron here. How do I design stimulation patterns to stimulate just this neuron and not the others. And so an example of an active research area in here is to design stimulation patterns across your different electrodes. And that for example, maybe this third electrode sends out this electrical signal that emanates out in this foggy metric circle. Maybe the electrode next to it sends another signal electrical signal that also emanates out. As you can see here, the red and the purple electromagnetic waves are going to start to interfere with each other. And you could have constructive interference and destructive interference. And so you might think to try to pattern this stimulation on these electrodes to just target particular neurons that you care about in the vicinity. It's a difficult problem, but that's an example of how people are trying to solve this question.

So he'll. Maybe if you ask me how you want your own, could you like specifically design it in a way where say you want the red one there to simulate only the left green one and not the one on the right. Then you can have the purple one signal be in such a form that it acts as a low pass filter for the part of the red wave that you want to chop off and not the red right one to not see. You can just filter it out using a special touch to pass on the purple one so that the right one only sees the purple signal and the left one sees only the red signal. Could you is that possible to do or. It's not currently possible because it's not straightforward to implement a filter from just an electrode that can stimulate. So that's why instead of filtering the ideas here are constructive and destructive interference because really all we can control are signals that we send out. And we could we could try to position and set the parameters of the signal so that they will destructively interfere some cells, but then sending out a signal and asking it to do a filtering operation. That is non trivial. I'm not sure how that would happen. So that's a rational implant is an example of how we can write in to the central nervous system. You might also have a cochlear implant. So for someone who is deaf. They can't hear outside noises. The thing is that actually a cochlear implant is not. Also operates on on a principle that is not too difficult to understand here. I'm showing you the cochlea. The cochlear got. And what happens is that along the cochlea you have a bunch of these hair cells.

Normally when you hear sound, we talk about this in the first lecture. What happens is there's a pressure wave that's being sent to the air and that pressure wave is going to vibrate the liquid in this cochlear duct. And that vibrating liquid is going to move these hair cells left and right. And so the hair cells will be activated. And that will cause an electrical signal to be sent to your auditory cortex. So then you hear a sound of that frequency. And the really interesting thing about the cochlea is that it has so-called tonotopic mapping. Which means that if you activate hair cells here, it's the perception of a 20,000 hertz signal. And as you go down the cochlea, these hair cells activating give off the perception of a 3,000 hertz signal. Hair cells over here give off the perception of a 200 hertz signal. Hair cells over here give off the perception of a 600 hertz signal. And so as long as you can get the spectrum of the signal, as long as you know what its frequency components are, then you can replicate the sound by stimulating the hair cells in a particular area. So you can imagine if you're listening to someone speaking, you can have a device that records the audio. And then after it records the audio, it does a Fourier transform on the audio. And that Fourier transform is this operation you will all know very well through class. And it takes you from the time domain to the frequency domain where I know as a function of frequency, how much power is in a signal. And so this signal would have very high power at low frequencies, the lower power at higher frequencies. And so if I could take the Fourier transform and know what these powers are, then I could say, OK, let's say that this was centered at 300 hertz, then I could stimulate here with a large power. And that if this was, let's say 1000 hertz and I could stimulate over here with a bunch of power. And so that's how cochlear implants work. Any questions there?

All right, everyone, we're going to get started for today's lecture. A few announcements before we begin. The first is we will release homework number one by this Friday. It'll be uploaded to CCLE. And then it's going to be due the Friday after that on October 16th. All homeworks will be due uploaded to Gradescope by 1159 PM. And so please be sure to leave enough time to make sure you can upload all the documents to Gradescope and that it doesn't push you past the 1159 PM deadline. We sent out an announcement with instructions on how to sign up for Piazza and Gradescope. And so if you haven't done that already, please go ahead and follow those instructions. And then lastly, we're going to send out an announcement shortly later today on the consolidation of discussion section so thanks for submitting the Google form that we sent out and we were able I believe just got an update from Tom, we were able to find three discussion sections that everyone will be able to make who wants to attend live discussions.

All right, any questions before we begin? All right, and then before we begin, I'm also just gonna see if I can find my TA, okay, and make them co-host. There's Tom Moy. Okay, and make them cause there's more. Right. Okay, I'll maybe deal with that during the break. Alright so we'll be clear on that in the future will always announce when the next homework is going to be released and announces like we just did and when they'll be due. motivation of not having not having assessments that are worth so much so that it might encourage students to to to be academically dishonest.

And so we talked about how the grading scheme is set up and how their bonuses on pizza. Right, so now I just want to talk in more detail about exams for this class. And so this is a slide here on academic integrity. I want to put it up to communicate to you all that I take academic integrity very seriously. I believe it's important that our assessments are fair. And when we make choices on what to do for this class, we do it with fairness in mind. And so in this class, if we suspect you of academically dishonest behavior, please know that we will, that means the teaching staff, we will follow up on that and report that to the Dean of Students.

And so this is also my slide where I'd say, please don't put us in that situation where we have to do this. Please be academically honest and that matters a lot for this class. So we will have a midterm exam and a final exam. And during this time of online instruction, online instruction is very difficult for us to prevent cheating on exams. We acknowledge that, for example, due to collaboration. And so to try to make exams more equitable, all exams are going to be open note, open book, and you may access notes on CCLE via your computer. It is closed internet in that we don't want you to be googling for solutions. However, the TAs and I also aim to write exam questions that could not be easily googled. Finally, we're also going to, after the exams are collected, perform some analyses on the exam answers. And if the TAs or I suspect any students are collaborating on the exam, then we reserve the right to administer an oral exam to any students who are suspected of collaborating. And the oral exam results will supersede the written exam results. If there are any other policies that we'll have towards the exam, we'll announce that closer to the exam.

We also recognize that some of you may not be in the United States or maybe you're on the East Coast and if you're in a different time zone such that taking the exam during class time or during our final exam slot would be difficult, please email me by the end of this week so that we can have a list of the students and we can organize a separate exam time. Okay, so many are saying they aren't able to connect. That's peculiar. The lecture will be recorded. I do see a lot of people who don't have their mic or video set up. So, here's what I'm going to do. I'm going to end this meeting right now, and then I'm going to start it again within the next minute, and then we'll see if people can connect them.

So I'm going to end the meeting now.

All right, everyone. For today, we have a few announcements. First, a reminder that homework number four is due this Friday, uploaded to Gradescope. And on Monday after class, we sent out an announcement on CCLE with details about the midterm exam, which will be on Monday during class time. Alright, so please be sure to read over those midterm details, which talk about the exam timing. So the exam will happen between 2 and 3.50 PM during class time. We're going to upload the exam to CCLE at 1.55 PM so that you can download it and print it out if you desire.

You don't have to do your work on the exam. And then you need to stop working at 3.50 PM and then we give you 10 minutes to upload your exam to Gradescope. All right? So those details will all be on CCLE. The TAs and I will also be in a Zoom room, not this room, but a different link that we have put in that CCLE announcement. So please drop by that link if you have any questions about the exam and we'll be posting any updates or clarifications to Piazza.

All right, so those are the details from the midterm announcement on CCLE. HKN is going to be holding a review session for the midterm for this class. It's going to be Friday, November 6th from 4 to 6 p.m. Pacific Standard Time at this Zoom link. Now I didn't request, or I haven't coordinated this review session with HKN. These are other students who have taken ECE 102 before and wanted to do this service to help students review the material. And so again, we haven't coordinated with them. But likely, topics that they cover are going to be related to what we'll do, what we've covered in class. All right, and then Tom boy is going to hold a midterm review session.

This is of course coordinated within the class. This will be Sunday, November 8 from 12 to 2pm, and it will be at Tom boys usual office hours link and discussion section link Tom boy is going to record this review session and also post the solutions for this review session. OK, that was a lot. Any questions on announcements or questions on things related to the midterm? So I saw in the chat, Rodrigo says, ask so we don't have to log into class to take the midterm. That's correct. We're not going to proctor this exam over Zoom. Okay, any other questions?

All right, so we'll get into material then. So, oh and a reminder, the midterm covers up until the end of Fourier series. So we're going to talk about Fourier transforms today, and this material will not be on the midterm exam. So we've talked about how for Fourier series we can decompose any signal as a sum of complex exponentials and this is for periodic signals. But in reality or in real life in several applications we'll work in, the signals that we work with are not periodic. And so we need a generalization of Fourier series to signals that are not periodic and And this is called the Fourier transform.

And the intuition for the Fourier transform of. So let's say it's a rect. And we'll talk about this more in class. Let's say that the rect existed from negative t over 2 to time t over 2. All right. And so if I were to then go ahead and make a periodic extension of this signal, it would look like the following. We repeat every capital T. All right. But I could also modify this signal by making the zero time longer.

And so if I only cared about really calculating the Fourier transform of this aperiodic rect, what I could do is I could define T to go towards infinity. And so it would extend this zero time all the way to infinity and it would never repeat therefore. Right. And so the idea for calculating the Fourier transform of the signal is that we are going to take a signal and extend and make it period infinite. And so if we make it period infinite is going as a signal that is no longer periodic because it's never going to repeat since the period T, big T is infinite. All right. Any questions on the intuition here? All right. So our basic starting point is we're going to take our Fourier series equations, right?

And so f of t can be written as this infinite sum of exponentials, complex exponentials, where each is weighted by coefficient ck. And ck is the equation that we derive for computing the Fourier transform coefficients. And now this big T here is the period. And in the Fourier transform, we're going to set big T equal to infinity again, so the signal never repeats. All right. So we had started this example of the rect last lecture. What we did is we said we're going to have a rect and the rect is 1 from negative 0.5 to 0.5 and then after that it stays 0 and the amount of time that it stays 0 is, it's going to stay 0 until a time capital T over 2 on the right side and until a time negative cap T over 2 on the And so for this rec that stays zero until these two time points we have the slide that shows the Fourier series coefficients for this rect is CK equals one over big T the period, think of K over big T.

Right. And then the next slide, Cisco through the derivation of those four years series coefficients, which we've done before. then started to just try to get some intuition over what happens if big T goes to infinity. All right, so we started off by just saying, well what if big T was equal to one? So if big T equals one, then the Fourier series Ck is equal to just sinc of k. All right, and sinc of k looks like this function. All right, and so now let's calculate my Fourier series coefficients. Let's calculate Ck, so let's calculate C0, C1, C2, C3, etc. All right, so for C0, that would be k equals 0. So for k equals 0, this corresponds to the complex exponential e to the j times 0 times omega naught times t, which is just equal to 1. All right, and so at k equals 0, then c0, the first coefficient, is going to be equal to sinc of 0. And so sinc of 0 is just this value of the sinc function at t equals 0, or sorry, at omega equals 0. And so that's c0 equals 1. Right.

for C1, this would correspond to the complex exponential e to the j times 1 times omega naught times t. So it'd be the complex exponential that has a frequency of omega naught. This omega naught is equal to 2 pi because omega naught is 2 pi over the period big T and big T here is equal to 1. And so that means that the Fourier series coefficient for the frequency at omega naught, which is two pi, is going to be equal to sinc of one. And sinc of one is just equal to zero. All right, and so the Fourier series coefficient at omega two pi is just going to be equal to zero. And it's the same thing at four pi, six pi, etc. The Fourier series coefficients are all equal to 0. All right, so if big T equals 1, all the Fourier series coefficients are 0, except for the 0th Fourier series coefficient, C0, which is equal to 1. Okay, so I asked at the end of last lecture does this make sense that if my Fourier series coefficients are zero except for C zero, then that means that my signal is just equal to one, because we know that f of t is equal to some of CK each of the JK, But now everything is zero except for C zero. And so we would just have a C zero times e to the J times zero times Omega naught times T. And this would just be equal to C zero which is equal to one.

Right. And so if big T equals one. Then my signal f of t is just the one signal. And we said that this makes sense because if we look at how we define this rect, the rect is a 1 between negative 0.5 to 0.5. And then it stays zero until negative t over 2 on the left hand side and then positive t over 2 on the right side t over two is plus 0.5. And so actually when t equals one, the signal is just this blue line here that stays at one. And so if I made the periodic extension of the signal, it would just remain at one. And so that's why the fourier series coefficient indeed comes out to one and, and that makes sense. asked to go back to this slide. Yeah, so I want to pause and see if there are any questions here again. All right. So now what we're going to do is we're going to set, we did this for big T equals one.

All right, everyone, we're going to get started for today. Our announcements are that homework number two is due tonight. And yesterday, the TAs released homework number three, which is a coding homework. And as per Tanmoy's announcement, we recommend that you get an early start. It's all on Poisson processes, but it's a lot of coding. So be sure to get an early start on that because the coding can be time-consuming, especially if there's debugging. Then our midterm is going to be in class a week from today.

It'll be on Monday, May 3rd, 2021. Earlier today, I sent out an announcement with details about the midterm, including how we're going to distribute it, how we expect you to upload it by 4pm, as well as if you're in a different time zone or you received permission from me earlier, how we'll schedule your other exam time. All right. The midterm is going to cover material up to and including croissant processes and so we're going to finish croissant processes at the first part of lecture today, and that'll be the end of material for the midterm. We put all of our past exams on CCLE and so you're welcome to look at those midterms, of course, to prepare for this midterm. With the following note which is that the first midterm that we gave in 2017, which I think Tom Wael said that was, was extremely long, way too long for a midterm.

So you should not expect a midterm at the length of the 2017 exam. All right, and then again, see the CCLE announcement for any other details about the midterm. And I'm happy to take any questions about the midterm if people have them. Right, I see no hands raised. And so we'll, on Wednesday I'll be happy to again take any questions on the midterm if people have them as they come up.

Right. So with that we're going to finish Poisson processes during the first part of today's lecture and then after that we're going to start to get into decoding neural data and so we'll get into discrete classification today and motivate that and talk about the particular decoding task we're going to be doing. So these are recap slides from last lecture. We're at the end of Poisson processes and last lecture we talked about inhomogeneous Poisson processes where the key difference is now that firing rate of the Poisson process lambda r can change over time, right. And we define the Poisson process, the inhomogeneous Poisson process with the following properties that there are zero spikes at time zero, that the number of spikes that happen in a window between time S and time T plus S is given by the integral of the rate function under the curve, and that becomes the mean of my Poisson distribution.

And then that the number of spikes in any given window or the variable N of S as independent increments, which means the spikes in non-overlapping windows are independent. And so starting from this definition, recall this is different than how we did homogeneous Poisson processes. In that case, we built a Poisson process by concatenating exponential interarrival times, and we derived these three properties. For inhomogeneous Poisson process, we're saying that it's a process with these three properties. And so then last lecture we were interested in asking, are the inter-arrival times exponential? Right, so we derived the inter-arrival time of just the first spike. And we found that it was not exponential. Right, so that tells us the ISIs independent.

Right, so in a homogeneous Poisson process we assume that the next spikes should happen with a high firing rate, i.e. they should happen in less time. Whereas if I knew that the first spike happened after a long amount of time in this firing rate curve, then we would expect T2 to be during a time when there's a smaller firing rate. And so we would expect the time to the next spike to be bigger. And so, we already have this intuition that the size should be dependent. But to calculate it, we needed to to show a rigorously we need to be able to calculate this probability. And so remember our approach was to calculate the distribution of the second ISI, it's time being greater than some time, s, given that the first ISI happened at time t or happened after a length of t. And if this probability depends on little t, then this distribution of t2 being greater than some time depends on the value that t1 took on. And therefore, they can't be independent because t2 depends on the particular value of t1. Right, so if t1 and t2 are independent, then this won't depend on T, but if it depends on T, then T2 and T1 are not independent.

And so we had a lot of discussion at the end of last lecture about why this probability can be rewritten as probability number, letter C here. That is the probability that we have zero spikes between time T and time T plus S. So we're going to continue today, actually writing out this probability, right. And this will be the last thing that we do for inhomogeneous Poisson processes and then after that we'll tell you about how to code them up and then that should give you everything you need to do homework number three. So our question is, are the ISIs of a homogeneous, of an inhomogeneous Poisson process independent. And so, let me just, we have in the prior slide that we want to calculate the probability of T2 bigger than S given T1 equals T.

And that this probability was from the poll, this, the answer is C. So let me write that down. It's probability that N of T plus S minus N of T equals zero. All right, and I'm going to, we had this notation from Wednesday's lecture last week, but recall, we defined this quantity mu of T, which is the integral of my rate function lambda r from time 0 to time t. All right, and so let me just write down that again over here. We have that mu of t is the integral of my firing rate over time from time 0 to time t of lambda r, or let me do t plus s and t here, since that's what we have, this expression.

If I want to calculate this integral, right, all this integral then is would be mu of t. And we're going to need to calculate this because we have, we know how to calculate this probability from our definition of the Poisson process, because you'll recall in our definition we said that the number of spikes in a window is going to be Poisson distributed, where the mean of the Poisson variable is going to have a mean, which is the integral of the rate function between t and t plus s, that's just this quantity here, so it's going to be the mean mu of t plus s minus mu of t, raised to the number of spikes that we see in the window. And so the number of spikes that we see in the window is zero, so this gets raised to the zeroth power, times e to the minus the mean, so that would be mu of t plus s minus mu of t. And then all of this is divided by the number of spikes we see, which is zero factorial. All right, all I've done is I've written my Poisson distribution here.

And so we can see that these two terms both cancel out to be equal to one. And so therefore we get that this is equal to e to the minus mu t plus s minus mu of t. Let me put parentheses here. Alright, and so from here, you can see that clearly this probability is a function of the time t. And so since this probability is a function of t, and little t again is the value taken on by little t1, then the distribution of t2 depends on t1, and therefore t2 and t1 are not independent. And so there we have given a formal mathematical proof to show that T2 and T1 are not independent.

All right, everyone, happy to take any questions. I had a quick question about number three for the homework due tonight. Yes. Sorry. All right, question three. Yeah, for part B, I wasn't sure if my approach to this was correct, and I heard that one of my other classmates had used a different approach so I just wanted to verify my method. Sure. What I was thinking was that I would take the area from 0 to 1 millisecond and divide that by the area from 0 to 20 milliseconds. What was the reason for dividing by the area from 0 to 20 milliseconds?

Because with 50 spikes per second, I got that there would be 20 millisecond intervals. Got it. Yeah, so 20 milliseconds is the average interval. But if you just want to find the percentage of spikes that would violate a one millisecond refractory period you actually only have to compute the first probability, because you want to divide that by all potential spikes, some of which may have a inter spike interval that's greater than 20 milliseconds. And so you would only want to calculate the the first expression that you mentioned there. Let me just pull up my iPad, and a share screen here so I can just. I can just write out everything so that I make sure that we're all on the same page. Okay. All right, yeah, so for question 3b, just like you were saying, we would want to calculate the probability that our exponentially distributed variable has. We want to calculate the entry, the area under the curve from zero to 0.001 seconds which is one millisecond. And so, all you would want to calculate, we want to divide this by the probability of the ISI, of all potential ISIs, which is just, would just be the probability that t is less than infinity, but this denominator here would just be equal to one, and so we would just want to calculate And we derive that this is one minus the XP of land to T.

Okay, I see. Thank you. Great. Let's go into. Let's go for the next questions in the order of hands race so I'm not sure. Okay, I think it's, I think it is in order so Chase is next. Hi, I just wanted to like, talk about five and see if my approaches correct. Sure, yeah. Which one of number five, or which. would just be multiplying them because they're independent, and then it would be one minus the CDF of both the first neuron and the second neuron.

And then for B, it's kind of the same thing since it's memoryless, but C I think was the one that I wasn't the most sure about. And the way that I reasoned about it was that, I guess since you're seeing if one fires and two doesn't fire at a certain point, it would be the integral of the CDF of the first neuron times one minus the CDF of the second one. And then, or no no no, sorry. I think it'd be the probability that the first neuron fires at any given time, times, the CDF, or the one minus the CDF of the second one. Yeah, so, first off, for number one, your approach is correct. For number two, you said something about it being memoryless, but if you meant the, if you meant, actually, sorry, let me read question B, given that no neurons are detected in the first s seconds. Yeah, so it should just be the independent increments property. I'm not sure if that's what you use there. Yeah, yeah. Great. OK, yeah. So for part C. So part C is a bit more tricky.

And if OK, in the interest of time, I can I can state one hint and actually maybe just write out where you want to start off. So, for part, see, you were mentioning probabilities in terms of CDs, which, which is a valid approach for doing part a also in part a you could also have done it with the number of spike So, let me just say what I for part a I think you mentioned that it would be the probability that the CDF that the first. Sorry, that the first neuron. second neuron, its first ISI is greater than 60 milliseconds. And that's totally correct and you should get, you should get the correct answer that way. Another way that you could have written it is the probability that there are just that there are zero spikes on n1. At time t equals 60 milliseconds, the same time. And so, the reason that thinking about this helps is it helps to frame Part C. They want to know the probability that a neuron is detected on electrode one before electrode to. And so Let me first write it out in terms of, in terms of just thinking about in terms of number of spikes. And then, and then I think that will give a pathway for the answer and then after that I can listen again if you like chase to how you were trying to set it up and see if it's equivalent or not.

But for part C. If we want to know the probability that electrode one detects a neuron. So that would be the probability that a neuron is detected on electrode one before electrode two, right? That's saying that at some point in time, N1 of T is equal to one because we've detected a neuron on electrode one, but electrode two has not yet had a neuron. So, n two of T is equal to zero. Does that make sense. At a high level. Great. Yeah, so then the caveat here is that we want that spike to have only been for electrode one and not electrode two. So, n1 of t equals one, n2 of t equals zero, but we also want that overall there's only just been one spike.

All right, so office hours are being recorded now and we'll do the raise. I'll take questions in the order that hands are raised. Collecky. All right, I was kind of used on number 4D on the homework. Sorry, could you say 4D or 4D? 4D. Have the harmonics one? What was your confusion on the question? Just like how to go about the question. I, yeah. All right, yeah. So did other people have questions on 4B? So should we do 4B1 or 4B? Actually, that's 4B1 and then what do you? Yes. So I think the question is, inventions on harmonics? I don't know if there's some property or something like that that we're supposed to know and use. Yeah. So do the five harmonics?

Yeah. And we could have defined this more clearly on the homework. So let's do 4B here. So when we say that the Fourier series has only odd harmonics, that means that the only coefficients that are not zero are C1, C-1, C3, C-3, etc. These are not zero. But then C2, C-2, C4, C-4, etc. are zero. And so I've seen already an answer posted on Piazza that uses this property to derive a relationship for X of T. Because ultimately, we're asking you all to plot what X of T is going to look like. So we can go ahead and try to get that property and then we can see what X of T looks like. So can anyone who saw for this property tell us your approach here? Sorry, what exactly did you ask me? Oh, sorry. Let me clarify the question. So we're told in this question that the signal X of T only has odd harmonics and isn't even function. So we're just going to focus on the odd harmonics property. And I'm going to actually just write what I've seen on Piazza.

So on Piazza, people have said that this odd harmonics property means that negative X of T is equal to X of T plus T over 2. Big T over 2 or big T is the period. And so that's pretty much the critical insight that you need to be able to solve the rest of this problem. And so can anyone has anyone derived this and or have an approach, I guess, as to how to go about showing this? Oh, yeah, I did. Wait, I did derive it with T minus T over 2, which I think is the same thing. Yes, it's the same thing. Okay. Yeah, it shouldn't matter then. Oh, what I did was just. So we have the Fourier series representation of a signal is like the sum and then times the coefficient and then the complex and exponential. So I since it's odd harmonics, I replaced all the case with like inside the summation with 2k plus 1. And then I just subbed in T plus T over 2 into the thing, the fourth A series representation. Since it's like addition, you get on two complex exponential terms. So one of them has 2k plus 1 and this is multiplied by T over 2 and also omega non. So T over 2 times omega non is should be pi and then this is pi times the odd number.

So if you write that in like the trigonometric form, you'll get it to always equal negative 1. And that's how you get the negative x of t. Okay, great. So one thing along the line, you said you subbed in T plus big T over 2. And what was the rationale for that? What do you like do you mean like the motivation for plugging in? Yeah. I would I just proved this property. I didn't actually got it. Yeah, that's that's that's good. Thanks. Thanks for that Eric. Yeah, so let me tell you how. This is how I thought through this question, which is I want I know that and it's long these drawings exactly of what Eric said. And so we'll do what Eric said. So, but just a slight with minor differences. So we know that these even Fourier coefficients are equal to zero.

Right. So let's just take one of them as an example. So let's say that C2 is equal to zero. Right. And it's going to be true for every single even harmonic. Every single C sub even number. Let's go ahead and see how it can be the case that C2 can equal zero. And then we're going to see a general property for which Eric's explanation is to more general explanation. But this would be how I start off the question as a I'm not sure. Or I'm thinking I'm not sure what the property is like let's say that I didn't know this property. How would I arrive at it? Right. So C2 is equal to zero. We also know that C2 is equal to. The integral from over a period. So from zero to big T. So we have a C2 of our signal, which we call X of T. And then each of the J. And then we have a K omega not little T. And here since we have C2, then K is equal to two. So we have a J times two times omega not times little T. And then we have a C2 of T equal to zero. So if this is equal to zero, then it means that the integral over a period is going to cancel out to zero.

And so. One way in which I can try this is I can split this up into two halves. From zero to big T over two. X of T e to the J times two omega not T dT plus an integral from T over to the big T of X of T e to the J times two times omega not times T. And so here I'm just doing an example for one setting of K. And again, this is to give us the intuition as to what the answer looks like. After which then what Eric said before is the general showing this. So at this stage can someone tell me how this might how we might show that that these two some together equals or. Oh, sorry, I missed the minus sign. Thank you. I just saw that in chat. Everywhere. That minus sign is actually very important. Can you do a substitution exactly the bells exactly. Yeah, so I'm saying that if I integrate one part, the other part should be negative of that. And so if it's going to be negative of that, I just want to do a substitution to see if I can combine these two together. Right. And so.

Essentially, I want the first term and the second term to cancel out. The first term and second term look very different right now. This is zero to T over two. T over two to big T. And so let's take Kai's recommendation and do a substitution. So I'm going to define a tau. And I want this tau to move these integration down to zero to T over two. So I'm going to say that tau is equal to T minus big T over two. So if tau is equal to T minus big T over two, then I can apply this substitution to this integral over here. So let me write out the next step. This is zero to cap T over two. X of T e to the minus J to omega not T and T plus an integral. And now I'm going to do my substitution. So I'm going to be integrating over a detail. And because I'm integrating over detail, my integration bands are going to go from zero to T over two. I'll have a zero to cap T over two. And I'm going to have an X where now everywhere there's a T, I'm going to put tau plus big T over two.

All right, everyone, we're going to get started for today. First, a reminder that midterm will be during the next class time. So it's going to be a Monday, May 3rd in class. Oh, we'll go in class already. In class on Monday, May 3rd, 2021. We, again, on Monday, posted details about the exam as an announcement on CCLE. Be sure to take a look over those. And if you cannot take the exam during the in class time, because you're in a different time zone, or I previously approved it, please send me an email following the format of the announcement on CCLE. Then a reminder also that past years as midterms are all uploaded to CCLE and that the 2017 midterm was too long. So keep that in mind if you study by doing that exam. It was also a bit on the hard side too. You would expect that the exam should look more like it did in recent years. All right, any questions on the midterm? All right, so then another reminder homework number three is Tuesday, May 4th, 2021, the day after the midterm. And it has a good amount of Python coding.

So we recommend you can early start on that. And then last, we received some emails about read grade requests. And so if you have questions about or concerns, or you believe that a question that you submitted on the homework was misgraded. You should submit those read grade requests via grade scope. So just with the grade scope portal, you can submit pre grade requests. And this will wrap the request to the greater who graded your question to take another look. Any questions on any logistics? All right, so let's get back into material. So last lecture, we ended by showing this delayed reach task and a classification brain computer interface or neural communication prosthesis that we built from it. And so you recall the task was at the monkey touches and holds a center target. A target then appears in one of eight locations or seven, sorry, one of seven locations. In this case, the downward location. And then the monkey isn't instructed to reach yet. But what the monkey does during this period is he plans to make a reach towards the target. And then a go queue is delivered, which corresponds to this peripheral target becoming large.

And this center holds queue disappearing after wish the monkey then knows that it's time to reach to the target. All right, and so there are two types of activity here. There's plan period activity, which is the neural activity during the monkeys plan to reach toward the target. And then the actual movement period, which corresponds to the monkey's actual physical reach to the target. All right, and last lecture, we said that for this first discrete communication prosthesis we're going to build, we're going to decode off of the plan period activity. So why is this well, we will do movement period activity, brain, brain computer interfaces next. But you can imagine if you were looking at say a keyboard, right? And we had the characters, etc. If I wanted to type on this keyboard and I were to move my hand, I would have to reach from location to location to type out a word. But what if I just imagined that I wanted to make a reach to the w or reach to the p or reach to the t, right? I wouldn't have to actually make a physical reach. And just across the planning it, that is represented in motor cortex. And you can imagine that this type of prosthesis could be much faster because if you have a discrete number of selections that you can make for the alphabet, it would be one out of 26 potential selections. And you can just plan to the t, plan to the age, plan to the e and you can type faster. Then if you were to physically make reaches to each of these target locations.

All right. Any questions on the task setup? All right. So then last lecture then we talked about the system about how what would happen is the monkey touches and holds a target. We show a peripheral target. And if it's a BMI trial or if it's a neural prosthesis or brain computer interface trial, the monkey would plan to this target. And that would correspond to this activity over here, the monkey's plan activity towards this target. We would decode this activity and then draw a circle where we think the target was. And if the circle overlaps the square, then it's correct. And then we will show the second trial, which would be the target a new location. The monkey would plan that's the neural activity over here. And then we would make a decode. And if it's correct, we would draw the circle in over the square. And then we would present another trial. And this is a plan activity again. And then if we decode correctly, then we would draw a circle over the correct target location. And so that's where we ended last time.

And we showed some videos of this decode. I'm going to show the video just one more time for the. Medium and fast BMI trials. Purpose is just recollect this and then happy to take any questions on this. And so this is for the medium speed trials. And so you can imagine there's an optimization game that can be played here. I could try to decode even faster in which case. The amount of time that I have to look at the plan activity and then decode it to be one of the K targets become shorter. Then I have less data and I would be more inaccurate. And so there's a trade off that you can get here between accurate accuracy and speed. And last I could also show this video here where the trials were very quick. All right. All right. So any questions here? Any questions on the BMI task? Sorry. I keep on the neural communication prosthesis or brain computer interface, the CI task. And sometimes I say BMI also, which is brain machine interface. So I use those terms interchangeably here. Any questions on this task?

A question from Brandon. So just out of curiosity in that last video, we saw a lot of the open circles, meaning that those were plan movements. There were like five plan circles and then one that was actually a physical reach. Is was there a reason as to why the experiment was set up that way? Yes. So ideally we would not have any physical reaches in there. We would just start showing targets and the monkey would immediately plan to them. And then we would classify them immediately. And we can do this in a super long chain. The problem is that the monkey may become disengaged in the task. And it becomes disengaged in the accuracy decreases. And so the intermission reaches that we interleave there are to just make sure the monkey stays engaged in the task. And also knows that he has to reach himself. This engagement related thing. Any other questions here? All right. So that's a look at what we're going to be doing in the next lectures on discrete classification. The question from Andrew. Yeah. Could you go to the slide with a task timeline? Yeah.

So I'm confused how like if there's like time required for like information to propagate. How is there a baseline neuroactivity? Or is there baseline neuroactivity like before anything happens? That's correct. Yeah. So I didn't explain these. I mean explain those really quickly. Thanks for pointing those at Andrew. So the baseline neuroactivity corresponds to the activity that's just in motor cortex when you're holding the center target. But there is no target that has been shown that you should plan to reach to get. And so this is just activity when you're holding a center target and you don't know what you're going to do next. And blue here. Yeah. And then in blue here will be the activity where a target comes up on the screen. And there's going to be some way to see maybe about 100 milliseconds for your eyes to proceed this target for that information to go through the visual cortex. And then eventually make its way to the motor cortex. I was just confused because they thought like baseline activity meant like activity. That was already part of like thinking about the task. Yeah. It isn't. Yeah. It's only just the activity before any target is shown. Thanks for that clarification. Any other questions here? So does it do we use the baseline activity anyways in the record decoder? For the discrete decoders that will have you using class, you will not use the baseline activity for the decoder. Since it doesn't correspond to any particular reach direction.

All right, Sal? Hi. I just wanted to ask a quick question, and I'll stick around too. For this homework that we  homework five, I've been working at it. I was just curious, how much of the  with what we've already gone through, how much of this homework do you expect us to be able to complete with the material that we already know. Yeah, so Fourier series number one should be able, you should be able to do. Yeah, I did one. The number two is symmetry properties of the Fourier transform. So we did go over this in class briefly since they were the same as the Fourier series. So we have to go. So are we going to go over it more or is this going to be like kind of that's going to be the exposure to it and then that will be the exposure to it. So we won't cover that anymore. And so, yeah, for that one, you'll need to spend some time, likely with with the symmetry properties and just thinking about what they imply. And so, And then the figure one will take some time to.

Yeah, we will take some time but you you have all the results you need to show it. Got it. So I'm going to wrap up with questions based off of some of the derivations we've already done with the Fourier transform. In terms of, in terms of manipulating the Fourier transform, and we'll, we'll go over more on on Monday. We have our next lecture. I see. All right. Thank you. I would ask. Cool. Thanks. And just, I think everyone knows this, but this homework is not due tomorrow. It's due a week from tomorrow.

And so, I think everyone knew that, but just wanted to state that to be obvious so that no one would be panicking. And the TAs will be going over  the TAs will be going over related questions to these during their discussions this week as well  related questions to these OREA transfer questions. Yes, Al. Yeah, I guess that's kind of a part of what I was going to ask, if we can go like over an example like of something like a problem like 2A. But you're saying that the TAs might go over examples like that tomorrow? We can go ahead and go over 2A.

I remember we did this question, we've given this question in prior years also. The TAs may go through it tomorrow. I'm happy to discuss 2A right now. That'd be great. Yeah, because I'm kind of looking at it and I'm not really sure how to even approach this. I hear you. So, let me go ahead and first copy over the Fourier transform properties because I've mentioned I sometimes remember them myself or I remember them incorrectly. So, for a transform properties. There we go. And again the derivation of these.

For anyone who didn't recall when we did this slide in lecture. Copy. The derivation of these is exactly analogous to the oops The derivation of these is exactly analogous to the derivation of these properties when we did the Fourier series. Maybe, maybe I'll do the first, I guess there are eight so I'll do the first four to get us started on this and then, and then I happy to talk about the other ones but actually, I'll do the first four, maybe a few less if people have questions but I don't see too many questions right now so why don't I go ahead and do the first four. So 2A1 asks, determine which of the signals whose Fourier transforms are depicted in figure 1 satisfy the following, x of t is even. So then we will look at our Fourier transform properties, and if x of t is even, then we know that capital X of j omega is even.

So then we need to, this tells us that capital X of j omega is even. So then what we need to do is we need to look at that figure one. Look at, let me, I'm just gonna pull off this page so that I can look at it. Okay so I'm looking at figure one right now and what we want to determine is from figure one which of these Fourier transforms are even. All right so I'm gonna have you all look at figure one and then I'm gonna ask you all which of these Fourier transforms are even? Yeah, Sal.

Um, well, it looks like, um, E, but also A, but I'm not sure if A is correct. I'm saying there's two different graphs. Great, yeah, so, um, A is split up into the real part and the imaginary part of X of j omega is also even. And so if they're both even then their sum is even. Some is even. And more precisely, when we take x, when we take real part of x of j omega plus j times the imaginary part of x of j omega, both the imaginary and the real parts are even and so therefore the entire signal must the there. When we combine them into a complex number that will also be even. So a is correct. It's even and then Sal also said that E is even. That's also correct. That one you can just look. X of j omega is clearly a symmetric about the y-axis there. There's one more of these that is even. Can anyone tell me what that is?

Oh D, right? Yeah, it's d also. So in d we give you the magnitude and the phase, right? So if you were to go out ahead and write this out, magnitude and phase, right, in d we have a number where x of j omega is going to be equal to the j pi over 2. And we know that e to the j pi over 2 is just equal to j. And so this signal is just j times a rect that has a width of 2. So it's t divided by 2. Sorry professor, is that the magnitude times e to the j pi over 2, is that just a definition for that? It would be then equal to, so the magnitude of x of j omega is a rect, that should be omega over 2, rect of omega over 2, and then the phase would be e to the j, and then the phase is pi over 2 for all omega, so it's just pi over 2, and that's equal to j times rect of omega over 2, and rect we know is an even signal. I mean, you can just look at it, it's an even signal. I didn't need to say that. And so we know that j times rect is also an even signal.

Oh, I see. So you multiply then. Yeah, okay. Yeah. So for 2a1, we should get the answers a, d, and e. Let me make sure that's correct. Yep. That's correct for 2A1. Sorry, one more time. So from that multiplication, J times rect omega over 2, how do you know that that's even other than just looking at the graphs? Yeah, J times rect omega over 2 is a signal that starts at minus. Oh, okay. Sorry, I think it's omega over 4, sorry. Because the width is 4, sorry.

All right, homework to the gray. Let me pull it up. Yeah. Which notebook is it on or is it the? It's just the problem three. Oh, yeah, the problem three notebook. Okay. Problem three. The in homogenous problem prophecies. Yeah. Okay. Yeah. So my question is, so I did problem two, which is the homogenous one and I understand it. And like everything is striking out properly. When I'm trying to generate the histogram, so part B.

It says that it wants to plot the expected firing profile determined by the union equation, as well as this histogram on the same plot. Yeah. But for the histogram, since there's 50 bends of 20 milliseconds each. There's like the X that length of the axis 50. But if I'm plotting the expected firing profile over a second. And the like times and milliseconds on the axis of a thousand. I'm unsure how to. Yeah. So you will want to sample the, you'll want to sample equation one and two also every. Every 20 milliseconds. Okay. And so let me share my screen. That's good. Cool. So even though you have 50 bins and they go from zero to 1000.

You would have the access to going from zero to 1000. You would have 50 bins and then you would sample the actual function. Also every 20 milliseconds. So you would have 50 times points to plot and Python. Okay. Yeah. That definitely looks good. Follow questions to that then is when I was plotting the bins. I was like labeling the bins. So like I was labeling them like zero to 20, 21 to 40 and so on. So like I don't know how to like make the x axis like time like this, but also show 50 bins. Um, actually, when you, uh, what function are you using to plot the, uh, the bars are using the PLT dot bar function. Yeah. Yeah.

Yeah. So for the PLT dot bar, you'll have like an, uh, a vector of x look x values and y values, right? Yeah. So for the x values, you could just make that the like zero, 20, 40, 60, 80, 100, all the way up to 1000. And then that'll, that'll plot the y values at those x locations. I see. Um, along. I see. I'll try that. Do you mind if I try it right now? No problem. Yeah. Yeah. Yeah.

Yeah. So I share my screen. Yes. Well, awesome. Um, will you be showing code for the, uh, for the problem? Oh, yeah. I'm going to just pause recording then so that, uh, all right. So anyone watching this postdoc, we just returned from looking at Ian's code. And, uh, a reminder that. So if you're plotting, if you're using PLT dot bar. And the time bins are 20 milliseconds. So you're giving a time sample the x locate the x locations of PLT dot bar are like 20, 40, 60, 80. Um, there's some odd behavior in PLT dot bar. So you have to sit the width of the bar to 12 to see all the bars.

I'm just thinking sure that. So the book itself that we wrote the, uh, the width equals 12 thing, neat. Yeah. Yeah. Okay. Yeah. And so if you, if you, if you don't set the x positions to be 20, 40, 60, 80, but you said, 3, 1, 2, 3, 4, 5, then the, um, width equals 12 thing won't make sense. So make sure that you set the x positions, anyone watching to 20, 40, 60, 80, et cetera. Okay. Awesome. Thank you. I'm probably three now, but, uh, yeah, Zach, if you have any questions, go for it. All right. Sounds good.

So for, uh, so problem two, like towards the end. So for the spy times, so I know I for the last part, when we plot the CV, so the average asset in the CV of the ISS. So for understanding is for each of the eight, which part of the sec? I was at part G. Part G. Okay. Oh, okay. So for each of the, uh, reaches, so see how there is 100 trials in each of the trials, we have the spy times and the original spy times are like the capital TN where they show, like it's increasing versus if we do like a difference array, et cetera, we can find the individual spy times. So when we calculate like the average by a side of a given reach, I guess my intuition is, do we calculate first the mean of a given trial? And then from there, do it over the different trials or to be like, add everything up and then divide about a total number of, I guess, ISIS.

Yeah, I would do the latter. Yeah. But let me look at what we do in the, in the homework in, in sorry, in the solutions. Yep, that's what we do. Yeah. So the reason I said the latter is because maybe you have some trials where like, there are fewer spikes, then you would be up waiting their contribution to the average. Whereas we just want to look at all of the ISIS and then see like a cross all ISIS that happen across all trials for reach. What was the average yet? Yeah, same for the CV as well. So if we, as I'm trying to separate each of the reaches, there's a hundred trials and each trial has data. What the CVB of again, all the data if we create, put everything in a given reach angle. So there's a hundred trials times how many ISIS will we copy the CV of like the total of that? Yeah, so we should take the standard deviation and the mean across all the ISIS and then the CV will be one number for each wish condition. But it's a standard deviation of all of your concatenated all of the ISIS across all the trials divided by the mean of all the ISIS across all the trials.

Can I see? Yep. Okay, I'll set it in for part F. So the right for part G. So this is where we're plotting the ISIS distribution and I know we'll probably use like a histogram and we use the exponential. So I was able to kind of get it going. And then I guess my issue was not really so I know like the political swell that was applicable for one of the previous parts. So for fear because it's normalized, I saw like a Python on the other some post there's like a setting where you said like area equals one or something equals true. Yeah, norm equals true, I think. Yeah, so we do PLT dot hiss. And the first argument we just give the ISI the list of ISIS or the array of ISIS that you have and then common norm equals true. Okay, gotcha. And then we did give also a common dint equals 30 to have a plot to have it make a histogram with 30 bins. So I see that makes sense. So see originally I was like for each of the ISIS I was looking at like mainly created like 50 bins and then I was you know, say, okay, this less than this, creating this, I put in this pile. I was trying to like a bar PLT dot bar kind of from scratch. So for this is we want to have to really do any dividing and sorting it kind of does it for us.

All right, everyone. We're going to get started for today. So a few announcements. The first is at homework number five, which we uploaded to CCLE last week is going to be due this Friday. I'll put it to grade scope by 1159 PM. And then later this evening, we're going to release a midterm grades, the statistics as well as the solutions. Are any course logistics or admin questions? All right, so it's been over a week since our last lecture. So I want to recap a bit about what we were doing last time. We had derived the Fourier transform, which is the generalization of the Fourier series to arbitrary signals that may not be periodic. And so it's like the Fourier series and that it tells us the frequency content of a signal. All right, and so the Fourier transform capital F of J omega is this formula and computer Fourier transform of our time domain signal F of T. And there was some discussion last lecture about why we have a J here. So in other settings, you may just see the Fourier transform written as F of omega. In the end, the Fourier transform is a function of frequency.

Right, when we plot spectrum frequency is on the x axis and then on the y axis, you see how much of that frequency is used in the signal in this class. We will use the notation J omega. However, the J there is primarily symbolic. It's to tell us that this omega is a frequency. And we'll see why we use this notation more and get to a plus transform. But remember, ultimately our original signal F of T whoops. Original signal F of T is a function of time. And it tells us how our signal evolves over time. Our Fourier transform F of J omega is a function of frequency. And it tells us the frequency, how much of it tells us how much our signals composed of cosines and signs of frequencies over entire spectrum and entire span of frequencies. And we also derive last lecture, the inverse Fourier transform, which takes us from our F of J omega back to the time domain F of T. Right. And so last lecture, we did a few Fourier series of Fourier transform examples. We derived the Fourier transform, for example, of this signal each the negative ATU of T by just plugging it into this equation and doing the integral. And so this is an example how we actually compute that Fourier transform integral.

And then we said that we were going to start to compute some or to derive some properties of the Fourier transform, which are going to be critical for us using the Fourier transform. And so last time we derived that the Fourier transform is linear. And this is a really simple proof. And we also derived this time scaling property, which is that if I have a signal F of T and I either compress it by multiplying the T argument by a where a is greater than one. Or I expand it by multiplying it most playing T by an a that is lesson one. And the transform will also become scaled. And so I want to just recall the intuition of this to make sure that we have. Have intuition over the results that we're seeing. And so this is my signal F of T. Right. If I compress my signal, which means is less than one right my signal might look like this. Sorry, that is less than one means to extend the signals. Sorry, let me if we expand our signal. So the a is less than one, then our signal might look like this. And then if I compress my signal a is greater than one, then my signal might look like this.

Right. So for my compress signal with a greater than one. If we compress a signal in time, what we see is the Fourier transform the spectrum gets expanded because a is greater than one. So this omega is going to multiply is going to be divided by a greater than one. So it's going to expand the spectrum. Where is if I expand the signal in time, this blue signal, my Fourier transform is going to be compressed. Right. Can someone remind me the intuition of why this makes sense. Why is this an expected result? Can someone raise their hand and respond? Kai. Because for compressed signal, your all the frequencies are going up. So you're going to have more higher frequency content. And in the frequency domain, that's further away from the origin. Yep.

Great. Yeah, so let me just draw out what Kai was saying, which is the correct answer. If this is our spectrum, f of j omega. So the exact same as omega, let's say that the, let's say that F of T had a Fourier transform that looked like this. So this is going to be capital F of j omega. Where F of T has a Fourier transform capital F of j omega. And so what Kai was saying is when we compress the signal, right. And we cause a signal to actually have higher frequency components, meaning it changes more quickly. If we were to think of trying to reconstruct this signal with co-signs. If I want to get these wiggles and squiggles out, I would need to use co-signs that are pretty high frequency. All right. And so cosine with higher frequency is going to have a larger value on this omega axis, which is quantifying frequency. And so we would expect then. If a is greater than one for the spectrum to be expanded, because I need to use higher frequency co-signs. To make my red signal, whereas my blue signal, my extended signal.

It's. Trusted at in time. And so if I want to reconstruct this blue signal, I would use co-signs that have. A relatively low frequency, right? They have a very large period. So for the blue signal, I might expect the spectrum to look like. This because all I need is low frequencies. All right. And then the the amputees are just following this one over a scaling here. Okay. Any questions there? All right. So if you for if you don't recall this proof, we we derived this last lecture. So feel free to look at the last video to recall this. We're going to do a bunch more proof today. And so the next operate. So today we're going to go through all of these properties.

We're not going to go in depth into some of the proofs because some of the proofs look very similar to ones we've done in the past. However, we'll do a fair amount of these proofs. I copy and pasted the proofs into these lecture notes, even if we're not going to do them or we're going to go to them more quickly. But if you look at the formal notes, hand out number 10. There will be a derivation of every single one of these properties there. So we're going to start off with time reversal for today. And time reversal tells me that if I take my FFT and I time reverses. So I do F of negative T. Then what happens is that the spectrum is also reversed. Alright, this is actually really easy to prove to prove this. All we have to do is use the scaling result here setting a equals negative one. And so if we take the time scaling result, we already proved and set a equals minus one. Then we achieve this result. And so we don't even have to do a formal proof here. So let's do an example of how this time reversal property works. So we're going to ask here to find the Fourier transform of each of the negative a and then absolute value of T. So this signal is one that looks like this at time T equals zero.

It takes on the value one. And then when T is positive. Time is growing. We have a decaying exponential. And this is an even signal. We're taking the absolute value of T. So when time decreases, we also have a decaying exponential like this. And so this is our F of T equals E to the minus a absolute value of T. And last lecture, we had derived the Fourier transform of F of minus a T times U of T. F of minus a T times U of T is the signal that is zero. Until time T equals zero and then it rises up and then is E to the minus a T. So it's this signal. So if I want to find the Fourier transform of each of the minus a absolute value of T. Then what I can do is since I already know each of the minus a T times U of T, the Fourier transform of this signal which we derived last lecture, I can write my F of T as being equal to E to the minus a T U of T. And then what I could do is I could add to this signal.

Okay. All right, what is your question. So I'm a little confused about how to approach one, a, I think I watched Shoshana's office hours and he was explaining how it could be turned into like a binomial distribution. That's right. I'm, I'm not sure how to go about it. Like how to reach the, where the lambda s comes in, and why that's like separate from 1 minus p. Got it. So, in this question, let me just pull up a, let me pull up a blank window so I can Right on there.

Right, so. So, for this question, it sounds like from what you said that Shashank had discussed how probability of M equals M given N equals N is binomial, right? Mm-hmm. Great. And at this point, we know what this probability is. That's the binomial distribution. Are there any other probabilities that we know here that we could use to calculate probability I'm not seeing it. Oh, that it's Poisson? Yeah, we know the probability of the n process. So we know that probability of n equals little n is lambda. Exactly, that's right. So this is Poisson lambda. And so that's where the lambda s is going to come in, in your derivation. So now the key is, if these are the two probabilities that you know, this binomial one and this Poisson one, how do we use it to calculate probability of big M equals little m?

And so if you... So, you mean like Bayes' rule? Yeah, Bayes' rule would be the first one that I try also. So if we had that, we would need like a probability n equals n. Sorry, n equals n divided, given that n equals little m. And then the numerator would be a probability n equals little m given big N equals n, and then probability of big N equals n. And we do know these two. But we don't know- But right now, exactly, yeah, we don't know the denominator.

So actually for this one, we could actually solve it using the other thing we know, which is a law of total probability. So we know that this is equal to the sum over all possible values of little n. And this probability here is just the numerator, this expression over here. So if you plug in this expression into here, then you can start to do the simplifying algebra that should lead you to the correct answer for this. So it's going to stay in terms of n though, right? Well, this expression here is going to have an n in it, but then when you sum across all potential values of n, then it should disappear.

that look like the Poisson distribution with 1 minus p times landom times s? Yep, that's right. Okay. Yeah, so at that point it's going to be, it's going to be a bunch of algebra. I can give you a little hint which will hopefully simplify things. So, oh and sorry, this should be from n equals m to infinity because we Because we know that we know that admin is going to have fewer spikes than n. you should be able to simplify to a term where you have a sum from n equals m to infinity. And you're going to have like a p to the n minus m times a lambda s to the minus lambda st, divided by n minus m factorial. So you're going to get this expression when you do this simplification. And the key thing to realize is when you get to this expression, if I go ahead and I do a substitution, k equals, this is really bad, k equals n minus m, right? Then that changes the sum from being k equals 0 to infinity, and all these n minus m is changed to k.

Oh, okay. And then what you'll see is that all this is is a Poisson distribution, summed over all potential values of k, and so this whole sum will equal one and then the sum will go away. This is equal to one. Oh because it's exponential? Yes, plus on and you're summing over all potential values and we know that a probability distribution when you sum over all potential values has to equal one. Okay. Okay, thank you. That helps a lot. Cool. Yeah.

Okay, I'm gonna clear these drawings. Yeah, sure. Thank you. That was all I had. Okay, great.

Thank you. All right, everyone. We're going to get started for today. A few announcements. First a reminder homework number five is due this Friday, uploaded to grade scope by midnight. If you didn't hear the end of last lecture, or look at the cover page of the midterm exam, we announced that the final exam score will replace your midterm score if you score higher on the final exam. And then as per our syllabus, I wanna remind everyone, we don't have lecture a week from today on November 25th, 2020, the day before Thanksgiving.

Any questions before we start with material? All right. So, we're going to continue where we left off. Last lecture, we spent some time finishing discussing and proving much of these properties about Fourier transforms. Right. And there is just one more property will get to today which is the integral of a signal what is its Fourier transform and we'll derive that today. And we've also along the way derived a bunch of Fourier transform pairs. step, or rather, we'll discuss how it's derived. We won't test you on it because it's a generalized Fourier transform that we don't want to emphasize too much. But in general, when you take the exam or do the homeworks, we'll provide a Fourier transform table that contains properties as well as Fourier transform pairs and you're welcome to use all of these without proof. All right.

Okay, any questions from last lecture just to follow up on anything about any properties any Fourier transform where when we just apply the definition naively. It doesn't work out. Right. So, these will be the generalized Fourier transforms that we discussed today. We did talk about a few of them so a few of them, we can do some straightforward computation. If we use the Dirac delta and we apply the algebraic properties we know of the Dirac delta, we found that the derivative of the Dirac delta is 1. And we said that this makes sense intuitively because the Dirac delta is a function that is 0 and then changes infinitely fast to be of an infinite amplitude. All right. And so, to create that infinitely fast transition we're going to need sinusoids with frequencies that approach infinity.

And so that's why it makes sense that the Fourier transform of the function by tau. What that corresponds to is a complex exponential e to the minus j omega tau. And we saw using our convolution theorem, as well as our time shift theorem, that this result is consistent with previous things that we've derived. All right, then we try to take the Fourier transform of the signal of just a constant one. And we saw that if we try to evaluate the Fourier transform which is 1, then 1 is going to have a Fourier transform which is 2 pi times delta of minus omega, but then delta is even, so that delta of minus omega turns into delta omega, and that's applying the duality property that we derived last lecture. Andrew?

Yeah, I have a question. So since the integral is not Evaluable, but it does turn into that like 2 pi times Dirac Delta Does that mean like that integral like does? Equal that end result and that like if like we find this integral and like another problem We can like use that result Yeah, I have eaten negative JW omega t. Can we say that that just equals to pi direct. Yeah, we can. Yeah, so, I'm solving this integral, including duality and the fact that the Fourier transform of delta t is one allows us to, to, to give this value to the Fourier transform of one, and so the answer is yes, and then she is a bit of subtlety that I missed there please chime in and let me know. Cool, thanks. And I'm just going to take this opportunity really quickly to make my TAs co-hosts so that they can unmute themselves.

Okay, and so we found that the Fourier transform of one is two pi delta omega, which is just saying that the Fourier transform of one is a signal that only has a non zero value at omega equals zero. And so this solution here corresponds to, or makes sense intuitively. Okay, any questions here? All right. And then we also asked, well, if the Fourier transform of one is delta omega, there's a similar analog for when we have delta, what happens if our Fourier transform is delta omega minus omega not right. So the sum of some signal is delta omega minus omega not and we calculate the inverse Fourier transform, we do this approach because then this gives us a delta in the, in the integral from which we can use the properties of the delta to compute its inverse Fourier transform, we get another Fourier transform pair, which is that the Fourier transform of a complex exponential is two pi times a delta omega minus omega zero. And so this answer should also make sense intuitively because if I want to construct a complex exponential with frequency omega zero, right? All I should need in my frequency domain, in my Fourier domain are sines and cosines that have a frequency omega zero.

And so that corresponds to a delta function right at omega zero. All right, any questions there. Right, so you can see here. We're using the inverse Fourier transform equation the Fourier transform of the impulse response which is called the frequency response. we know the Fourier transform of e to the j omega naught t, which is a delta at omega naught, we can compute the Fourier transforms of a few more signals. And so I've written these out because these are relatively straightforward given everything we've shown already. We know that cosine omega naught is simply the sum of two complex exponentials at omega naught and minus omega naught weighed by one half. We know that from Euler's formula. And so if we wanted to calculate the Fourier transform of cosine, then we're in good shape because we know the Fourier transform of each of the J omega naught t.

So we apply the fourier transform to cosine one half comes out because of homogeneity. And, well, a bunch of things missing here. Okay. Then we have the fourier transform of. We have superposition, so that the fourier transform applies to each of these complex exponential. And then the twos cancel here to give pi of delta omega minus omega naught plus delta omega plus omega naught. And so just like the Fourier series of cosine, where two were values, where Fourier coefficients c1 and c-1 that happened at the frequency omega naught. The Fourier transform of cosine is going to be two delta functions that occur at the frequencies omega naught and minus omega naught. Any questions here? All right, so that's the Fourier transform of cosine. And then the Fourier transform of sign is exactly analogous. We will, it would be the exact same map is on the prior page.

All right, everyone, we're going to start lecture for today. So two announcements. First, we anticipate returning your midterm scores to you on Monday, May 10th, and we'll return those after class. And then the second is that today we uploaded homework number four to CCLE, and it's due in nine days on May 14th. The homework is it involves a lot of coding and also a bunch of math. So we really encourage you to start this early and you should be able to do most of the homework, which is today in class we're going to discuss how we use maximum likelihood to find the optimal parameters for our discrete decoding model. a likelihood under a constraint that some set of probabilities add up to one. And so the way that you do this is something called Lagrange multiplier that you might remember from a calculus class here, where instead of maximizing log l by itself when you have a constraint like this, what you can do is you could put that constraint into the objective function as well, and that constraint multiplies a lambda.

And for this homework question, if you differentiate then this expression with respect to the parameters and lambda, then you're going to be able to solve this optimization problem. Right, so I think it'll become clear when you look at the homework, but I just wanted to put that up front, so that you don't get stuck on that. All right. Any questions on any course logistics? All right. So it's been a week since our last lecture, so I want to remind you where we were. We were considering this case where we record from neural data. In this case, we record from two neurons, neuron 1 on the x-axis, neuron 2 on the y-axis. And we record from these neurons as we ask the monkey to plan movements to different targets. And so here we've shown three different targets, right as red X's, left as blue circles, upward reaches as green triangles.

Right. And for each of these different reaches, the neural data, the neurons are going to fire in different ways. And so what we do is we perform a training set where we know the answers. We ask the monkey to make a plan to a reach. We record neural data. And we know the answer of what target they were planning to reach to. We know if it's a red X, a blue circle, or a green triangle. And then the goal of the training phase in machine learning is that then we want to take this data and learn a decision rule for how to classify new unseen data where we don't know the answer.

And so in training, that would be akin to learning these boundaries that we draw here in pink. And then when we go to the test phase where we want to now put our algorithm online and make new predictions without knowing the answer, what we do is we remember those boundaries. And now, depending on where the data, the new data point here as an orange square pops up, it pops up in this vicinity, then we can guess that the monkey planned an upward reach and if in this vicinity, the monkey planned a rightward reach, etc. Any questions here? All right, so then last lecture we talked about how do we set up this model such that we learn these decision boundaries in the training set. And so we said we were going to work with so-called probabilistic generative models. And we said that what we would want to do is we want to learn a distribution P of X given CK, right? Now, CK is one of the potential classes that the data could come from.

And so in this example here, there's C1, C2, and C3, three possible reaches. P of X given Ck, then, is what the neural data looks like when you have data coming from that class. And so P of X given C1 is going to be the distribution of these red Xs because it's a distribution of data X, given that the monkey planned a reach to the rightward target c1. And we'll make one of these distributions p of x given c2 for these blue circles and a p of x given c3 for these green triangles. And so that is what we need to learn in the training phase. And then in the testing phase what we will then be able to calculate is given Given some new neural data that I don't know the answer to, so given some XJ, what target CK did the monkey plan to?

Okay, so we could calculate the probability of a plan to the right, the probability of a plan to the left, and the probability of a plan upwards and get numbers. And we could choose that the monkey reached to the, the monkey plan to reach the target with the highest probability. Right, and then last lecture, we had done the math to show how we can calculate P of CK given XJ from knowing this training distribution. Any questions there.

I'll recap for now. Alright, so then, if we need to learn P of X given CK, then we need to choose what a distribution for P of X given CK is. And so then towards the latter part of last lecture, we decided that we were going to model P of X given CK with a multivariate normal distribution or a multivariate Gaussian distribution. In a multivariate Gaussian distribution, there are two parameters that set, that specify everything about the distribution.

Once I know the mu, which is the mean of the distribution, and the sigma, which is the covariance of the distribution, then I can write down the distribution exactly. And I can calculate the probability density function for any point x. All right. And then we went into some detail about what this covariance matrix means, this diagonal terms and this off-diagonal terms. And that was last picture. Any questions here? All right. So if I model p of x given ck via this multivariate normal distribution, then what the problem is going to boil down to is this multivariate normal distribution is totally specified by two numbers or two, one vector and one matrix, mu the mean and sigma the covariance matrix. And so for every single distribution in the training phase where I learn it, I'm going to want to set the value of mu and its covariance matrix, which remember we conceptualize as these ellipsoids.

I wanna set the values of these so that they well describe the data. So for these plan ups, I want the mean to be in the vicinity of the points, essentially it's centroid. And here the covariance ellipsoid should be skewed so that it has a positive covariance between x1 and x2, because we see this general trend that when x1 is higher, x2 is higher. But then maybe P of x given c1, its centroid is here in the midst of the red x's, and its covariance ellipsoids are like circles, because there doesn't seem to be too much correlation between x1 and x2.

So now the whole game of training is, how do I choose mu and sigma, so that they really well describe the distribution of the data for each of these planned reaches. Okay. Any questions there. last lecture, which was introducing the maximum likelihood framework. So I mentioned that before we derive the maximum likelihood solution for this classification model that we're working with. So you may be confused about exactly what are the parameters, what are the goals of this modeling, etc. We have a question from the swan. Yeah, I just want to make sure. So, you're drawing a leaf solid on the 2d plane that doesn't mean that data point will be like a leaf site. Right. So just a conceptualize of the correlation matrix.

That's correct. Yeah. Think of the ellipsoid that's. Remember when we drew like, let's say that, let's say we had a 1d normal distribution where data points were well congregated here and then like maybe they're more sparse out here. If we want to model this with a normal distribution we might say that the one standard deviation point is between these two values because 67% of my data points fall in this range. But data points can exist outside of the standard deviation lines. They're just less probable. But the ellipsoids themselves don't contain the point. They just describe where most of the data points should be. So even if my data looks like maybe in each axis is a uniform distribution, then I can still have that ellipsoid.

All right, everyone will go ahead and start office hours. Let's use the raise hand system to take questions in order. Tyler. Professor, I, well, I guess, let's, I want to start off with the very start problem, one, a on the homework. Can you go over the math behind showing how the properties change. Okay. So question one a says, when f of t is periodic f of t is real. We have seen some properties of symmetry for the four a series coefficients. How do these properties change when f of t is purely imaginary. All right. Can someone who maybe to this question. Let us know your approach here.

I started off so far. So, I said if so in the slide, it was assuming FT was real. So, I said, FT is imaginary, then it's kind of like you just multiply in a J. So, the. Yep. Yeah. Yeah, that's right. Yeah. And then what Tyler said is integrate over a period. And then Tyler multiplied some real signal. Since f of t is purely imaginary, let's just call the other signal g of t. So here f of t would equal j times g of t, where g of t is real. And then we would have our And that's J sine two pi k over big T zero T, just like in the lecture notes. TT. So, now, we want to get the, just like an electric us we want to get the real part of Tk is going to be a 1 over T0 integral over a period. Whereas J times G of T times minus J sine is going to be purely real because the J's here are going to cancel.

And so we're going to get the real component will be the portion that multiplies the sine. And then the imaginary portion is going to be the remainder, the part that multiplies G of T cosine 2 pi K over big T star T DT. All right. I was going to show you the first two properties but when it started doing the conjure parts. I was a little confused how the math was working out, so I just want to see those worked out. Oh great. Yeah, okay so the last three properties on slide 41. Perfect. Okay, thanks. Well, since essentially the even oddness switches for the real and imaginary parts, so I think the first part should be like the real component is equal to the negative, the real component of C of negative K. Yep. And then, and then for the imaginary part, same deal but remove the minus sign from the front.

Great. All right, so now we want to calculate, let's say, let's call it CK star. So CK star is going to be the complex conjugate of CK. that Ck was equal to its real part plus j times its imaginary part. Then we know that Ck star is going to be the real part of Ck minus j times the imaginary part of C k. And so relationship. Does anyone who did this question want to tell us what the next steps that you did are? And feel free to unmute yourself, you don't have to raise your hand. I rewrote the real part of C sub k as the negative of the negative of the real part of C sub K, and then that allows us to do some substitution based on what we saw earlier. Yes, so we can write this as the negative of the negative part of real of C minus K. Did I get that right Bradley.

Bradley? Yeah, that's what I did. Perfect, yeah. And then we have, so if we have a minus sign here, then we're going, well let's try to then get the imaginary part into a C minus K term. So can someone tell us what to do for the of CK. Wait, I have a thought about what you just wrote down. If you, if in the green you equated the real part of CK to the negative of the real part of C negative K, is that equality correct? Should there be two negatives if it's more equating to the real part of C of K? Oh, you're right, yeah, it should just be minus real part of c minus k. Yep. That's my bad.

All right, and then here we have minus J, and we have that the imaginary part of CK is the imaginary part of C minus K. Right. All right. And then I think, sorry, and this is where I had a misinterpreted Bradley's comment. This can be written as minus, and then we have a real part of C minus K plus a J times the imaginary part of C minus K. And all this is is C minus K. And so this would equal minus C minus K. All right, okay. Any questions there?

All right, so that's the next relationship that we have, which is C star k is equal to minus C of minus k. And then we have two other relationships for the amplitude and the phase. So can someone tell us how you approach these questions? For the amplitude, it should stay the same because the negative gets squared again. Perfect. Yeah. So, Melissa says that Ck, its magnitude, equals C minus k, its magnitude. When we calculate the magnitude, it's the square root of the real part squared plus the imaginary part squared so the negative sign will go away just like Melissa said. Okay.

So we have one last property then the phase. So, does anyone want to tell us how you did the phase. Can I ask a clarifying question on the phase property? Yep. On the handout, the property is written differently than what we had said in class. So I'm wondering which one we should use. Oh, the one in class. If there was a mistake on the handout, then I probably typed it wrong on the handout. So the one in classes the correct one and I apologize for the difference. Let me bring that up really quickly. Properties. Here we go. use, was it this minus sign over here, Melissa? I guess there may have been.

All right, everyone, we're going to get started for today. So just a few announcements before we begin. The first is a reminder that homework number four is do this Friday. And we're also going to be uploading homework number five. At the end of this lecture, we'll take some time to discuss the midterm. And I just want to put this in announcements so you all know we open up re-graves for the midterm exam for one week after we return the grades. And so if you want to get a re-grave on any midterm question, those are due by May 17th. 21. All right. Any questions or any questions on any any course logistics? All right. So we are going to continue with the screen classification. We're going to finish that in the first half of lecture today. So a reminder where we are. We had this model where we have neural data that's given by the X and the Y axis that comes from different classes.

In this case, we have two classes when the monkey plan to reach to a right retarded and when the monkey plan to reach to a left retarded. And those are red circles and blue, sorry, red X's and blue circles. And last lecture, we talked about how we were going to model this by having the distribution of the data coming from each class, being this multivariate Gaussian distribution with a mean and a covariance matrix. And then we said now from training data, which are examples of the monkey planning reaches to targets where the neural data during the reaches X i and the target identity is ti. We're going to try to learn the parameters of pi pi is the proportion of plan left targets. The means of these distributions and the covariance, right. And these are the parameters of my model and I get to choose them to make the data as likely as possible. Right. So last lecture, we derived the data log likelihood. That's this expression here. And we had this log of a normal distribution that was this expression over here. And we said we were going to now differentiate the log likelihood with respect to pi mu zero mu one and sigma to find the optimal parameters. And last lecture, we had done the log likelihood, the pie and got that pie, which is the number is the proportion of the probability of there being a left trial was just the proportion of left trials capital and one over the total trials capital and. Right. And the tackle and zero is the number of trials that were planted, but right target. And then we then differentiated log likelihood with respect to new one. And we found that new one was equal to one over the number of trials where the monkey planned left times the sum of all the neural activity when the monkey planted a left. And so this ends up being the sample mean of the neural data when the monkey plans to the left. And so that's the centroid of this cluster over here. All right. And we said that that made intuitive sense and there was a maligous answer for mu zero.

Right. I want to pause here and ask if there are any questions recapping this. All right. So then when we left off, we were now going to do maybe the most involved part, which is to differentiate with respect to the covariance matrix sigma. Right. And we mentioned as so these are just copy and pasted the log likelihood from prior slides. And then we mentioned that we are going to use these properties about the derivative of scalars with respect to matrices, as well as the cyclic property of the traces. And we can use these without proof. So we'll just assume that they're known for this class. Right. So we did any questions before we head on to do this. Question from Amina. I wanted to ask about the trace. Like I understand what it actually is, which is just the sum of the diagonal, but I can't. I don't really see why it's fundamentally important to know that. When you say fundamentally important to know the trace, do you mean like why do we need to use it as an operator in our derivation? Yeah. Yeah. So the nice thing about the trace is that it makes this product of matrices into a scalar. And in this class, we're never going to differentiate more than a scalar with respect to a matrix. It is true that you could, for example, differentiate a vector with respect to a matrix. And that becomes a 3d tensor or the derivative of a matrix with respect to a matrix that becomes a 4d tensor. You could try to apply those rules to solve these derivatives. But for us to make our life simple, we end up using this trace property. And we find that this will allow us to just work with matrices and vectors and simplify the algebra involved. Any other questions here? All right. So we're going to take the derivative of the log by the hood with respect to sigma. And so this first term, TI log pi has no sigma in it. So we can ignore it. And then we were differentiating then this term, TI log of the multivariate normal distribution. And so my derivative operators linear so it can go inside the sum. So we'll have a sum. And then I bring out the TI because it doesn't depend on sigma, my covariance matrix, big sigma.

And so now I'm going to differentiate this term with respect to sigma. So for this term, which we'll draw here and move. I'm going to have first this log normal term. And that log normal term has a bunch of expressions. This middle expression here, the D over 2 log of 2 times pi. This doesn't have any sigma. So I can ignore it. So I'm going to do this one first. Right. So here I'm going to get this term minus 1 half. And then we have here an X i minus new transpose sigma inverse X i minus new. We know that this is a scalar. Right. Because this is a row vector times a matrix times a column vector. And since it's a scalar and we know that the trace of a scalar is a scalar, I'm going to go ahead and just write trace of this expression. So instead of just running the expression, I'm going to put a trace around it. So I'm going to write trace of X i minus new transpose sigma inverse X i minus new. And then I'm also going to have a term here minus 1 half log a determinant of sigma. So I'll copy that of minus 1 half log determinant sigma. And I'm going to differentiate both of these terms. And then I'm going to have a plus. So this red term doesn't have a sigma. So differentiating with respect to sigma gives 0 and then I'll have a 1 minus ti. And then pretty much the same thing. I'm going to have a minus 1 half trace of every got to put my you want to see. 1 half trace of X i minus new zero sigma inverse X i minus new zero minus 1 half log determinant of sigma. All right. Any questions here. Okay, so if I look at these expressions for the 1 half log determinant of sigma. I'm sitting in pretty good shape because I know how to differentiate these. I have my look up table and here. The derivative of log determinant sigma with respect to sigma will just be sigma inverse. So these terms I can differentiate. But these terms. The traces of these vector times matrix times vector is not exactly in this form trace of sigma inverse times a. All right. So how can I transform these expressions to be in this form so I can apply this derivative rule here. You can write it in the chatter or razor hand. So charan says we can use this cycling property of the trace. And so when I want to use this derivative rule, I want the sigma minus 1 to be in front.

All right, everyone. We're going to have homework number six not do this Friday but do Monday of next week. All right. And then this homework will cover material up to and including this lecture. And so we had a typo on the homework that said it covers material up to lecture 14 should just be up to include, including today's lecture. Alright, any questions. Before we begin. All right, so we're going to continue with frequency response today. You'll recall that after Fourier transform and knowing the convol- Melissa. Are you going to be holding office hours, adjusted office hours this week? Yes, I, so I won't be holding office hours on Thanksgiving. I did see a Piazza post requesting me to change my office hours. I'm looking into that right now because I, I'm not sure I'm going to have availability prior to the day the homework is due. But if I if I'm able to find a spot potentially on the weekend, then I will do it.

And Daniel. Yeah, I was wondering about Friday, if that is going to be regularly scheduled office hours with the TAs. I believe that will not be I believe Friday is also off so UCLA has both Thursday and Friday off. or planning on holding anything there. If there's a difference, if there's a change in what I just said, I will announce it. Okay. Thanks Daniel. Those are good questions. Any other questions?

Okay, let me make Tom White co-host really quickly. And, circle on. I wanted to add that we will be posting the discussion problems for this week along with the recorded videos on the solution so that it helps the student with solving homework six. Great, thanks, Tomwe. So if I'm clear, based off of, in response to Daniel's question, there will be a discussion video this week, as well as posted discussion questions and solutions for students.

All right. Okay, and Sal. Thank you. I have a question following up on that. So would it also be released on Friday or there should be expected to be released on Friday the discussion questions in the recording? Good question. At T.A. do you have an answer for Sal? So we will try to release it by this Wednesday night so that students have a lot of time over the weekend to look at it.

Thank you. Thank you all. Okay. Any other questions on logistics for the class. All right. So, getting back into material. Last lecture we were talking about frequency response, which was to say, prior we've talked about how LTI systems can be written as convolution between input and impulse response. And this is due to the Fourier transform of the impulse response capital H which is called the frequency response times the Fourier transform of the input x. And therefore we were able to see that the magnitude of the frequency response and the phase will be shifted, the phase of the output will be shifted by the phase of the frequency response. So last time we did one example, we'll do another example to start off this lecture on frequency response. And so last lecture we considered a system that gets an input to cosine t plus three cosine three t plus two plus cosine of two t, and the system has an impulse response, which is given by the sinc squared.

And so, last lecture, we talked about how, if I asked you to compute the integral we would have sine squares times cosines that we would have to integrate. However, if we do this in the frequency domain by taking Fourier transform we find that this output to find the output is almost is very straightforward. And so all I have to do is take the Fourier transform of capital H, which we did over here, and then multiply them together to do this multiplication, we drew this diagram last time to show that this is X of j omega. This here is H of j omega, and then their product is here, why have jam. Why have j omega and take the inverse Fourier transform by recalling that So the inverse Fourier transform is just cosine of one times t. And then similarly for this term over here. All right, so with that we were able to compute what y of t was. Any questions from that example that we did last lecture? All right, so we're going to do one more example, and then after that we're going to get back into our discussion of filters which we started last lecture. And so in this example we have an input to the system which is e to the minus t for t bigger than or equal to zero, so multiplied by the step function. We're going to put this into a system with this impulse response. And so we want to know what the output is as well as this Fourier transform. And again we're going to use the fact that convolution in the time domain is multiplication in the frequency domain. So from our lookup table, we know this pair that e to the minus a t times u of t has Fourier transform one over a plus j omega.

And then h of j omega is going to be a constant 2 because of linearity of the Fourier transform, and then e to the minus 2t is going to give us a Fourier transform of 1 over 2 plus j omega. And so from these we can calculate y of j omega, the Fourier transform of the output, by simply multiplying these two together and we get that the output Fourier transform is 2 over 1 plus j omega times 2 plus j omega. And that is the output Fourier transform. So computing capital Y j omega was very straightforward. Any questions here? All right, so then to calculate the y, little y of t, the inverse Fourier transform of this expression, we typically don't want to do that inverse Fourier transform integral, that's tedious, and so we would use a lookup table.

However, in our lookup table, we don't have something where the denominator is a product of these a plus j omega terms. So I'm going to tell you how to do this inverse Fourier transform by a technique called partial fractions. We're not gonna go into it in much detail here because this is gonna be a critical topic for Laplace transforms. And in Laplace transforms, we're gonna give you three or four methods to do partial fractions.

And so this one we're just gonna do, this one we're going to do and the details will be clear, but we're going to give a much more extensive discussion of partial fractions later on. And so, in partial fractions what we do is we have a yj omega here, for example, which is two over one plus j omega. Two plus j omega. So we know a Fourier transform pair which is e to the minus at u of t has a Fourier transform 1 over a plus j omega. And so what I'm going to do is I'm going to assume that this expression can be written as the sum of two fractions where the denominator of one fraction is 1 plus j omega and the denominator of the other fraction is 2 plus j omega. So I'm going to assume that this can be written as the sum of two fractions where one fraction has a denominator 1 plus j omega and the other has a denominator 2 plus j omega. If I gave you a fraction like this, right, you would know to simplify it, and I asked you to simplify it into one fraction, what you would do is you would multiply this left-hand sign by 2 plus j omega over 2 plus j omega in the numerator and denominator, and then for the right-hand side, 1 plus j omega in the numerator and denominator. And Tomoy tells me that you all did partial fractions in discussion last week, so that's also great. And so for this partial fraction we're just going to do it a very straightforward way, which is, and again in Laplace transform we're going to give you several methods to do partial fractions, but what we're going to do is I'm going to assume this to be true, that I can write this as a sum of two fractions, and then what I need to do is find out what a and b are such that these two expressions are equal to each other. So what I'm going to do is I'm going to multiply, if this is the left-hand side of the equation and this is the right-hand side of the equation.

We're going to start lecture now. So a few answers before we begin. The first to reminder that homework number four is do this Friday and then we will also release homework number five then. And homework number five is going to be a pen and paper homework on graphical models. The other announcement is a reminder that midterm read grades are going to close on Monday, May 17th and so be sure to get your read grades in by then. Are there any questions regarding the course? All right, so we'll get back to material. So we're going to finish up graphical models today and then after that we're going to get into continuous decoding for brain machine interfaces. So recap from last lecture is we introduce this notion of graphical models where we have nodes that represent random variables and links that connect random variables. And when we have a graphical model, what this does is it gives us a factorization of the probability density of all of the random variables.

And that factorization is that we're going to iterate over all the random variables and it's going to be a product of their probabilities given their parents. And so we had done a few examples where we drew a graph and we were able to write out the factorized distribution. And then we wanted to look at these graphs and gain some intuition over them as well as answer a few questions. The first question is are certain nodes in the graph independent and the other was are they conditionally independent? So we're in the middle of going through these three examples of the potential ways that you could hook up three nodes with links. All right, and we're asking for each of these examples what the factorized distribution of what the factorized distribution of A, B and C was. If A and B are independent and then if A and B are conditionally independent, it's given C. Any questions plus bar? All right, so we did example one and today we're going to continue off on example two.

All right. So for example two, this is our graph and we have A being the parent of C, which is the parent of B. And so the factorized distribution was P of A because it has no parents, so there's no condition. There's no condition on any variables. Times P of C given A times P of B given C. And then last factor we had run the poll to ask the intuitive answers for these questions which will not show rigorously. But we asked two questions. First is A intuitively independent of B, which means if they're independent knowing A does not give you any more information about B than you already knew. And so when no variables are observed, in particular C is not observed, A and B are not independent. And that's because if I know A, I know something about C. And if I know something about C, then I know something about B.

All right, so through this node C, A gives me information about B. And then the second question we asked is is A independent of B given C. And the intuition here is that the answer should be yes. And the intuition is this, when I know C, I observe its value for A. And so then A being independent of B given C tells me in intuition terms that is asking the question, does A give me any more information about B than I already knew from knowing C. The way that A and B were dependent is that A gave me information about C that then gave me information about B. But now if I know C, A doesn't give me any more information about C. I know C perfectly. And so I don't gain any information about B from knowing A because the information I have about B, I already know from observing C. All right, so those are the two intuitive answers. I know we covered this intuition a bit quickly at the end of last lecture. So I want to ask if there are any questions here. All right, so then we're going to go ahead and do the more rigorous derivation.

So I'm going to move this to the next slide so that we can just say this slide for number two. So is A independent of B intuitively now? All right, and so if we want to show that P, that A and B are independent, then we need to see if P of A comma B does this equal P of A times P of B. Remember that since these are not independent, you can also just come up with a counter example and show in that counter example that A, that A and B are dependent. So let's go ahead and just try to answer with a general proof. So we have P of A comma B and we want to see if it's equal to P of A times P of B. So maybe think about it for 20 to 30 seconds as to what the first step here would be. Can someone write me in the chat or I'll space your hand for what the first step you might do here is? Total probability, that's correct. So we're going to remember we want to show if this is true for this particular graph, right?

And the information we have about this graph is that P of A, B, C has this decomposition. So we want to introduce P, A, B, C somewhere. So we're going to write this as sum over C of P of A comma B comma C. And then we'll use the factorization of the graph. So this is sum over C and then we'll have a P of A times P of C given A times P of B given C. Right? At this point, we can see P of A has no dependence on C. And so this is equal to the P of A times the sum over C of P of C given A times P of B given C. And just like last lecture or just like the last example, when we get to this answer here, these will be independent. And if this expression here equals P of B, right? But in general, this is not equal P of B. So in general, this does not equal P of B.

Right? So therefore, A and B are not independent. Just like the last example, one of the conditions where we explored this a bit more, one of the conditions for this equal P of B is that P of C given A is equal to P of C. Right? In which case, this would equal P of B comma C and then we sum over C given P of B. But in general, that is not true. And C is going to depend on the value of P of C. Any questions here? All right. So then let's do the conditional independence one. So I'm going to copy this graph over also. I just saw in chat. Can I explain why this is not equal to P of B? Yeah.

So we'll just do one condition. So one condition for this equal P of B would be that we know that P of B can be written as the sum over C of P of B comma C. Right? And this equals the sum over C of P of C times P of B given C. And so if this summation looked like this, then the sum would equal P of B. Now this summation has a P of C given A. And to say that P of C given A equals P of C means to say that A and C are independent. All right? But A is a parent of C. And so here A and C are not independent. And so in general, P of C given A does not simplify the P of C. And in general, therefore, this is not equal to P of B. All right. So we're going to do the conditional independence now.

All right, everyone, we're going to get started for today. I hope everyone had a happy Thanksgiving and a good break. So announcements for today are first that homework number six, we sent an announcement on Piazza and CCLE last week that we have delayed the homework to be due this Friday, uploaded to gradescope by 1159pm. All right, and then start the Laplace transform. And then the rest of the class will be about the Laplace transform how to invert the Laplace transform and therefore has a high overlap in properties with the Fourier transform. So since we have gone extensively to the Fourier transform, hopefully going through the Laplace transform would be quicker.

All right. Any questions on course logistics or any administrative related things? All right, so we'll go ahead and get started. So, I just wanted to remind you. Last one last Monday actually before a week ago before Thanksgiving. We had started this lecture on frequency response, where we had talked about low pass high pass and band pass filters which extract out frequencies in particular ranges, and we went on to derive their impulse responses, and some characteristics about them. We talked about this am radio example, and how filters could play a role in helping us to recover the signal signal after demodulation. some practical limitations of these filters. And one thing we mentioned was that if we were to take an ideal low-pass filter whose impulse response is a sinc, well, the sinc is not causal because we know that a causal impulse response must be zero any time when t is less than zero. And so we said, okay, well, to make it causal, we can do something. We can shift the signal in time, so that now the signal is zero prior to zero but then after zero we have a shifted impulse response.

And so the input filtered by this convolved with this delayed impulse responsible will also just be shifted. And so if I shifted the impulse response by three, my output will also be shifted by three. Right. And we said that this is called a distortion list LTI system. And so, a distortion list LTI system is one where the output is going to be the same thing as the input, except it might be scaled by some amplitude K, and it might be shifted by some time. TD, and so TD would be some delay, for example, the delay and the impulse response for making a causal like on on this slide over here. deriving what h of j omega was for a distortionless LTI system and we kind of went through this really quickly so I'm just going to walk us through this again, which is that the distortionless system has this equation that the output is the input that is shifted by some time TD and scaled by some amplitude K. So what is the frequency response, big H of j omega for a distortion list LTI system. And to calculate H of j omega, you all know that the frequency response, H of j omega is going to be the Fourier transform of the output, divided by the Fourier transform of Y of t, is equal to k times big X j omega, and then because it was shifted in time that corresponds to a multiplication in the frequency domain by this complex exponential. And then after I have this, then I can just solve for big H of j omega, which is big Y over big X, and that's equal to some constant big K times a complex exponential. And then the magnitude of H of j omega is just equal to K.

And then the phase of j omega is what's multiplying the j in the exponential, which is minus omega Td, the amount of delay we have in our system. All right. So in the distortionless LTI system, this is what its frequency response looks like. It has a magnitude which is this K, and so if I plotted the magnitude response, it would big K. And then the phase response is going to be negative omega Td. So that means that as omega increases, it's going to get more negative. And the slope of this line is going to be minus Td. Okay. And so if you deviate from this amplitude and phase spectrum, for example, if your amplitude spectrum look like this, right, or the phase spectrum look like this, then your output is no longer going to be distortionless.

Your output will have either amplitude distortion if the magnitude response is not just equal to k, or phase distortion if the phase response is not a straight line. So what do these distortions look like intuitively. Well for amplitude distortion. It's relatively straightforward. So, the amplitude response is going to be a constant with the value, the amplitude K. And so when the amplitude deviates from an impulse, for example, if we try to make an impulse, but we didn't do a good job and because an impulse is really hard to make in real life, and so, or it's impossible to make in real life. So instead of an impulse, we have something that looks kind of like an impulse, but has some, has some, isn't perfectly an impulse.

If we were to involve X of T and H of T, right? So we flip and drag this h of t here, right, this h of t is going to when we do a flip and drag is going to lead to a smoothing out of the abrupt corners of these racks. the function or in the frequency domain deviating from a straight line. Any questions there? All right, so then phase distortion is a bit more tricky to conceptualize. And so recall that our frequency response, h of j omega, can be written as the magnitude of H of j omega times the phase, e to the j phase of H of j omega. And so when there's phase distortion, what this is telling you is that the phase at different frequencies is going to be different. Right. And so, if I have. And I derive this for a decomposition, right, and the for a decomposition tells me that this is going to be comprised of science and cosine so maybe this is a low frequency cosine.

And then there's a higher frequency cosine. And then, let me do this in a different color. Purple, maybe even higher frequency cosine. this rect right here, right? The phase tells me how much each of these different cosines is gonna be shifted, right? Because phase gives a shift in the cosine. And so when there's phase distortion, the way that I picture it is that the cosines are being delayed relative to each other such that when you add them back up, the signal looks distorted.

And so maybe we have the case that the phase of the high frequency signals is close to the close is small so that their face doesn't get shifted a lot. And so maybe these stay here. Alright. So now because all the different cosines are being shifted at different phases relative to each other. When I go ahead and add them up. They won't perfectly add up to give me my original signal. Instead, when they add up, maybe I'll start to see some distortions in the output where here. Maybe the lower frequencies were delayed later so they only add up to give me my original signal when the low frequencies are also incorporated but maybe early on, I have just more representation from the higher frequencies. So when I add them back together that beats to some distortion in the output.

Right. So I want to. Sorry. I'm not here for this. Sorry, was that Caleb? I'm not sure if you have like a procedure for who goes first or something. Usually we do a hand raised procedure, but there are. There are so few people here that you could just scale for it. Yeah, thank you. I was really stuck on the Poisson distribution part of the homework. And I've been looking at some of the discussion notes regarding solving the optimization parameters. And I guess I just had a few questions about how our variables are being formatted. For instance, in Shoshank's discussion. And I will for thought our homework, we have these why I terms, which are elements of a vector why. And then in discussion, it seems like each why I term is also a vector from a size D.

And that sort of tripped me up and I was hoping you could clarify the variables and maybe how to proceed with the problem. Yeah, so why I is a scalar. And so I so shouldn't be a vector of size D. Let me, sorry, let me grab my iPad. I should have had it already so that I can write out some things. And I just realized if I do connect my iPad, I have to get my AirPods working. Otherwise my iPad audio will. Will make so let me just do this. I hope it just takes 30 seconds, sorry, everyone. Thank you. All right. Can you all hear me? Yes. Okay, great. The AirPods are working out.

All right. So for this question. Regarding the setup, it should start off similarly to the other questions. And so for example, the derivation of pi k should be exactly the same. You just look at that pi k is the proportion of trials. The difference will come when we now. So just going up from the start to this line, this is writing the total data likelihood. So we're going over all of our classes with OK. And then for each class, where iterating over the trials, J in that class. And then we had the log probability of the neural data and the class. And so I feel free to anyone stop me if any of this is unclear. So this is our data log likelihood data log likelihood. And then going from here to here, I think all of you have done this already. I just use Bayes rule to write its p of ck plus p of y given ck. And this is log of pi k again, the same derivation has in the prior parts.

And in the prior parts for log p of y given ck. You all ended up using the Gaussian distributions. Now for Caleb's question as to what happens when this is poson. So for the poson distribution, what we do is. In the multi variate gas in case we model this covariance between neurons. And so there is some inter there are terms following how. Enter how the relationship between neurons in the poson case, we don't have that. So in the poson case, we just have a random variable describing a single neuron. So the way that we said this in the homework statement is that. When we take the probability of all. D neurons. So why to the J is. Your vector in our D and it contains your firing rates of the dean neurons. So why one why to to why D. And this part what we say is that. The why I the little why I the elements of these of this vector are independent conditioned on the class.

And so what that means is that. If I take the probability of this entire vector given the class, I'm in ck. This is going to equal p of y one given ck. Times p of y to give them ck. All of these little why ones why to's why these these are just scalars. They're single neurons. And all of these have a poson distribution. Real quick, these things you could differentiate between the superscript and parentheses in the subscript. Yes, the superscript and parentheses, the J here is referring to which trial we're looking at. So. All of these have a superscript J saying this is a neural data on the j trial. I committed them at a convenience, but let me just put them in to be absolutely clear. So for the j trial, we're saying that the neural data that we see on the j trial, which is a vector in our D for dean neurons. For the naive base plus on model. Can be broken up into a product of probabilities, which is a probability of the first neuron, the first element.

Times of probability of the second neuron, the second element, etc. And that's this expression that I've written right here. Okay, I just think it was just a little bit confusing for me because when I was deriving it for the Gaussian model, but looking at the summation line and read, I would use J as sort of a subscript rather than a superscript in that case. Yeah. And for these notes, I intentionally put J in a superscript. Actually, these are from Monday's office hours notes. I originally was using I, but then I saw that in the question statement, we use I as a subscript for the neuron number. And so that's why that's why I changed all of these to j's and have used it the trial to be the superscript parentheses to differentiate from the subscript number, which is the number the neuron number. Okay. Yeah. And so what you should be able to do then is if this is the probability of this probability is P of Y, the entire YJ, which is the entire vector in RD, then you could take this product. And so you know from the problem statement that the I neuron given the class CK is going to have a pause on distribution with mean lambda K I. That means that each of the P of Y I given CK can be written as the mean lambda K I raise to the spike counts, which is Y I times E to the minus mean divided by the spike counts, which is Y I factorial. So this this line here, all I've done is I've taken the plus on a lamp a K I and written that written the actual probability mass function in place here. Okay. I'm I guess I'm just wondering that at that point, you're taking we're optimizing over lambda. Was it lambda K I or lambda K J? Okay. So you just have one of these in the in the product.

Well, you take the line. So and then you pick out the the one with the I one. That's correct. That's correct exactly. So yeah, you you put this. I'll just say it just in case to be clear to everyone off on the call. What what Caleb was saying is that we take this product, we plug it in here, right? And then that's just into a sum of log of this expression. And then from there, you can differentiate with respect to lambda K I. Because that's the parameter of this model. And as Caleb was also mentioning, this son is going to have. So that's the lambda K I's for many case and many I's where you're different shooting with respect to a particular particular lambda K I. And so that should simplify the calculus and. To. To make sure that you've done the the math correctly, I can tell you the intuitive answer here, which is that lambda K I ends up being. The average firing rate for neuron I in class K. So when you actually derive what lambda K I is. You should get an expression that looks like lambda K I is equal to the average firing rate of neuron I in class K.

All right, we're going to get started for today. So just two announcements. The first is that homework number six is due this Friday, and then, including today we have three lectures left so we're going to finish sampling today and then the rest of our Any other admin related questions. All right. Cool. So, we can't store the value of the signal at every single point in time because there's infinitely many of them. And so we have to store samples. But then, now comes the question. How quickly do I sample my signal because if I sample very quickly like up here, then I'm definitely going to be able to know what my original signal was if I sample too quickly, then I'll also end up using a lot of memory storage to store the signal. And so what we're going to finish deriving today is the sampling theorem, which tells us that, tells us the minimum, sorry, tells us the maximum time in between samples, or the minimum rate at which we need to sample a signal, so that we can perfectly reconstruct it.

Right. So then, last. Oh, and here's an example which we'll talk about later on, which we'll talk about later on, but just shows that if you only have samples like the red points for the samples shown in the red points, we can show here that it could correspond to cosines at different frequencies and so here's an example where, without any other information these red samples here are ambiguous because it could be this cosine at 0.75 hertz, or they could be this, they can correspond to the samples of this cosine here at 1.25 hertz. So we'll talk about that later today this is an effect called aliasing. All right, so last time we took a very roundabout path to essentially build up the intuition for how to think about sampling. And we introduced the signal called the impulse train or the delta train, where this big T tells us that we have a bunch of deltas that are separated in time by a big T. So these are a bunch of deltas that are all big T's spaced apart.

and we call omega naught is equal to two pi over big T. Right? And so an impulse train in the time domain has a Fourier transform, which is another impulse train in the frequency domain. And because we know that in time or to sample a signal in time, what we do is we multiply that signal by a Delta train. Right? If I sample a signal in time, if your signal is sampled in time. That means that in the frequency domain. The spectrum of the signal is going to be convolved with an impulse train because multiplication and time is convolution in the frequency domain. And so this is this periodic sampling duality that we derived last lecture.

by multiplying it by my impulse train which are impulses separated by time big T. What that means is I'm going to take my spectrum for FFT, so here I've just drawn this as a red triangle here. And then I'm going to convolve it with an impulse train which means that I'm going to create replicas of it at every omega naught. Alright, so I might pause and see if there any questions for this recap from last time. Alright, so Okay. So, this is the slide that we ended on last time, which was to say, if we take a signal at 50 and sample it by multiplying it by the impulse train. Then, the Fourier transform of the signal is going to be the Fourier transform of FFT replicated every integer multiple of Omega naught. We saw from this that we can deduce the intuition for what rate we have to sample at. So, if Omega not is big.

Right. If Omega not is big, which means that capital T is small, the time in between my sampling impulses is small, then the replicas are going to be far away from the center remember the replicas occur every omega not right. However, if omega not a small shown here in purple, meaning that the time in between my samples is relatively large, then the replicas are going to be close to the original signal, whereas in the case of when Omega not was big and we had a replica far away. I could recover my original signal which is just this triangle over here by applying a low pass filter in this range. Okay. And so we're going to be the maximum frequency of the signal. And so, the frequency at which the signal goes to zero and stays at zero forever. We're going to call that be. That's going to be a bandwidth and frequency but in the omega domain, it would be two pi times. times B. Grace. I wanted to clarify some notation.

So when you write tilde f of t equals f of t times delta sub tau t, or delta sub big f is f that is sampled in the frequency? Sampled in the time domain. Yeah, so f tilde here would correspond to the sequence of these impulses. Okay, thank you so much. Great. Thanks for that question. Any other questions here. And then I saw a question in chat, Jared asked with bandwidth we are saying that in time the signal contains no frequencies larger than plus minus be over saying that in the not in time but in the frequency domain omega. So the largest frequency for Omega would be to pi be. So basically it's the width, or it's half of the width of the signal spectrum.

And that's what you're looking for. When you're looking at Omega, the angular or natural frequency. Alright, so And so, we're going to multiply an impulse train. Omega not, and then an impulse train with impulses separated by Omega naught, and that creates the replicas at Omega naught. Right. And so here we're showing this convolution. Again, just to get the flip. Not again but to get the flip and drag intuition which is, if I take this impulse train and flipping flip it right if I flip it it's even so it's going to be exactly the same. Now when I do the drag this impulse, when I drag it to the left and the right is going to trace out this triangle. All right. And then if I drag this impulse to the right, eventually it's going to trace out a triangle that's going to be this triangle and if I drag this impulse to the left, it's going to eventually trace out a triangle and then the same for all And you can eventually get these triangles replicated every omega. Rampton. Um, so you said that f of j omega must be zero above to pi be and below negative two pi be. Is that always the case for the periodic signals. Yes. So, you do mean periodic in time.

All right, everyone. For today, we have just one announcement, which is that homework number five, which is pen and paper homework on graphical models with upload to grade scope last week and it's going to be, sorry, uploaded to CCLE last week. And there will be due this Friday, uploaded to grade scope by 1159 PM. Any questions on any course logistics? Oh, and a reminder that today is the last day to get in your midterm read grade requests. And so if you haven't taken a look at your midterm yet, please be sure to do that today. All right. All right. So last lecture, we started to get into BMI continuous decoding where the goal is to decode the signals from the motor cortex, the spike signals. And instead of using that to classify, which you all did on homework number four, to classify one of eight targets, now we want to decode algorithm that translates the neural spikes into continuous movements like a robotic arm or in our case, a computer cursor on a screen.

All right. And last lecture, we had gone over several videos showing the history of these continuous motor BMI's. And now we're going to get into the algorithms. And so there are going to be three algorithms that we cover in class, which are the optimal linear estimator. Here we call it linear vector, the weener filter, and then the common filter, which will be for the next few lectures. And we go over the Matthew hindies in this review paper that we wrote in 2014. All right. Were there any questions from last lecture about anything related to the videos or to any historical BMI performance? All right. So then let's set up the decoding problem and let's get to algorithms. So in the data set that we are going to give you for homework number six, what we'll have is a monkey, monkey J, and he reaches to eight different targets without a planned period this time.

He just makes movements continuously from targets to target. And simultaneously, movements, we record neural activity. All right. So we have two observations. The first observation is the monkeys observed kinematics. And we write that as respect to XK. K here denotes time. So it's K instead of T because we're going to discretize the time. And then PX and PY, these are the monkeys X and Y position at time K. And then VX and VY, these are the monkeys X and Y velocity at time K. These are the position and velocity of his hand. So as he reaches, we track a little bead on his hand and we're calculating the position and the velocity of that little bead. All right. And so simultaneous to this, let's say that we have one new TOR ray implanted.

And so on this Utah array, we'll have capital N equals 96 electrodes. So on each of these electrodes, we're recording spike, spike knee activity. And so here we have a vector that tells us the bin spike counts at a given time. All right. So this is this illustration here. The input to these decoders are a spike vaster where we have 96 neurons. And basically at some time point K, what we do is we define a bin with a window. And I believe in the homework, this window will be 25 milliseconds long. Right. And what we do is we count the number of spikes that occur on every single neuron or every single electrode in this 25 milliseconds. And if we divide the number of spikes by 25 milliseconds, that gives us the firing rate, nestinit of firing rate. Right. We usually just avoid the dividing by 25 since I've just scales everything.

And so it's not totally necessary. So Y1K, if we do divide by 25, that'll be neuron once firing rate in that 25 millisecond bin. Y2K will be neuron 2's firing rate, et cetera, et cetera, down to YNK, which is the 96 electrodes firing rate. So we have a question from Jonathan. Yeah, is this sort of analysis performed during the experiment or is it performed after the experiment? Or does it matter? Great. So for building the decoder, which is what we're going to talk about first, how we train it, we collect the data, and then we do this analysis after the experiment. However, it's entirely possible to also do this as the experiment is running, collect your data, and then update your decoder. So when you take these bins of neuron firing rates and you've already performed the experiment, are you putting a bin center around time point or is sort of like the bin, it's taking the time point and a number of time points before the time point.

Do you understand what I'm getting at? I'm not 100% sure. Jonathan, let me just draw diagram first because maybe this helps. And then if this doesn't help, then let me address your question again. So if we have spikes, what we do is, if this is zero, time zero, this is time 25 milliseconds, this is time 15 milliseconds, this is time 75 milliseconds. So this activity between zero to 25, we'll call Y1, Y at time 1, this activity will be Y at time 2. And so we just increment every 25 milliseconds and there we count the number of spikes, we get the firing rate, and they just go in 25 milliseconds increments. Okay, that's fine. Thank you. Okay, great. Jonathan. Yeah, it's on one.

Yeah, it's on one. So since this is a continuous decoding task, right, we are doing it for 25 millisecond time bins. So for that 25 millisecond time bins, how do you record the kinematics? Like for example, the position might vary over to 25 milliseconds or is it fixed? Yeah, great. So over the 25 milliseconds, the monkey will be moving. So if you imagine, let's say the monkey is holding a center target and then he makes a reschedulatory out to one of the targets, let's say he reaches out to here. So this would be time zero and then in the homework, we'll tell you how to do this, but basically every 25 milliseconds. So actually, let me fight it like this. In between these two time points, we'll be 25 milliseconds in space. And so this will be here. The x and y position here will be p of x1 and p of y1.

And the x and y position here will be p of x2 and p of y2. And then the way that we get the velocity is that we simply do the simple oiler approximation of the derivative. So if I want to calculate the velocity in this 25 milliseconds bin, I would take the x velocity would be px2 minus px1 divided by dt, which is 25 milliseconds. And that would give me an estimate of the velocity. And then we would do this regression. Then the neural data from 25 to 50 milliseconds would be regressed against this velocity and this position. And there are some details about the timing that are important to get right. And so we walk through all of that in homework number six. And I want to say one more thing I responded to Jonathan's earlier question, which is we learned a decoder post-talk after the experiment, after we've collected the data. But then of course, after we had that decoder, then we can decode new neural data on the fly to then move a cursor on the screen.

And we predict that cursor's movements, those movements are entirely nearly driven. And so when we really decode the neural activity to get the kinematics, we put a hat over it to denote that it's decoded and the decoded kinematics will be x hat k. So similar to before in the training phase, I want to learn a relationship between yk and xk. That's my training phase. In my testing phase, now I only get yk the neural data. And I want to predict what the kinematics of that cursor are x hat k. Sorry Jonathan, I'm trying to get it again. So do you think that 25 millisecond ad hocly or that's the amount of data that's required to decode this kinematics with high fidelity? Yeah. So great question Tomway. So the 25 milliseconds we choose from empirical results, so actually in empirical results, it gets even your BMI, your decoder performance gets even better as you make dt smaller and smaller.

0:00:00
All right. We can do the race hand system. And I see first the question in the chat. So Caleb asks on the Wiener filter slide. So sorry, let me connect my iPad again. So I can get the Wiener filter slide up. All right. So Caleb's question on the slide. How about getting from the Wiener filter to the correct form? I think that blows probably this slide. Can you confirm that the top yellow example is correct? It seems like the last term should be L5 times Y0. If you follow the pattern, L3 times Y2 L4 times Y1, you are correct, Caleb. So let's see.

0:01:22
We're starting at time P plus 1. So my error is this should be an L4. So this should be an L4. Since P is equal to 4, so it goes from L0 all the way up to L4. And then this goes to K minus P. K is equal to P plus 1 is equal to 5, so 5 minus 4 is equal to 1. So it should have been this. If you follow the pattern, good. OK. Thanks for catching that Caleb. I'm going to re-upload these notes now so that I have the correct version uploaded to CCLE. So then while this is happening, I'm happy to take the next question. Edwin. Hello, Professor.

0:02:31
I'm wondering if I can ask a question about the latest homework? Yes, let me pull it up. All right, I had the homework up. OK, so I'm working on the last problem about the precision matrix. And so far for the covariance, I have a 4 by 4 that just has to add no terms. But I'm a little bit confused because in part C, I see that we're able to invert it. But my dad knows just turned out to be the variance of each input, so I feel like I'm not completely comprehending the problems. I see. Sorry, let me just really quickly read this. Yes, so I'm sorry. Edwin, you were saying that your precision matrix to the inverse of the covariance, you had just the variance terms on the diagonal? Yes, correct. OK, yeah, so there is something, I think there was a, that's not the question answer, so I think that B was probably incorrect.

0:03:58
And so for B, we can walk through that if that would be helpful. Yes, please. All right, great. So we have this graph, which is x1 to x2 to x3 to x4. And then we say a possible application of this directly graph is to model a stimulus that changes over time. And so in this case, we have x1 is Gaussian like this. And then xt given xt minus 1 is Gaussian with mean xt minus 1 and covariance, and variance sigma squared. And here this is for t equals 2, 3, 4. All right, and so then we ask what is the 4 by 4 covariance matrix of the vector x, which is x1, x2, x3, x4. All right, so can someone, it can be Edwin or anyone else tell me what a first step you thought to do here was? I started with working with the definition of the covariance and an useful thing I thought was trying writing the graphical interpretation of the probabilities.

0:05:39
Okay. Yeah, so let's say that we want to calculate the covariance for xi and xj. So this would be the expected value of xi, xj minus the expected value of xi, expected value of xj. And then Edwin, sorry, was the other thing that you said with the graphical model? I just wrote down the equation. Yeah, so what were the equations that you had? The probability of x1 times the probability of x2 given x1 times the probability of x3 given x2 times the probability of x4 given x3. Great. So this is the joint density. All right. And then again, Edwin or anyone else, given this information, how does anyone want to take a step at how they might have calculated these quantities? Okay.

0:06:53
Let me go ahead and walk us through this time. So here, we need a relation for xi and xj. And so if I were to write this expression out, let's just focus on the boundary equation. What I'm saying is that xt, given xt minus 1, is normally distributed with mean xt minus 1 and variance sigma squared. In this case, the number xt minus 1 is an observed quantity. It has no randomness. And so the way that I can simplify this equation, xt given xt minus 1, being normally distributed with mean xt minus 1 and variance sigma squared, that's the same thing as saying that x of t is equal to x of t minus 1 plus a random variable, I'll call it w, where w is normally distributed with mean 0 and variance sigma squared. Now why can I say this? It's because of following, if I take the expected value of xt given xt minus 1, that's going to be the expected value of xt minus 1, xt minus 1 is an observed quantity. It doesn't have any randomness, so it's just equal to xt minus 1 plus the expected value of w, but the expected value of w is 0.

0:08:44
So the expected value of xt given t minus 1 is equal to xt minus 1, and so the mean here is xt minus 1, and so that's all good. Now I want to calculate the variance of xt given xt minus 1. And in this equation, this would be the variance of xt minus 1 plus the variance of w. But in this case, xt minus 1 is an observed quantity, it's deterministic, so it doesn't have any variance, it's just a single number. So it's variance is equal to 0, and therefore the only variance in this expression comes from w, which has variance sigma squared. And so this variance is equal to sigma squared, right? And so this equation xt equals xt minus 1 plus w is a restatement of this fact of this distribution over here. Okay. Does anyone want me to go over any part of that again? I lost the motivation behind the addition of w, can you please go back to that? Oh, you mean why we put things in this notation?

All right, everyone. For today, we have two announcements. The first is a reminder that homework number five is due this Friday, May 21st. I'll upload to Gradescope by 1159 PM. The second announcement is that last lecture, someone asked a question about homework number seven. And I would look at the syllabus for this year, and on the syllabus for this year, we only listed up to homework number six. And given the pace of the class this year, this will be the last homework for this class. So usually we do have a, when this is taught in person and the pace is a bit quicker. We do have a homework number seven, which is on the mentionality reduction. And this year we are not going to have that homework, but we will likely release, release solutions for our difficult carriers. All right. Any questions on any course logistics?

Questions from Edwin. Hello, I'm just curious whether we will still cover dimensionality reduction. Yes, I believe we will be able to, I think given the pace of the class, we should finish common filter sometime next week and then after that our last topic is the mentionality reduction. Thank you. Any other questions? All right. So we are continuing on continuous decoding for BMI's. And today we're going to talk about the common filter. And so our motivation at the end of last lecture for the common filter was the following. We could decode with the optimal linear estimator as well as the weiner filter and we saw the weiner filter did quite well. But neither of these decoders took into account anything special about the movements we make. Both the optimal linear estimator and the weiner filter were essentially these squares regressions of neural data to kinematics.

All right. We now we know that when we move our movements are smooth and our arm has inertia. So we aren't making a jittery movements like we saw for the optimal linear estimator. All right. So the idea behind the common filter is can we incorporate additional prior knowledge we have like the fact that our movements are not jittery in real life or typically not jittery. Can we incorporate that into the decoder? All right. And so the premise of the common filter is to ask what if we have additional information in this case that our movements are smooth. Right. So here in lecture we're going to we're going to primarily talk about a velocity common filter which incorporates the smoothness of movements for a computer cursor on the screen. But maybe you're controlling a robotic arm and you know something about the dynamics of how that robotic arm moves.

The common filter would allow you to incorporate those dynamics into the estimation. And in this lecture what we're going to do is we're going to talk about the common filter first at a level of intuition since the math gets pretty involved and it's easy to get lost in the read. So we're going to talk about the common filter at a high level intuition and then after that we'll dive into the more math details. All right. So we're still in the context of the motor prosthesis where our goal is to be code the continuous movements of a computer cursor on a screen and you could generalize this to a 3D robotic arm if you're controlling the endpoint of that robotic arm. Okay. So really the common filter has been the workhorse for motor neural prostheses in the last decade and the best state of the art decoders today include a common filter. That said the common filter is of course not specific to this area of brainwashing interfaces and so one of the rewarding things for me in teaching these classes is to see students come back and tell me about how they used some of the techniques they learned in research and for this class what I hear most is how they were able to use the common filter in a particular application.

Essentially the common filter is a technique that is applicable whenever you have time series data and there's some dynamics or there's some structure across time where you want to model that. And so anytime when data is modeled to evolve through time in principled ways the common filter can help you incorporate that evolution through time those dynamics through time into your actual inference, interior predictions, interior decoder. So it's a tool that hopefully that isn't just useful for this class but could hopefully be helpful for you in other context applications or classes. All right. So we are going to go into these next slides I covered the common filter to have very high intuitive bubble and we're going to provide you with the algorithm so that you can code it up on homework number six and then after that we're going to go into the detailed derivation of the common filter because as we'll see the algorithm for the common filter the equations at least look very complex and so when we derive them we'll see where they come from and of course that they are not magic.

All right. Any questions so far? All right. So this was a figure from a study that essentially motivated the common filter. I kind of mentioned this study in passing last lecture where in this case what these people from the brain gate clinical trial did what these researchers did is they had the subject perform a participant perform a center out in back tasks to four targets and on a single trial if they decoded with a wiener filter these are what the trajectories look like and they look pretty noisy. If you take all the trajectories that go downward and you average them together you get these this black line here for the right word trials would be this blue line and you can see that even averaging across all the trials to a particular target the trajectories even in the memes look pretty noisy. So this is a wiener filter and this paper established that we should work with common filters although again for this study like I mentioned last time their delta t times p the number of things they look back in history was 1,000 milliseconds which actually poses problems for the common filter because it means neural data from one second to go is forming your movement at the current time point and you can imagine if motor commands from a second ago are influencing your reach right now that could actually be difficult to control and that's why in the homework we asked you to set p delta t on the order of 100 to 200 milliseconds which we find these to better performance.

This is what their wiener filter did and then they also implemented a velocity based common filter so a common filter that just because velocity and you can see on the individual trial the trajectories are much cleaner and if you were to take the average across trials you would get straight lines each target. And so at the time this is a very compelling demonstration that the velocity based common filter should be used over the wiener filter although today with some more hyperparameter optimization there's evidence that the wiener filter actually the vanilla wiener filter is better than the vanilla common filter. However after this paper once in the field worked on common filters and we may optimize into the common filter such that the state of the art common filter is indeed the state of the art algorithm out there today. Any questions here? Alright so I'm going to show this video in this a bit since I have to go to keynote to do that so let me first talk about the intuition. Alright so let's see that we have the following equation this is following our conventions from last time xk are the kinematics and yk is the neural data alright and you'll recall last lecture we talked about the optimal linear estimator where we did the relationship being xk equals L times yk so that we take neural data and use that to decode the kinematics xk alright.

Sometimes people are interested in modeling the reverse equation which is yk equals c times xk and this equation is saying how can you construct your neural data from the kinematics alright and if you have this single equation and I now ask you to build a decoder to say given that I have neural data how can I infer kinematics this is a question that you should all be able to do because we know what the least square solution is for c right and it would be that c is equal to y times x transpose xx transpose inverse that's the least square solution that we derive last lecture and then if I wanted to decode x from y then I could just compute the pseudo inverse of c and therefore xk would equal c pseudo inverse times yk alright and so since this equation is essentially the inverse of the optimal linear estimator sometimes or not sometimes this decoder is referred to as the inverse optimal linear estimator or the inverse OLE alright and the inverse OLE is this is the exact decoder that was used by the Pittsburgh clinical trial featured on the 60 minutes video and so I said that they use an optimal linear estimator to be more detailed they use the inverse OLE so they find a c matrix that relates the kinematics to the neural data and then they decode using the pseudo inverse of that c matrix right any questions there alright so that's how we would decode neural data if this was the only equation I have but now what I'm going to say is that we have another equation and that equation relates how my kinematics evolved through time in principle the way so I'm going to have an equation like xk equals a times xk minus 1 alright and this a matrix then captures the natural evolution or some properties of the evolution of my kinematics through time alright and this is something that you all have like we've seen before so if you think back to your physics class where you learned Newton's laws of motion right we can write them as an equation xk plus 1 equals a times xk relating again the kinematics xk to the kinematics of the future time xk plus 1 alright and so let's imagine that we have additional information in this case let's say that we are modeling a ball falling on earth right and so if we model a ball following on earth falling on earth what I'm going to do is I'm going to put the x and y position of the ball and the x and y velocity of the ball into this vector and this xk plus 1 equals a xk will then summarize my laws of motion so the first equation is going to say p xk plus 1 let me write it over here the x position at time k plus 1 is going to equal one time the x position at time k right and then plus delta t time the x velocity at time k that's just my integrated velocity so plus v at time k delta t alright this ball is falling on earth and so if we rack a y velocity right we're going to have acceleration due to gravity and we know from physics that that y position should follow this equation it's your initial y position plus your integrated velocity plus 1 half a t squared right so 1 half time the acceleration due to gravity which is minus 9.81 meter per second squared times a delta t squared alright so that's just one of those equations from physics when you solve kinematic problems and so we have that equation right here the y position at time k plus 1 is the y position at time k plus the integrated y velocity and then minus 1 half a delta t squared okay and then similarly we have then an equation that relates the velocities and so if you're in a vacuum then your x velocity is just going to be the same but your y velocity is going to increase according to the acceleration due to gravity okay and so this is a long-winded way of saying I can write Newton's equations succinctly in this matrix vector multiply that tells me how the positions and velocities of my ball evolve from time k to time k plus 1 right and they're all summarized by this matrix okay any questions there all right so what I want you to notice is that in addition to this equation that gives me a relationship between neural data and kinematics xk remember xk is what I want to decode right I now have one more equation I have an equation that tells me how the kinematics at a prior time step inform the kinematics at the next time step so now I have two equations giving me information about the kinematics and so why might this matter for this I'm going to go into my slides and and show a few videos so we're going to consider this problem of the ball falling except now it's going to be a cannon ball and we're going to be shooting a cannon ball into the sky so believe it like forward so here I'm showing a video of you can imagine a cannon ball being fired off into the sky right and we know that it follows a parabolic trajectory right and we know that if you know the initial position and the initial velocity because we know the dynamics and Newton's laws of equation sorry Newton's laws of motion we can solve for the position of the ball of the cannon ball at any single point in time so if I give you the initial position and the initial velocity and I ask you what is the position of the cannon ball at a particular point in time you can solve that for me with Newton's equations of motion right any questions there all right so then let's say that you were an alien who came to visit earth and you didn't know Newton's laws you didn't know what our gravitational constant was all you could know you don't know anything about the physics of earth all right and so if you're an alien that's come to visit earth and I ask you as an alien to track the um position of the ball as it flies through the sky you can still do it because you actually get to observe the ball flying through the sky and so even though you don't know Newton's laws of motion what you can do is whenever you see the ball you can plop down an orange dot and um if you do this for every single frame in time then you're going to know the trajectory of the ball all right so there are two ways to get the trajectory of the ball one you know physics and so you can calculate it uh two you may not know physics but you can wash the ball flying through the sky and at every single point in time you can just say okay the ball is here the ball is here the ball is there etc okay now let's say you're still in the alien shoes um but now we ask you to track the location of the ball in this sky except now you as the alien can only view the ball through a noisy camera okay and so you can only view the ball through this camera and maybe you're watching a post-tot video the camera has low resolution there and so here that low resolution is from blurring this pixels by analogy and uh further the video is noisy so it turns out that uh when the light is dim and it's at a dusk there are a few photons that are entering the the camera and the photon arrival times are actually follow a Poisson process not unlike the the spike times all right and so in the analogy um the observation of this noisy low resolution video is analogous to how if we were to try to decode a cursor position from neural data that neural data is low resolution because I only get to measure a hundred neurons out of a hundred million and the neural data is also noisy because the spikes um uh have various zochastic processes and we can model that with a Poisson process right so now if I ask the alien to try to trace this ball in the sky um he can watch the video again and you can see there's a ball going there is kind of hard to make out right at the ball is almost fallen okay and so now if the alien goes from this noisy video and says okay this is where the ball was at every single point in time he gets out this blue trajectory right now this blue trajectory generally gets the position of the ball across time but there are some aspects of this trajectory that you know uh just are impossible like when the ball here is reported to fall down and then float back up right and we know that that can't happen the cannonball in space uh in the sky can't just uh fall and then float back up due to gravity right so even though the alien did a pretty good job there are some of these sub-optimalities in the observed trajectory that we can definitely improve upon because we know the laws of physics and so the idea of the common filter is to say my observations might be for example low resolution or noisy meaning that if I try to track this cannonball with just my observations only I'm going to get a trajectory that guessed a lot of the features correct but we get some features wrong okay and that's because my observations are noisy and low resolution just like when we decode from the neural data right we will get a lot of the features correct like in the optimal linear estimator but some things will be at a lower level uh incorrect like the jitteryness of the cursor however uh if we then take the trajectory and incorporate our prior knowledge that the trajectory um that the cannonball has to obey Newtonian mechanics then what we can do is say well when I saw the cannonball fall down and then float back up because my video was noisy I know that can't happen and so maybe I can denoise the trajectory to return something in orange and so this orange trajectory incorporates both my noisy observations as well as my knowledge of Newtonian mechanics right so what I'm doing is I'm taking both sources of information the low rise video camera as well as the laws of physics to get a better estimation of the actual flight of the cannonball shown there in orange okay any questions on that analogy Jonathan I have a question yeah come on yeah so for example you if you take a like the winner filter right and you get some decoding right so if you denoise that decoding results will you get something comparable to Kalman filter um it turns out and this is um something that I won't answer completely here uh it turns out that the Kalman filter as we will implement it is actually a specific case of a winner filter but uh tansher your question some way yes under some uh constraints on xk uh the winner filter uh will approximate a Kalman filter correct thank you come way all right and then let me also just show the video that I skipped before showing the performance of um our state of the art Kalman filter so one thing you can note about this video is that the cursor movements were very smooth there is no jitteriness and that smoothness is conferred by the Kalman filter modeling all right so if no questions then let me get on to the equations so what we are now saying is that instead of having just an observation equation an observation that's noisy and low resolution like the video camera in this case our low resolution noisy observation is neural data instead of just taking our noisy low-res neural data and using that to infer kinematics I'm also now going to use information about how the kinematics evolve through time in principled ways to further improve my estimation of what the decoded kinematics are so instead of having just one equation here the inverse ole I'm now going to have two equations and I'm going to use both of those equations to solve for xk all right and so these two equations together are called a linear dynamical system and there are entire classes taught on the analyses of linear dynamical systems and I highly recommend taking a class like that it both solidifies your linear algebra and then also gives you tools that help you to analyze time series data so this first equation xk plus 1 equals a xk this is typically recalled a state process in a dynamical system xk which are for us the kinematics are typically called the state and yk in a general dynamical system are usually called the observations it's what you get to observe in an experiment in this case is our neural data okay and so and this equation is therefore called the observation equation or observation process okay so our dynamical system is comprised of a state equation or state process and then observation equation or observation process this matrix a is typically called the dynamics matrix and it models how your state evolves through time which in our previous example could be things like the laws of physics or in the BMI example is going to be the inertia of the movement alright okay so just like I said before now we have an additional equation that gives us more information onto what our decoded kinematics should be all right so concretely instead of just decoding xk equals c inverse yk the optimal linear estimator I should now have more information from this equation my state process equation to better update and refine my estimate of the decoded kinematics xk okay any questions on that intuition all right I'm just going to throw out the are you following question just to make sure people are following since I haven't seen any questions yet in TAs if you can just tell me what the percent to gs is okay great looks like most are following all right any questions here all right so here's a thought that you might have if I have an equation like yk equals c times xk well what happens if or let that actually let's take this equation xk plus 1 equals axk and let's say I'm modeling a ball following right if I'm modeling a ball falling and it's falling in a vacuum on earth right this equation is almost perfect right and so if this equation is almost perfect isn't all I need to solve for the position and the velocity of the ball at any single time point and the answer is yes if one of these equations is perfect you don't need the other but the thing is that in most cases these equations are not perfect both of them are providing a noisy estimate of what xk is and if they're both noisy then we're going to have to find a way to incorporate them based off of their noise to best estimate xk and we're going to see in the common filter solution if you assume that one of these equations is perfect the common filter does tell you to just use one of the equations right so how do we get the optimal estimate of the decoded kinematics from these two equations neither of these equations are perfect because if one of them were then we should just use that one equation to solve for the kinematics in real life noise is going to corrupt these equations and so for the BMI case the reason that this equation isn't perfect is because the only thing that we're going to be modeling in this class is the inertia of the velocities so we're going to say in general our movements are smooth but it doesn't tell me what my velocity at time k plus one is given the velocity at time k all right so in real life neither of these equations are perfect they have noise and so the noise on the state update process is going to be called WK and the noise on the observation process is going to be called QK right and we bottled these noise as random additive noise and they're also going to be Gaussian noise that corrupts these equations okay any questions there all right so for the common filter we're going to make several assumptions when we get to the details of the math we're going to assume that the noises are Gaussian noise terms and so if xk were velocities right so if xk was my x and y velocity at time k right then wk would be a two-dimensional noise source with covariance with mean zero and covariance big w and then QK is a noise source on the same dimensionality as yk my neural data and so if I have 96 neurons this QK would be 96-dimensional so if the covariance matrix w was equal to zero for example right then all my wk would be zero tiny that this equation is perfect but as long as w and q are not zero then these equations have noise in them and again then we need to know how to estimate how to use both of these equations to estimate xk given my neural data and my historical kinematic data any questions there all right so then you might ask how do we get the optimal estimate of x hat of k from these two equations so in general this is an extremely complicated problem without nice closed form solutions but under certain assumptions which are linearity and Gaussian noise so under the assumption that the state update process is a linear equation which is which is which is this here is a times xk and the observation process is linear too as well as Gaussian noise at wk and qk are Gaussian then there's a recursive solution to estimate xk and that's called the Coleman filter and again at least for these starting slides we're going to just start with the high level intuition the take-home point and intuition behind the Coleman filter is that my decode equation of x hat k now instead of just being a mapping from the neural data so if I if I didn't have this m1 x hat k minus 1 x hat k would be equal to m2y k which looks like an optimal linear estimator but now that I have this dynamics equation the state update process I'm going to also have another term m1 which is another matrix times my kinematics at the prior time step all right so instead of only using neural data to decode kinematics which is what we did for both the optimal linear estimator and the wiener filter we now also use the previously decoded kinematics xk minus 1 so this term here corresponds to this term here since the previously decoded kinematics also has information about what the next kinematics should be through this dynamics equation all right and so that leads to a decoding equation of this form all right any questions there and then Brandon asked and checked and I repeat what m1 and m2 are so m1 and m2 are just going to be matrices that map the prior kinematics and the neural data into my currently decoding kinematics we haven't arrived with m1 and m2 are yet in fact m1 and m2 are going to take on pretty complicated expressions that need to be recursively calculated but and and that recursion is is called is the common filter algorithm but at least at a high level m1 will map by prior kinematics to my current kinematics influenced by this equation and then m2 will map my neural data to my kinematics so basically m1 and m2 are summarizing how to combine these two equations to get my current kinematics from past kinematics and neural data all right any questions there okay so the next part of this lecture is we're going to tell you essentially the approach of how we solve for the common filter at a high level and then we're going to write out the common filter solution so that you could code it up in your homework if you wanted and we're also going to check that the common filter solution makes intuitive sense and so this is all in terms of gaining intuition of the common filter and then after that we'll dive into the details right so the common filter will give us a recursive method to calculate m1 and m2 and m1 and m2 these two matrices here are going to be some combination of a c big w the covariance of this noise term and big q the covariance of the q k noise term so they're going to be a function of these terms and the common filter is going to tell us exactly those equations right and so the goal of the common filter is going to be to estimate the distribution p of your current kinematics xk given all of my prior neural data y1 to yk so the picture that we should have in mind is the following and I just saw a question in chat it says why are we using the covariance of the noises so the code on any given time point time k w k and q k are going to take on particular sample values from this Gaussian distribution and that's going to vary from time point to time point but knowing that these noise sources we're going to see our independence and identically distributed and so on any given time point they may take on a they'll take on a particular value to get the best estimate of xk given that w k and q k take on random values from these from these particular distributions right the way that we characterize them is by the distribution parameters which are the mean and the covariance is and so this means that we don't observe the noise at every single time points update the common filter we just know the noise is statistics and using the noise is statistics will know what's an optimal way to combine them is and a question from shall ran yeah professor just wondering for these m1 and m2 are they the same across all time points?

All right, everyone. I'm happy to commend soft as ours and take questions in the order that hands are raised. Eric, I wasn't sure about 3C. It's the one where you can involve a signal and the HFT that they drew and you want to find a period where it's a constant. I did the question by like, I considered it conceptually if I have some periodic signal and then if I like to look and drag it, then intuitively if I had the same period, then no matter how you drag it, you'll get the same convolution. And then if you decrease it, decrease the period by like, integer values, it'll also work. But I'm not sure how to actually mathematically work that out. Great. That's the correct intuition, which is you'll notice that in the sink there are zeros at particular locations. And we know that a periodic signal corresponds to a sample signal, the periodic signal and time corresponds to a sample signal in the frequency domain. And so if that sampled signal has the samples at the zero points of the sink function, then they'll all be zeroed out and then any integer multiples of that period will also be that way. So we can do that mathematically. I want to ask if anyone had any questions on 3ARB before we did that. So as to be helpful to anyone, if not, we'll just start with 3C.

Alright, so we'll do 3C. And let me just drive the intuition that Eric was talking about. So as a 3C asks for non-constant periodic signal XFT for what period does Y of T equals X of T convolved with H of T equal a constant C. And then we tell you to think about the Fourier series and the Fourier transform. So we know that in the frequency domain, Y of J omega is going to be H of J omega times X of J omega. Right. And then from the previous part of the question, well, since we know that H of T is, H of T is a racked, right, then H of J omega has to be a sink. Right. So you should have gotten in 3B that we asked you. Yeah. In 3B, we asked you to sketch the amplitude response. So in 3B, we asked you to sketch the amplitude response. So it would be the amplitude of H of J omega. And you should have gotten that this was equal to sink omega big T over 2 pi, I believe. That's what our solution says at least. And therefore, H of J omega looks like the absolute value of a sink. And it keeps going on, but I'm just going to draw a few. Right. So this is a capital H of J omega. And we want that we know therefore, or we know from our frequency response that the magnitude of Y of J omega is equal to the magnitude of H of J omega times the magnitude of X of J omega. Right. And so if we, if we tell you that Y of T is going to equal C, then can someone tell me what we would expect Y of J omega to be equal to. Delta function. Yeah. Great. So Daniel, tell us a delta function. That's right. So Y of J omega should just be equal to C time to delta function. Since it's in inverse Fourier transform.

And so, would be the constant. And so next we, we use the fact that we learned that if a signal is periodic in time, right, it's sampled in the frequency domain. So a periodic signal periodic X of T in time is going to be sampled in the frequency domain. So it's going to be an impulse train. And so we know that the Fourier transform X of J omega is going to look like a bunch of impulses based at some separation given by given by the period of the signal. So from this, we can see that if I want Y of J omega to be equal to a delta, right. And I know that Y of J omega is H of J omega times X of J omega. And that H of J omega is zero at these particular points. If I design my periodic signal X of T to be periodic such that it's samples all occur at the zero points of H of J omega. And I multiply H of J omega and X of J omega all I'm left with is a delta at zero. And it's inverse Fourier transform is going to be a constant. So that's the key trick for this question. Are there any questions on this intuition and then after that, we'll do the math, which answers Eric's question. Why did you focus on the magnitudes instead of just the original function? Was there a reason for that? Yeah, you're right, Daniel. I didn't need to focus on the magnitudes, especially since we want Y of J omega to be C times delta omega. So actually, I sort of just drawn H of J omega being a single mega T upper two pi. And so this would go negative and positive and negative and positive. Actually, let me change that now so that it's not confusing. And I draw I drew this one because I thought it was a picture I saw in the solutions. So since in part, they asked us to plot the magnitude. And the same intuition holds, which is the product of H and X will only equal a delta function, as long as all these replica deltas for as long as all these other deltas occur at the zero points of H of J omega. And Professor, I had a question. So this graph that you have right now, what does this graph represent? Because this is not the magnitude of H of J omega. Yes, so. Yeah, so H of J omega in the prior part is also multiplied by by a phase component. And so at the same time, though, that phase component is not going to change. So this sink will still be zero at these points. So I haven't drawn H of J omega exactly. Yeah, that's steric, rent. So what I've drawn is is the.

The extra on here is sink omega T over two pie. But there is also there is also a phase component to the signal, but where it went, think of omega T over two pie is there a then the overall H of J omega will be Sarah. So for the purposes of this thought, I'm just going to leave it up since the intuition still holds, which is at these points, the sink is around. Thank you. So, um, if everyone's following that intuition, then we'll go ahead and write out the math for this. So, um, we know that if X of T is periodic. So what do we know we can write X of T as people can put in the chat also if you don't want to unmute and raise your hand. I know there's a lower activation energy to write something in the chat. How should I write X of T it's periodic. Four A series. Great. Yeah. So X of T can be written as a four A series. And so, uh, this is C K E to the J K omega not T where omega not is equal to two pie over big T and big T is the period of the signal. And so, um, we derived in class that this has four A transform X of J omega equals two pie times some from K equals minus infinity to infinity of C K and then multiplied by delta. So this is a delta omega and then the impulses occur where real may they're not great. So this would be K omega not. And so, um, then we want to know, um, let me copy and paste this onto the next slide. Um, we want that Y of J omega is equal to a constant times delta T, sorry, delta of omega. And Y of J omega is going to be equal to, um, each of J omega climbs X of J omega. But now X of J omega is going to be, um, this sum of impulses that we wrote. And then it's going to be a two pie, um, and then a sum from K equals minus infinity to infinity. And then we're going to have, um, a C K. And our delta function is going to sample the value of H at K omega not. So it's going to be H of J K omega not times a delta omega minus K omega not. So then, uh, what we need to do then is determine what, uh, what the period or, uh, when does this, when does this equal, uh, C times delta omega.

All right, everyone, we're going to begin now. So first, the TSO uploaded homework number seven last Friday and homework number seven is going to be due this Friday on the last day of classes at 11.59 p.m. uploaded to grade scope. The first three questions on this homework are on sampling and because we haven't fully covered the Laplace transform yet for this quarter, we gave you three questions, four, five, six on homework number seven, which we are going to grade based off of correctness, which is based off of effort. And so as long as you make any attempt to do the question, you're going to get full credit. And so in that sense, we want you to think of these more practice questions for the final exam. The final exam will be commuative and it'll cover material up to and including the inversion of the Laplace transform, which we'll start today and then we'll finish in the first half of Wednesday.

And so be sure to, if you don't do a significant attempt on these questions for homework number seven, be sure that when you look at the solutions, you understand how to do these questions because they are material that could be covered on the final exam. Tonmoi will be holding a final exam review session this Sunday, so in six days. And there's going to be a link, which is here. And I believe Tonmoi will either, Tonmoi will send an announcement on Piazza or CCLE and asking for what time works best for the Sunday review session. All right, so I encourage you all to attend that review session. And then the final exam is going to be held on Wednesday, December 16th, from 3 to 6 PM over Zoom. We're going to be sending on email with further exam details, but in broad strokes, the exam, the final exam logistics are going to be very similar to the midterm exam logistics. The final exam is commuative and so it'll cover topics across the entire class up to and including the inversion of Laplace transform. All right.

So we'll dive back into material. So in the second half of last lecture, we had started to cover our last topic in this class, which is the Laplace transform. And the motivation for the Laplace transform is that a lot of signals that we want to analyze may be growing over time and may be power signals. And we can't take the Fourier transform of a power signal. It's up for a few, which we did a generalized Fourier transform up. But in general, we can't take these Fourier transforms. And so while the Fourier transform reconstructed signals with bases e to the j omega t, for the Laplace transform, we get an additional sigma term e to the sigma plus j omega t that allows these cosines and signs to have a growing amplitude and therefore allow us to model power signals. All right. So the key thing is that there is also this e to the sigma part, which is a real exponential in time and models this growth.

All right. And so we notice then, well, we presented the equation for the Laplace transform, that's this equation here. And we notice that it bears a striking resemblance to the Fourier transform. The only difference is that the Laplace transform instead of an e to the minus j omega t, we have an e to the minus s t, where s here is sigma plus j omega. All right. So now this exponential here in the Laplace transform integral includes not just the j omega term, but also the sigma term. All right. And we said it would be good to conceptualize the sigma and the j omega as in a complex claim where the real part of s is sigma, that's the x axis. And the imaginary part of s is omega and that's the y axis. And what we note is that the Fourier and Laplace transform look very similar except for the Fourier transform.

It's a special case of the Laplace transform when s is just equal to j omega. So when sigma equals the row. All right. And we talked about then when are these two things the same or when can I just take the Laplace transform and replace all the s's with j omega's so that I get out of Fourier transform. So we started this example at the end of last class where we decided to take the Fourier transform of e to the minus a t times u of t. Its Fourier transform is 1 over a plus j omega. And when we took the Laplace transform we got the Laplace transform was 1 over a plus s. All right. And so we see that the Fourier transform and the Laplace transform are indeed of the same form except in the Fourier transform the s is replaced by j omega. All right. But we notice something interesting which is that in the course of doing this integral to get to 1 over a plus s.

When we did this integral we had this expression here evaluated at infinity minus this expression evaluated at zero. And we saw to get to the answer 1 over a plus s we have to have that as time went to infinity this term over here this term would go to zero. All right. And this is critical because this defines the region of convergence of the Laplace transform. So again for this integral here to equal 1 over a plus s this term here has to go to zero as time here t goes to infinity. All right. And so we have to then find a condition under which this term goes to zero as t goes to infinity. And that's how we did that at the end of last lecture where we saw that as long as as long as so this is the term e to the minus a plus s t goes to zero as long as e to the minus a plus sigma t goes to zero or sigma remember a s is equal to sigma plus j omega. So sigma is the real part of s.

All right. And so if sigma is greater than a minus a then the Laplace transform exists because this term again there goes to zero. And therefore we say that the region of convergence for this Laplace transform occurs when sigma is bigger than minus a. And sigma again is the real part of s. And so in our picture of a 2d plane right if the x axis is the real part of s sigma and the y axis is the imaginary part omega. And a is some positive number. Right. Then minus a is going to be a negative number. And as long as the real part of s is bigger than minus a by e to the entire green region then we're going to be able to compute the Laplace transform. And what you're going to notice here is that this region of convergence contains the j omega axis which is where the Fourier transform is evaluated upon.

And so for the Fourier transform the Fourier transform is going to be a special case of the Laplace transform where you can replace all the s's with j omega as long as the Laplace transform region of convergence contains the j omega axis. All right. We drew another example maybe another Laplace transform has a region of convergence shown here in purple. And this would not include the j omega axis. And so the Laplace transform that you find for this purple quantity you cannot just replace s with j omega and arrive at a Fourier transform. Okay. I want to pause here and ask if there are any questions recapping what we talked about last lecture. Chris. Hi. Could you please repeat what you were saying about the green and the purple interval?

Yeah. So we're going to do a purple example next. I'm going to focus on green just for now. So the green interval corresponds to the region of convergence which far the values of s for which the Laplace transform exists. And so for the Laplace transform to exist we have to choose a value of s such that this exponential goes to zero as t went to infinity. And we derived that the condition for this exponent, this exponential to go to zero as t went to infinity was that it's real part sigma had to be bigger than minus a. And so what I'm drawing here is I'm drawing I'm highlighting here in green the entire region for which these particular values of s anywhere in this green lead to you being able to compute a Laplace transform for for e to the minus e to the minus a t times u of t. So as long as you choose an s that is in this green region, then the Laplace transform will exist. I'm going to meet you one more time.

All right. Can everyone hear me now? All right. I'm sorry about that. I'm not sure what happened with Zoom. If you if anyone again has trouble entering, please just write something over chat. All right. So I'm going to just restart. We lost 10 minutes, but given that we maybe had half of the class not here, it'll be, I did, I think, to restart. So very quickly, homework is going to be released this Friday and then do in a week on Friday, upload to Grayscope by 11.59 p.m. Homworks in general will be due 11.59 p.m. the day that we say they're due. And so when you're uploading to Grayscope, make sure that you have some leeway to submit by 11.59 p.m. The portal will close after two late days following 11.59 p.m.

We sent out instructions on how to sign up for Piazza and Grayscope. And so please do so if you haven't already. And then we will send out an announcement shortly on the consolidation of discussion sections. And so, Tonmoi, one of our TAs was able to find three sections that everyone who wanted to attend the live discussions can make. And so we'll be able to do that consolidation. All right. I see the chat lighting up. If there are any problems, TAs, can you just unmute yourselves and let me know. I'm going to just forward to have here. So I just wanted to mention on the syllabus, it appears when we write homework, we release that they're released on Wednesday, but we release them typically one week before the due date. Unless they are a longer assignment. So we, these homework assignments are all due on Fridays and we're going to release them on Fridays. But we will announce all of that in class. And so hopefully none of that will be ambiguous.

All right. So last, we were in last lecture. We ended talking about the syllabus, which we didn't complete, but we'll complete right now. So I had mentioned that homework is worth 50% of the grade. And it is a very high weight for this class. That reflects how important we believe the homeworks are. As we'll discuss later on, we designed the homeworks to be fairly difficult, but the exams to be no more difficult than the homework. We also made the homeworks work a lot to decrease the percentage that the midterm and final exam assessments are worth to try to lower the stakes on those exams. And to discourage any academic dishonesty. And so I wanted to then talk about academic integrity, which is very important to me and to the teaching staff of this class. And so this slide reminds you all of the true brewing UCLA academic integrity principles. I take academic integrity very seriously because it's important that we are all on a fair and level playing field. When you cheat, it's not only the service to yourself, because it's not a reflection of the material you've learned, but it's also unfair to your fellow peers who may have worked very hard to study for the exam. Another thing that we'll do in the class and I'll discuss shortly is that this class is rated on an absolute scale not on a curve. So you aren't compared to your fellow peers. In any case, for this slide, my point is showing this is to tell you that I take academic integrity very seriously.

And if we believe that you have been academically dishonest on an assignment or exam, I will follow up and submit the case to the office to the dean of students office. So again, please be academically honest in this class and ultimately fair to your fellow peers. So this is how exams are going to work. We, the teaching staff, recognize that during online instruction with remote exams, it's very difficult for us to prevent cheating on exams, for example, due to collaboration. So in trying to make things as equitable as possible, the first thing that we're going to do is make all exams open note, open book, and you're free to access CCLE on your computer. Exam will only be closed internet and that you shouldn't, you can't Google the answers to questions. And to try to discourage this, the TAs and I are also going to aim to write exam questions that I cannot be easily searched. To deal with this issue of collaboration, the TAs and I are also going to perform analyses on exam answers after that. And if we suspect any students of collaborating on the exam, we reserve the right to administer an oral exam to the suspected students and the results of the oral exam will supersede the results of the written exam. And if there are any other further policies, we'll announce those closer to the gate. In Jonathan. So I know that you said the exam is closed internet, but since we're also allowed to use the notes on CCLE, can we have several tabs of CCLE open like of like, oh, this is chapter one notes. So I don't have to flip through CCLE. Yes, just click on this tab. Yes, you're welcome to do that. So it is close and try to accept to access CCLE. You can have as many CCLE tabs open as you like.

Okay. Thank you. Any other questions on exam policies? All right, great. So we also recognize that students may be in different time zones that make taking the exam during class time or during the scheduled final exam time difficult. So if you're in that situation where you need to take the exam during a different time, please email me by the end of this week so that we can prepare for this. I just saw in chat someone asked about a map lab. So there's not going to be any map lab syntax questions on the exam. You won't be asked to write card. All right, so grading in this class is done on an absolute scale. And so this is the scale for how we're going to assign grades. And so throughout the quarter, you'll be able to calculate your grade exactly given the breakdown. We had in the prior slide and this scale here. Now, when I was an undergrad, I knew when I went into a class and there's an absolute scale, I was a bit scared because what if the professor writes a very difficult exam and all the grades are really low. And so we work, we try to design the exam so that that isn't the case. But if we do end up giving an exam where the average grade is very low, causing the students causing many students to be in a lower grade range, then we reserve the right to relax the scale so that the scale would be the scale would be an easier scale would be relaxed, but it will not be made more stringent. All right, I'm seeing a bunch of questions on the exam. So I'll really quickly look at the chat Angela asked the exam written or typed out. So we are going to give you questions, which if you want to type them on my logic, you can, but typically most students just write their work and their answers on a sheet of paper and then also that PDF to grade scope. We will not be using respond this lockdown and we will not monitor you during the exams. And so we will distribute the exam for the in class exam, it'll be a one hour or 50 minute exam. And the TAs and I will also be in a zoom room in case you need to come and ask questions, but we won't ask you to turn on your cameras and we won't monitor you.

Okay, any other questions. Right, and then are we submitting it to grade scope? Yes, the exams will be submitted to grade scope. All right. And so what I was just saying about if we, the scale may be relaxed, but it will not be made more stringent. And then I'm writing this because I sometimes receive these requests at the end of class. I will not make a change to your final grade unless I made a calculation error. And so please do not send any requests of this nature and I will not reply to emails making such a request. And then you have the option of taking this class. If you're an undergraduate student pass or no pass or if you're a graduate student satisfactory or unsatisfactory. And I just wanted to copy down the UCLA registrar rules for what is assigned a grade P and what's assigned a grade S. Any questions. All right. So, as we mentioned before, the homework has a significant weight in this class. I personally believe that a lot of learning happens on the homework. And we will strive to give homeworks where there is a lot of learning that takes place. So, the homeworks, we try to make thorough and instructive on the flip side. They end up being sometimes a lot of work and time consuming. And so I want to give you a fair warning about that to please start the homeworks early. The upside to this is that we design the exams so that they are at a difficulty no more than the homework.

All right. So now we're recording. So I was just responding to Jerry's question, which said what before we start the project. I don't recall the exact week off the top of my head, but it's around Thanksgiving and it's listed on the syllabus. So the syllabus date will be the date that we release the project. And it'll be equivalent to about two ECU 102 homeworks. All right. Okay. So are there any questions that people had about this example brain machine interface system from last lecture since I know we ended while we were talking about it? All right. So we'll go then to some other examples building off of this idea. And so if you can control a computer cursor on the screen, you can bet you can also control a robotic arm. So I'm going to show you a video here. What's happening is just like for a computer cursor, what you're doing is you're controlling the 2D position of a cursor on the screen.

You can also generalize that to control the 3D position of a robotic arm. And so what this participant here, Jan, which I'm not Jan, a capy, what capy is thinking about is she's going to be controlling the 3D endpoint of this robotic arm. It turns out that this arm is fairly complex. You can see it has several joints and angles. She's not controlling those joints and angles. She's not thinking I want to have the angle, have the first 20 at 45 degrees in the second joint, the BS 7 degrees. She's not thinking that she's only thinking about the 3D endpoint. And this is actually something reasonable because when you think about how we move, we are in thinking I'm going to move with my elbow at, you know, a 90 degree angle. We think about the endpoint that we're trying to reach to and the biomechanics of our arm takes care of the rest. And so that's kind of the goal for this, that is the goal for these robotic, very machine interfaces as well, which is that we would decode the endpoint. And then a biomechanical model to solve all the inverse kinematics of what these joints should be. There's going to be one more thing she controls in here.

So just like in the keyboard example, there's a click signal to select the target. In this example, there's also going to be a click signal or a binary signal, except it's not going to select the target, it's going to rotate the hand so that she can drink from the bottle. So let me go ahead and play this video. Sorry, I'm not sure. You can see she controls her water gun to bring the cup of coffee to her. And then she's able to drink some. All right, in the video, so at that point, I said, when it bit longer, you would see the completion of the trial. And she has this big smile across her face, because this was one of the first times that she was able to drink from a coffee cup without needing someone to directly hand it to her. Any questions here? All right, so in another example of the robotic arm. So the video that we just showed you is from a clinical trial called the Brain Gate Clinical Trial. It's part of Massachusetts General Hospital in Boston, as well as Brown University. And now they have sites also at Case Western and Stanford University. There's also another clinical trial at the University of Pittsburgh.

And that's going to be the topic of this 60 minutes segment with Scott Pelley. So I'm going to play the news clips that that aired on 60 minutes with respect to a robot controlled brain machine interface here. More than 1300 Americans have lost limbs on the battlefield. And that fact led the Department of Defense to start a crash program to help veterans and civilians by creating an artificial arm and hand that are amazingly human. But that's not the breakthrough. We don't use that word very often because it's overused. But when you see how they have connected this robotic limb to a human brain, you will understand why we made the exception. To take this ultimate step, they had to find a person willing to have brain surgery to explore new frontiers of what it is to be human. That person would have to be an explorer with desperate need, remarkable courage, and maybe most of all, a mind that is gained. All right, so that's the intro. And then we're going to go on to now the clips from their clinical trial. And so this participant, her name is Jan, and actually the person screwing in the circuitry that connects to her, her, her electrode array that records signal from the brain. That's one of the leads of the clinical trial, Jen Collinger. Plugged her brain into the computer, and this is what we saw. So I can move it up and straight down and left and right and diagonally. I can close it and open it and I can go forward and back.

That is just the most astounding thing I've ever seen. Can we shake hands? No, really. Yeah. Like, come right over here. Yes, you can. Okay. Oh, my goodness. Wow. And I can do a fist bump that you like. It's amazing. What are you doing, Jan? What's going on in your mind as you're moving this arm around? What are you thinking? Okay, the best way to lay is raise your arm. Uh-huh.

What did you think about and he did that? Well, not very much. I do it all the time. It's not a matter. Is that hard work? Are you having to concentrate? All right. So with that video, I want to highlight a few things. First, you can see that she could move the robotic arm. Through the space, she was able to open and close the hand and even give. Scott tell you a fist bump. Interestingly, um, Scott tell you asked her, what are you thinking about when you. When you when you move the arm and her response was essentially, uh, I don't really think about anything. I'm or I'm naturalistic.

Like I think about or like when you raise your right arm is something that haven't automatically and that's the goal of boy, you won't bring machine interfaces that your limb would be controlled in a similar way to how you would have controls your native arm. So your robotic limb would go up when you want to move, when you want to move your native arm up. And that's called a biomatic brain machine interface. A biomatic because it's exploring the same types of, uh, motor commands that would have originally moved your arm. And so they can fully these things should be relatively naturalistic. That's the goal at least. Okay. Any questions here? All right. So this project is one of is also was also later funded through funds made available by President Barack Obama's Brain Initiative, which has been really critical for research in this area.

And there's a picture you can Google it up from this clinical trial of another participant doing the same fist bump thing with President Obama. And that's I think really cool. All right, I just to also convey that there are really interesting problems that come up with brain computer interface control or brain machine interface control. Here's another video that you might find interesting. Help with some of the things that Jan has trouble with. Okay, for example, sometimes when she looks right at an object, she can't grab it. Okay, I went to take the cone away to go ahead and close it. Sure. So that's the cone away. There's no problem. But as soon as I put the cone there, she can't do it. Why is still a mystery. All right.

And so yeah, this is a very interesting observation that she has no problem opening and closing the fists of the robotic arm. However, when there is in particular a red cone, she struggles to grasp it. I've seen some talks and talk to the postdocs who are involved with this study. And they did an analysis and it's interesting when she sees the red cone. There is a large change in the firing rates of neurons in her motor cortex. And because something very special about this red cone or not special, but something different about this red cone causes her neurons to fire so differently. That throws off the decoder and that's why she's no longer able to grasp. To try to achieve the support, they also book a virtual and reality environment where they showed her a red cone in the virtual reality environment. And even in that environment, she still had this big change in firing rate that caused her to not be able to grasp. Any questions here? Yes, pressure. Was that was she only unable to grab the red cone because she was able to shake the guy's hand. That's kind of an object to look at.

All right, we're starting our office hours now. Hi, Professor. Hi, hi, Chris. Hey, um, I got a little bit confused in the last graph that we talked about in lecture just now. Okay. The one with the introduction of the plus. All right. Ion channel, I just wanted to clarify a few things. Yep. First of all, is there a reason why we use that negative 65 millivolts as our resting potential, or sorry, not our resting potential, our resting voltage because like in an actual neuron you have both K plus and NA plus?

That's correct, yeah. So let me pull up this slide right now really quickly too, so that I can just make sure that we're all looking at the same thing. So I'm going to bring up this slide here, and then I'm going to share my screen. All right, so I think Grace, you're talking about this slide, right? Yes. Yeah, so, and your question was, is the reason that we have the negative 65 millivolts due to the introduction of sodium into the mix right.

Yeah, so I'm looking at this chart we see that k plus is minus 75 for equilibrium potential so if only k plus was there, the equilibrium potential would be minus 75. If only NA plus was there, then the resting potential would be plus 55. Now, when K plus and NA plus are both there, the resting potential is gonna be in between these two numbers because K plus is gonna pull it down to minus 75, NA plus is gonna try to pull it up to plus 55. Why does it end up at minus 65? Is that essentially what happens is that it's going to be a weighted sum of K plus equilibrium potential and any plus and the weight is going to be based off of how permeable.

The channels are to K plus and plus. And so because at rest, K plus ion channels. There are many more of them at rest and plus. than any plus the weight of K plus is going to be much higher and so that's why it ends up being closer to minus 65, then to like say, minus 35 or plus 25. Okay, thank you. And, and really quickly, we'll talk about this, the equation that tells you this would be Goldman's equation. And, and, as I mentioned briefly in lecture, the PK is going to be much higher than PNA at rest and so that's why the K plus terms will dominate what the overall voltages and it ends up coming out to negative 65. Okay. Thank you. And then one more question was the increase like that, like that little red line that increases between B and C. I'm still not understanding why that increase happens. So is it because we have less positive ions outside because of the introduction of the NA plus ion channel. That's correct. Yes. So I'm going to put a negative charge in at minus 75. When I introduced this, and a plus channel and a plus float into the cell so now there's less positive charge outside the cell and more positive charge inside the cell, meaning that the voltage is going to go up. Because I mentioned the voltage from inside to outside the cell and I put more positive charge inside the cell.

charge internally will also, I guess, we can electric field. That's correct. Yeah, and that's why the. And that's why in the picture they go from like three plus signs here to just two plus signs to indicate there's less positive charge outside and I get therefore since the voltage is at the voltage was at zero, there would be no electric field, the voltage has gotten closer to zero so the electric field is weaker. Okay, and then the, sorry, the blue, is the blue line the electric field? The orange line is the electric field. Okay. The orange line is the current due to the electric field. Okay, got it. Thank you. Great. Thanks for the questions. Professor. Yeah. Hey, Brandon. Oh, I should also mention something I just looked it up, grace as to because you have the question about the Ion channel that I didn't know the answer to. And the reason why it's called hydration is because this gap is too narrow for it to pass with this waters of hydration, not because of the hydrophobic forces. Okay, thank you.

And then sorry Brandon you're saying something. Yeah. Do you think you could just scroll up and I can probably find the thing. Yeah, sure. Right there, 21. 21. Yeah. So, I was just curious. We know that the outside is more positive compared to the inside, right? Correct. And then, so, is there a preference as to why we define VN as the inside of our cell versus VNS outside.

Like when I was first seeing this, I thought it would be more natural to have like the VNB associated with the positive side. No particular reason, just convention in the field. So whoever first measured these, put their positive electrode inside the cell. And so since then we've all been defining it going from inside to, excuse me, inside to outside. If we were to just reverse everything, everything would be consistent, but all the signs would just be negated.

Right. So is this basically for all aspects of bioinformatics and biology where we always take VN as the inside of our cell, like by convention? I don't know about fields beyond neuroscience and how they, what conventions they define. I would guess that they use the same conventions as in neuroscience, which is the field that uses the most electrical engineering in terms of cells.

Okay, yeah, I just wanted to clear up on that convention. Thanks a lot. Yeah, yeah, of course. Professor, can I ask about the previous figure, the figure on the page 34? Yes. For the, so the C is a steady state as compared to the change at the figure B, right? Sorry, I was scrolling. I missed the first part of your question. Can you repeat that? And the C is T equal one second, you mean that is a steady state. After the be right. Um, so, in this, in this drawing it is a steady state.

It's just a view of it. One second later, but it ends up being. It ends up being this is ends up being the picture of the steady state, because of this opposing na plus k plus pump which we'll talk about next lecture, but essentially, this pump is going to let me get my annotator. And there's going to be one more thing here, called the pump. And the pump is going to push out any plus. And it's going to push in K minus, sorry K plus. And so for that reason, the concentration gradients are going to stay the same such that this arrow, always stays the size. So this is a picture of the steady state, but it's only the steady state when you also consider this, this NA plus K plus pump. So the chemical driving force on B and C are for the last channel. Like should be in the same lens right for the figure. The blue, the blue arrow. It seems like the part C is longer. I don't know. Maybe it's just a mistake. Oh, I see what you're saying. Yeah. Like this arrow looks a bit shorter than this arrow, right? Yeah. I think you're right. It is shorter. It should not be shorter. It should be the same length, right?

All right, everyone, we can go ahead and start office hours. Please raise your hand if you have any questions and then I'll call on you to unmute yourself. Alexandra. I was wondering if we could go over number two. Should we go over number two from the top? I think I get part A. I just want to make sure I'm interpreting the diagram correctly and then from there on. I'm not sure how to deal with the complex exponential in terms of graphing. Yeah, okay, sure. For the complex exponential in terms of graphing, I think that we may have given, we gave that hint to approximate as one plus j omega t and then for the j, you can just approximate it. You can draw it on the graph as it dotted line, but we'll get into that. People write in chat if you want me to go, actually, you know what, we'll just do number two from the top. All right, thanks for asking me the question.

Alexandra. Okay, so for number two, it says to write an expression for F of t, which is our sampling function and what we ought to see is that this sampling function is non-uniform, but it's non-uniform in a consistent way, which is that the impulses that should happen at odd samples, like negative three, negative one, one and three, are all shifted by some amount to tau. All right, so I'm going to draw this as two different impulse trains. I'm going to have the even ones I'll draw on purple. One, two, three, negative one, negative two, negative three. So the even ones are on the integers and then the odd ones I'll draw on this blue are shifted by some amount tau. All right, so if someone who did this question either unmute or are all right in chat, you're approached to write out this function as two uniformly space sampling functions. Sure. So the even ones are, well, the way it is, we can represent even number as like two k.

So for the even least space samples of, by even, I mean like on even numbers, we can represent it as a sum of delta of t minus 2k and then k is the whole range of integers. And we can represent an odd number as 2k minus 1 or 2k plus 1 or any 2k plus minus an odd number. I just used 2k minus 1, I think. So in that case, we would, I used, I wrote delta of t minus and then in parentheses, 2k minus 1 plus tau. Great. Great. Yeah, so that's, that's correct. Thank you, Eric, for that. So this is correct and then we have the plus tau because all of these blue impulses are delayed by tau. So we need a minus tau in here. And so that's what we get from this expression that Eric wrote for us.

So this is correct. I'm going to use the short hand notation that we have from class that we could write that this here is a delta with a subscript 2 of t. And then this one, I can write as a delta. And so the subscript is still 2 because all of these blue ones are evenly spaced by 2, right? And that's what Eric had with this 2k minus 1. So we'll have a 2. And then now all of the delta's are shifted by, so if I just had a delta of 2t, the blue impulses would be on 0, 2, 4, etc. But they need to be at 1 plus tau. So it would be a 1 plus tau here, right? So if you write either Eric's representation or, or this simplified notation representation, those are both correct. And so this would give us that f of t is equal to delta 2t plus delta 2t minus 1 plus tau.

All right. Any questions on part 1? All right. So if you have questions for number 2, just feel free to unmute yourself and ask them. All right. Let's go on to, let me write that this is 2a. All right. So then 2b says find the Fourier transform, big f of j omega, right? And so this one is fairly straightforward if we've gotten 2a correct. So can someone unmute and tell us how you did, or what was your thought process in doing 2b? I guess let me do the first part, which is that we know that the Fourier transform of delta 2 of t is going to be, well, we know that in general delta big tt is going to be omega not delta omega not omega. And so for delta 2t, omega not is going to be 2pi over 2, which is just pi.

So it's going to be pi, and then delta pi omega. All right. So that's for the purple one, and then what happens for the blue one? I think Professor, we can just multiply the same pi delta pi omega with e to the negative j omega times 1 plus tau. Yep, that's correct. Thank you, Brompton. So that gives you then your answer. Your big f of j omega is just going to be the sum of these two. Any questions on 2b? Yeah, Professor, I had a question. What is that? I got confused about which omega that actually was on the e to the minus j omega? Yes. This omega is the frequency variable.

So it would be the x axis of our spectrum. Okay. I'm going to get the delta. Because if we wrote the delta train out as a summation, we'd have delta of omega minus k pi, right? So then would we say that omega on that exponential would be k pi if we were writing it in some machine notation? I knew our correct. Yeah. So yeah, so it makes for pointing that out. Daniel is giving you a further simplification, which is this impulse here is impulse train. The delta pi omega is you can view it as sampling this exponential. And so Daniel was saying that you could further simplify this as a pi. These impulses are delta omega minus k pi e to the minus j omega 1 plus tau. And because the omega occurs, the impulse occurs that, sorry, the impulse occurs that omega equals k pi.

This simplifies to a k pi in the numerator. Oh, I see that works because it's of the shifting property then. Correct. I just have to think about it. I wasn't sure if it would work and why, but I think I see it now. Thank you. Great. I wonder if that's actually a further part of the question. Yeah, this is actually, oh, you know what? Sorry. So yeah, for 2b, I shouldn't have stopped here. We researched simplified according to what Daniel, Daniel brought up. So let's go ahead and do that. So we're going to take these 2 impulses and I'm going to carry over this work to the next page.

Thank you. All right, everyone, we're going to get started for today. So, our first announcement is that homework number seven is due this Friday, uploaded to grade scope. And as we've announced for this homework questions four or five and six which are on the plus transform and inverse Laplace transform are graded based on effort. And any attempt that you make on the question will give full credit to you. In that sense, we want you to think of these questions more as practice questions for the final sensible plus transform. And this inversion is fair game on the final. And then earlier today, we sent out an announcement on CCLE and Piazza on the final exam logistics.

So, first, Tonmoy is going to be holding a review session this Sunday, December 13th, from 2 to 6pm, and I highly encourage you to attend that review session by Tonmoy. Tonmoy also increased his office hours during final exam week. And I made a mistake in the initial announcement.

For his Wednesday office hours, I wrote it was from 9 to 11 p.m., but of course, that's after the final exam. That should read 9 to 11 a.m. And so I've corrected the announcement on both CCLE and Piazza, but these announcements were also emailed out. So I just want to make sure that that correction is clear, that on Wednesday, the day of the final exam, Tom Boyd will have office hours from 9 to 11 a.m. All right. The logistics of the final exam are going to be very similar to the midterm exam. First, the final exam is Wednesday, December 16, 2020, from 3 to 6 p.m. We are going to upload the exam to CCLE at 2.55pm, again to give anyone who wants to print out the exam some time to do so, although you're more than welcome to do the exam on a separate sheet of paper. And then the exam must be completely uploaded to Gradescope by 6.10pm, so we're giving you 10 minutes after the conclusion of the exam at 6pm to scan in your exam and assign all of your pages by 6 10 p.m.

All right, even though we're giving you until 6 10 p.m. to submit the exam, you're not to work on the exam after 6 p.m. Pacific Standard Time. And then the portal closes at 6 10 p.m. and so be sure to get in your exam before then. If you're a student in another time zone, in the exam announcements, I sent out the instructions for emailing me about your availability so that we can schedule your alternate exam time. And then just like on the midterm, the TAs and I are going to be online at this Zoom link to take any exam questions. This Zoom link will have the waiting room enabled, meaning that when you first click on the link, you may not be admitted into the room. So we take questions from students one at a time. And then after a student finishes, we'll admit the next student from the waiting room.

All right, so I want to pause here and ask if there are any questions on final exam logistics or homework or any other class logistics. Alright, great. Sounds like there are no questions so we're going to get back into material then. And then we will then address Laplace transform applications. All right. I see a question in chat saying how many questions will there be on the exam? We can't disclose that information, but the length of the exam will be will be comparable to prior years and the prior years as final exams are all on CCLE. I should say the exam length will be comparable to or shorter to prior year since we also recognize that this year. There are extraordinary circumstances and online teaching. Okay, so So in the lecture we had talked about how we had talked about the Laplace transform and several properties.

And then we had also talked about how, if you have any general differential equation, or this expression over here. going to be equal to this quantity here, which is a rational fraction. The numerator and denominator are both polynomials in S, and therefore it stands to reason that we have to know how to deal with these expressions and simplify them so that we can invert these Laplace transforms. So that led us to this thing called partial fraction expansions, where we said we could take a rational fraction where we have ratio polynomials and we could reduce it into a bunch of roots of A of S, the denominator here, and the numerator has a constant which is called a residue. So we said that this rational fraction can be written as this partial fraction expansion, and we were in the middle of doing the partial fraction expansion in the case where n is less than n.

This constraint means that the order of the polynomial in the numerator is strictly less than that in the denominator. And then we had talked last time about nomenclature, namely, A of S and B of S has m roots, which are called zeros of F of S. A of S has n roots, which are called the poles of F of S. And the poles are denoted lambda 1 up to lambda n, since we have an nth order polynomial, we'll have n roots. And then these numbers are one to rn are the residues. Any questions on this recap thus far. because it's easy for me to invert this Laplace transform. All of these are the inverse Laplace transform of 1 over s minus lambda, and we know from our Laplace transform table that the inverse Laplace transform of 1 over s minus a number is just e to that number t. So in the case where F of s has no repeated polls and m less than n. Our solution is going to be some sum of exponentials.

And then to get the partial fraction expansion we said that there are two steps first we need to find the polls, which means finding the zeros of the denominator of the best, which is a of s, and then after that we have to find the residues. So, getting the polls lambda one to lambda and all that is is solving for the roots of this equation. Right. But then the new thing that we have to do is be able to solve for the residues are one to our. And so we gave three methods to do this. And we're going to get back to these methods today so we started off by saying there's a method one which is typically labor intensive and we won't do it. And method two is the most commonly used method which is called the cover up procedure. Right. And so, in the cover up procedure. We went through this a bit more slowly today because this is the technique that you'll most frequently use when inverting the Laplace transform. of s factored into its form such that we have our three poles lambda one, lambda two, and lambda three. And then this is equal to three partial fractions each with the residue r1, r2, and r3. All right, so the idea behind method two is that to solve for one residue, let's say r1 term. But it's going to cancel out with one of the s minus ones in the denominator and so these two terms are going to cancel out. But now for R2 and R3, they're also going to be multiplied by s minus lambda one.

All right. So I have a question about part F and part G of 12 and 2. Okay. I have a question in general about some simplifications that I'm not sure I can do. Okay. So in part F where we're trying to see if B is independent of C, I'm able to isolate out C. So like from the probability of B and C, I say, I do the joint distribution, summing over all of A and D. And then once I go through all of that, I can take C out. And A given C just factors out as probability of, as one because it's law of total probability. But my question is I get like a summation over A, a summation over D of the probability of B given A, D. And so if we're summing over everything that's given, can that become probability of just B? So in general now, although we have extra terms in there, but a P of B given A, a, D summed over A, D in general only equals P of B when it's P of B, A, D. And so, in general P of B given A, D summed over A, D is not equal to P of B. But then, sorry, let me get my idea. I should have done this before, once I get it. So let me just connect my idea so we do have, and then make sure that everything is consistent.

So for 2F, I mean, you said that you had factorized how the key of C is, and you had a key of C, right? And then the summation of A for probability of A given C just goes to 1, right? That's correct. You had something like this. Yeah. Okay, and you had some over D. Yeah. So P of D, probability of A given A, D. Yeah. Great. All right. Oh, yeah. Okay. Then if you had the set, then, then, then, then you are good. Sorry. I think I misheard you earlier. So then that would just go to A given C just goes to 1, and then, probably, of D goes to 1 also, right?

Or do I have to use that for the chain rules? The thing is, you can't, sorry, you are generally correct that some over A of P of A given C will go to 1. Yeah. But in this case, it doesn't simplify nicely because P of A given C is still multiplying this expression here. So we will have a question. Yeah. I didn't know if I could separate that up or not. Yeah. So sorry. I'm writing it out, hopefully. So we should have a P of A given C, a P of D, and then a P of B given A and D. Okay. Yeah.

And it's because there are two, like, there's, it would be an A multiplied by an A probability. Yeah. There's another, yeah, there's another A here. So then from this, I have to do the simplification from there. Exactly. And then, but this, at this stage, you're pretty much done because we know that for this to simplify to P of B, this is, if we have, we need a sum over A, a sum over D of P of B comma A comma D. And in general, this does not simplify to that. So P of D times P of B given A, D, that would give us a P of B comma D given A. Yeah. Oh, sorry. No, that's not even true. Because it's not D given A. So actually, in general, this does not, and so you can say, and you can write some text arguing out why that isn't the case.

And then that's sufficient for this question. Okay. I see. So that answers my next question because I got to that place for part G, where it was this sum over D for P of D times P of B given A of D. And my question was, can that simplify to probability of B given A, and I don't think it can, right? It can, yes. So for that one, that is law of total probability. So if you have, can you repeat the sum that you have? I had sum over D of probability of D multiplied by probability of B given A comma D. B given A comma D. So can that simplify to probability of B given A? This one cannot. You would need of, if this was, if this was D given A, then this would equal sum over D probability of B comma D given A. And then this would simplify to probability of B given A.

Okay. However, we do have, this is for 2G, right? Yeah. And 2G. So I did show you row first and then I went to the joint probability over D. Yeah. And then I took out all the probability of C times probability of A given C from the ratio over D. But so then I'm left with, yeah, with what you wrote down in the first line. You're left with a, you're left with this. A is probability of B, yeah. Yeah. The probability of B given A comma D. Yeah. Yeah. So sorry, let me just look at the solution because that's the first step that you do also, but then they incorporate a probability of B given A. So let me just see how we get that.

Is it because V and A are independent and we've already shown that so it was a model? That could be the case. Yes, it is. Thank you. Okay. Yeah. So in part D, we showed that A and D are independent. And so actually this upper one would also simplify to P of D given A. So you can make an argument there. Yeah. So that's the case, P of D and P of D given A are the same. And so it doesn't define this way. Okay. Okay. So then that's how I can go to P. Okay.

Perfect. Yeah. Yeah. I have another question. All the other people ask and all circle back around. Sure. We have a good number of people here. So maybe we could do the race hand system. So if you have a question, you'll be the razor hand and then we'll just take them in order. So we can do that. Okay. So my question was also on 2F. I was wondering when we're simplifying probabilities. I got like the sum over D of P given A, D times P of B. And I was wondering.

Sorry, Rhett. I'm just going to write the answer that I know exactly. Can you say that sum again? The sum over D of P of D given P of B. Like sorry, P of D times P of B given A D. And I know that when we have two variables, we can say like the sum of P of C times P of A given C is like equal to P of A. Absolutely. If we could analogously do that for three variables and say that like P of D times P of B given A D summed over D is equal to P of B given A. I see. So in general, the expression for P of B given A written as a sum over D would be a sum over D of P of B comma D given A. And so when we do the summation for the law of total probability, we can think of that as taking out a variable that is in front of the conditioning sign.

All right, everyone we're going to get started for today. So the only announcement that we have right now is that homework number six was released last week, again, and last week. And it's going to be due nine days from today on June 2, 2021, uploaded to a grade of scale, all right? Any questions on any course logistics? All right, so we'll go ahead and continue where we left off last time, which was we were now going to derive the comment filter. So last lecture, we spent time discussing the intuition of the comment filter and how essentially it's using information from two sources of information, a state update process, which is this xk equals axk minus one equation, as well as the neural data and its relationship to kinematics, which is this yk equals c times xk equation, right? And so we talked about the intuition of that and we presented the comment filter solution and saw that it made intuitive sense on a few simple scalar examples, all right? So now we're getting into the comment filter derivation and that's where we're going to resume today. So a few things just to remind you of that we had these a few preliminaries. We had that if y and x are random vectors and they're linearly related like this, that the expected value of y is a times the expected value of x plus b. And the covariance of y is a times the covariance of x times a transpose, all right? And then we also had talked about Gaussian random vectors and these were these random vectors where they're jointly Gaussian and they can therefore be written in this form where the random variables, which are elements of this vector, they all have some means and then some covariance matrix. And the facts that we talked about last time were if I were to marginalize over this random vector, so say I have this random vector with x1, x2, x3, but I just wanted the distribution of x2. So I marginalize away x1 and x3 via my law of total probability, right? If I do that, then x2 is a Gaussian random variable with mean u2 and variance 4, all right? And if I want to marginalize, so I'm just left with x1 and x2, they would have mean 1, 2 and then this covariance gets in by this block here for the 1 and 2 indices. So marginalizing over this Gaussian random vector results still in a Gaussian random vector. If we have linear functions of Gaussian random vectors, they remain Gaussian. And then this one, which again, we'll talk about in more detail if we get to it today, which is if we condition with a Gaussian random vector. So if I have a Gaussian random vector where I'll split up this elements into two components, x1 and x2, then x1 given x2 and x2 given x1 are also Gaussian.

So the facts of this Gaussian random vector are marginalization, linear transformations and conditioning. When you do these operations, the output is still Gaussian, right? Were there any questions from any of the preliminaries? So Jonathan, I have a question. Yeah, Tom White. So for fact number three, it will also hold if we like if we have a like say an dimensional joint leg Gaussian and we condition any subset on another subset, it will still be joint leg Gaussian, correct? That's correct. Yeah. And x1 and x2 here are vectors. And so let's say that the overall x was 10 dimensional. x1 could be 6 dimensional and x2 could be 4 dimensional or x2 could be 2 dimensional. Essentially, when you condition some of these random variables on the other ones, the result is always Gaussian. All right. Thank you. Thanks for clarifying that, Tom White. All right. So, okay, let's get to our proof then. So last time we had written out our dynamical system with the following assumptions, the noise terms WK minus 1 and QK, they are Gaussian noise and they're independent, which means that at every single time step, I'm drawing new noise, okay? And then last lecture, we had asked this question, if x0 is Gaussian and we have the state update equation. So x0 being Gaussian means that the first initial state is Gaussian distributed and downstream states, states later on in time will also be Gaussian distributed because they're linear transformations of a Gaussian random vector. So if we have xk equals axk minus 1 plus WK minus 1, I asked what is the distribution of xk given xk minus 1? All right. And we deduced last lecture that it would be axk minus 1 and as the mean and the covariance would be W. All right. We saw that because if xk minus 1 is given to us, right? A is deterministic, xk minus 1 then becomes deterministic because we observed it. And then WK minus 1 is zero mean noise. So the overall mean of this expression is going to be a vector, a times xk minus 1 that we observe plus some noise with zero mean. And so the mean is just going to be the deterministic part axk minus 1. All right. And then axk minus 1 is observed, it's deterministic. So it doesn't have any randomness associated about it. And so the only randomness in xk given xk minus 1 would come from this noise term WK minus 1. And WK minus 1 has covariance matrix big W. All right. So that leads us to conclude that xk given xk minus 1 has this normal distribution. All right. Any questions there? All right.

And so we did do something similar for YK given xk following the exact same logic. We found that YK given xk has a normal distribution with mean dxk because cxk is observed. And then the randomness in this equation, if xk is observed, now only come from QK and QK has covariance q. And so that's the covariance right here. All right. And then we were also going to, for convenience, just say that the initial state x1 was also normally distributed with mean new one and covariance v1. All right. So the first thing that we wanted to do now in our common filter setting is train the common filter or train learn the parameters of my system, a w, c, and q that maximize the likelihood of the data. And so what we did, what we started to do then is we want to write the likelihood of the data, which is a probability of having observed my kinematics and my neural data at every single time step. And then of course, this will be a function of data. And I get to choose data. I get to choose data to make this likelihood as big as possible. All right. Any questions on this part of the recap? All right. So then we start to write out the log likelihood last time. So we drew off the graph of the dynamical system where we have our states, the kinematics evolving through time. And at every single point in time, there is this observation process, the yk equals cxk, which lead xk to be a parent of yk. And we know based off of the graph theory lecture that if I want to know the distribution of say x4 given x3, x2, and x1, we know that x4 is going to be conditionally independent of anything before x3 given that I observe x3. So we were able to write that p of xk given xk minus 1, xk minus 2, all the way to x1 equals p of xk given xk minus 1. And also p of yk given all the prior states as well as the prior observations. So the prior kinematics and the prior neural data, this is just equal to p yk given xk for the same exact reason, which is let's say equals 3. And I want p of y3 given I know x3, x2, y2, x1, and y1. But everything here is conditionally independent of y3 given that I observe x3. Okay. Okay, any questions there?

Sorry, sorry, I have a question. So when we see that yk given xk through xk minus 1 up to y1, right? So is equal to probability of yk given xk. So is xk capturing all the information that has happened in the past? Yes, that's correct. Thanks, Tomway. So xk is capturing all the information in the past about x1, x2, y1, and y2. So said differently, the reason that these are this conditional independence implies that all the information from x1, y1, x2, y2 is stored in x3. And therefore, if I know x3, knowing any of these prior, knowing any of these variables that were passed in time, doesn't give me any more additional information about y3. So all of the information from these variables is summarized systemically in x3. Right? And then a question to chat, what do xk and yk represent? Here xk are going to be our kinematics. So that's going to be the velocity of a computer cursor. And the yk is going to be our neural data. I remember then this equation tells me how, or I can model things like the inertia of the cursor that the velocity at time k minus 1 has some information about the velocity at time k. Because, for example, when I move to the right, if I'm moving to the right at a high speed, my velocity at the 200 millisecond pointing to the right implies that at the 225 millisecond, I should still be moving to the right. So this is the thing that captures inertia. And more generally, to capture any laws of physics or temporal structure in the data. And then this equation here represents how the neural data relates the kinematics and the neural data relate to each other.

All right, happy to start off anywhere. Yeah, Link's here. Okay, so I actually have a question about a lecture. I can really confuse about the Q and W matrix. I assume they are similar. So I'm just confused about first, why is this symmetric? It's one of my problems. And basically, I know that in lecture, we discussed about how we can just ignore the W matrix because somehow we average them out. Essentially, and then we have xk equals to a xk minus 1. I just would like to know, like, what's the reason behind it? Yeah. I think I'm just like wanting to do like idea about it. So that's basically, I'm just really confused about how the noise was set up basically. Okay, great. So first, let me wait for this to catch up.

The question is why is W and Q symmetric? It's because they are covariance matrices. So W and Q are, where's my apple pencil? Here, W and Q are covariance matrices. And so the ijth element of W is going to be the covariance between W i and W. Let me do superscript, so it's clear there. And this is the ith element of W and the jth element of W. And this is covariance itself is a, it's a symmetric quantity. So covariance of W i w j is equal to covariance w j w i. And so for that reason then, this equals w j i. And so, I'm sorry. Can you all hear me? I'm not sure if my internet connection has frozen. Hey, oh, I'm sorry about that. Can you all hear me?

Can you all hear me? Can you all hear me?

again. Okay, so, uh, Wingshee, your question was, uh, why are W and Q symmetric? Uh, and that's because the covariance operator is symmetric. Um, so I'm not sure how much of that answer came through before my internet cut out. Uh, is that all good? Yeah, but uh, it's a little bit laggy, but I know what you're talking about. Okay, and yeah, so can we go on to explaining the, uh, why can we ignore it in the expression we have in here? Yeah. Yeah, great. So, uh, for the, uh, this question is why, why when we derive the least squares solution, we can, uh, ignore the effect of W. And sorry, I think it's frozen again. Okay, okay, I think it's back now. Okay. Um, I, I'm so sorry, everyone. Uh, I think on Wednesday, I'll, I'll try, uh, I'm in a different internet situation right now and, um, and I'll try to make sure this isn't a problem on Wednesday.

So, for, why can we ignore the effect of W? First off, for the, okay, I'm going to turn off my video. I think that, that, we'll hopefully help with the lag. So, um, I'm sorry, I need to do one more thing. Okay, can people hear me? I guess, very clearly, way better than with the video. Okay, great. Okay, let's go with this for now. So, uh, why can we ignore the W? Um, so first off, for the maximum likelihood solution, we didn't ignore the W at all. And so, uh, first off, that solution requires no assumption. So, ignoring the W was really a consequence of, um, the least squares, uh, intuition. And so, uh, for that intuition, the way that I would think about it is as follows. Um, will WK in the end cause a change in my regression?

And so, um, I, um, I would like to draw. I'm going to just try this one more time, because it's going to help with the explanation. If it doesn't work, uh, I will give up on, on trying to share my screen. Uh, I'm glad that, that the problems are happening now and not during lecture. Um, okay, so hopefully, okay, so, okay, I think things are potentially working. Um, why can we ignore W for the intuition sake? So, the, the picture I have in mind here is the following. What I want to do is I want to get a regression between xk minus one and xk, right? And, uh, there are going to be data points around here.

So, let's say that I had, um, data points that look like this, right? Then my least squares regression would give me a line that goes to these cut of points. Now, WK is going to be zero mean noise. And so, if I were to now take these points and perturb them by adding the noise to them, some of them would go up, some of them would go down. But on average, the effect of, of these perturbations WK to all the data points has a zero mean average. And so, um, if there isn't any, um, uh, for example, if WK had a mean of one, all of these points in general would shift up and that would change the regression line. But because WK has a mean of zero, when I average across many data points, that isn't going to change my overall new slope here.

The slope is still going to, in the end, uh, be the effect between xk minus one and xk. Does that help with the intuition? Okay. Oh, yes. Uh, that helped a lot. And, uh, yeah, I think I'm clear on why, why we can't just, you know, in our least square solutions. So, uh, one last quick question. It's a clarification. Okay. So, at the end of the class, we have this curve, which is the probability of xk given xk all the ways to yk, right? Yeah.

So, is that a normal distribution? Like, or is it just a shape like a normal distribution? Great question. So, uh, it turns out that when we compute this distribution, it will be a normal distribution. And that's, that's because of, um, this, um, this, um, that if we can, addition on a Gaussian random vector, it produces a Gaussian random vector. So, we haven't get proven why it's going to be Gaussian, but it ends up that it is going to be Gaussian. And we'll prove that next lecture. Yeah, gotcha.

Yeah, that's, that's all my questions. Thank you very much. Thanks, thanks, too. All right, hopefully internet has stabilized a bit. If it ends up being bad again, can someone, uh, please let me know. And then, um, and then I will try to reset things. I have a question about the homework. Great. I'm just trying to sanity check, uh, my answers. Okay. And I got, for the means for error, for the optimal linear estimator, the weiner filter, I think I have pretty much the same number. Okay.

Um, I don't think that's. Uh, sorry, me. I, I broke up. I don't think that's correct. Yeah, that's all I said. Okay, got it. Uh, okay, let me, uh, let me, sorry, let me just pull up the homework. All right. All right. So, um, is this for, uh, notebook number three? Yeah. So it's, yeah, for three C, it says calculate the means for error. I got a certain number. Yes, it says does it do better worse than the optimal linear estimator?

And it's like almost the same number. Um, I'm going to pause the video for a moment so I can just talk to you about the numbers.

again. Okay, so, uh, Wingshee, your question was, uh, why are W and Q symmetric? Uh, and that's because the covariance operator is symmetric. Um, so I'm not sure how much of that answer came through before my internet cut out. Uh, is that all good? Yeah, but uh, it's a little bit laggy, but I know what you're talking about. Okay, and yeah, so can we go on to explaining the, uh, why can we ignore it in the expression we have in here? Yeah. Yeah, great. So, uh, for the, uh, this question is why, why when we derive the least squares solution, we can, uh, ignore the effect of W. And sorry, I think it's frozen again. Okay, okay, I think it's back now. Okay. Um, I, I'm so sorry, everyone. Uh, I think on Wednesday, I'll, I'll try, uh, I'm in a different internet situation right now and, um, and I'll try to make sure this isn't a problem on Wednesday.

So, for, why can we ignore the effect of W? First off, for the, okay, I'm going to turn off my video. I think that, that, we'll hopefully help with the lag. So, um, I'm sorry, I need to do one more thing. Okay, can people hear me? I guess, very clearly, way better than with the video. Okay, great. Okay, let's go with this for now. So, uh, why can we ignore the W? Um, so first off, for the maximum likelihood solution, we didn't ignore the W at all. And so, uh, first off, that solution requires no assumption. So, ignoring the W was really a consequence of, um, the least squares, uh, intuition. And so, uh, for that intuition, the way that I would think about it is as follows. Um, will WK in the end cause a change in my regression?

And so, um, I, um, I would like to draw. I'm going to just try this one more time, because it's going to help with the explanation. If it doesn't work, uh, I will give up on, on trying to share my screen. Uh, I'm glad that, that the problems are happening now and not during lecture. Um, okay, so hopefully, okay, so, okay, I think things are potentially working. Um, why can we ignore W for the intuition sake? So, the, the picture I have in mind here is the following. What I want to do is I want to get a regression between xk minus one and xk, right? And, uh, there are going to be data points around here.

So, let's say that I had, um, data points that look like this, right? Then my least squares regression would give me a line that goes to these cut of points. Now, WK is going to be zero mean noise. And so, if I were to now take these points and perturb them by adding the noise to them, some of them would go up, some of them would go down. But on average, the effect of, of these perturbations WK to all the data points has a zero mean average. And so, um, if there isn't any, um, uh, for example, if WK had a mean of one, all of these points in general would shift up and that would change the regression line. But because WK has a mean of zero, when I average across many data points, that isn't going to change my overall new slope here.

The slope is still going to, in the end, uh, be the effect between xk minus one and xk. Does that help with the intuition? Okay. Oh, yes. Uh, that helped a lot. And, uh, yeah, I think I'm clear on why, why we can't just, you know, in our least square solutions. So, uh, one last quick question. It's a clarification. Okay. So, at the end of the class, we have this curve, which is the probability of xk given xk all the ways to yk, right? Yeah.

So, is that a normal distribution? Like, or is it just a shape like a normal distribution? Great question. So, uh, it turns out that when we compute this distribution, it will be a normal distribution. And that's, that's because of, um, this, um, this, um, that if we can, addition on a Gaussian random vector, it produces a Gaussian random vector. So, we haven't get proven why it's going to be Gaussian, but it ends up that it is going to be Gaussian. And we'll prove that next lecture. Yeah, gotcha.

Yeah, that's, that's all my questions. Thank you very much. Thanks, thanks, too. All right, hopefully internet has stabilized a bit. If it ends up being bad again, can someone, uh, please let me know. And then, um, and then I will try to reset things. I have a question about the homework. Great. I'm just trying to sanity check, uh, my answers. Okay. And I got, for the means for error, for the optimal linear estimator, the weiner filter, I think I have pretty much the same number. Okay.

Um, I don't think that's. Uh, sorry, me. I, I broke up. I don't think that's correct. Yeah, that's all I said. Okay, got it. Uh, okay, let me, uh, let me, sorry, let me just pull up the homework. All right. All right. So, um, is this for, uh, notebook number three? Yeah. So it's, yeah, for three C, it says calculate the means for error. I got a certain number. Yes, it says does it do better worse than the optimal linear estimator?

And it's like almost the same number. Um, I'm going to pause the video for a moment so I can just talk to you about the numbers.

All right, everyone. We're going to get started for today. So just to announce for today, the first is a reminder that homework number six is due a week from today. And the other is that today we're going to be doing the derivation of the common filter recursion. And this is probably the most challenging derivation in the class. And it's going to piece together a lot of things we've talked about. The derivation is challenging, so you're not going to be tested on reproducing the derivation. But when you look over the derivation, you should be able to understand every step that occurs in the derivation in terms of us knowing the facts for each step. And so again, this derivation will be challenging and you won't be tested on reproducing it. But we really do encourage you to look at the derivation and make sure that you understand every step along the way. So today we should be finishing common filter. And then if we have some time, we're going to start the last topic for the course, which will be dimensionality reduction. And we'll be discussing a technique called PCA, which is principal component analysis, and one of the most commonly used dimensionality reduction techniques. All right. Any questions before we get into the common filter derivation? All right. Question from Andrew.

I'm a question. So this is like the first finding today on common filter and then starting dimensionality reduction. What are we going to be doing during V10? I assume we won't be spending like two and a half lectures on dimensionality reduction. Yeah, that's right. So next week because of the holiday, we only have one vector after this. And so during that lecture, we will finish off PCA. And that'll be likely all will cover for dimensionality reduction in detail. But we may talk about some ideas related to how it's attached to extent PCA to probabilistic PCA as well as vector analysis. I totally forgot about the holiday. Yeah. Yeah. And in a more typical offering of this class, we do get beyond when we get the vector analysis, we also talk about the expectation maximization algorithm, which some of you may be interested in learning. And even though we likely won't get to those this year, we have uploaded those materials into the lectures tab of CCLE. And so if you're interested in looking over that material, that material is available on CCLE. And and TA tonight would be happy to answer any questions about it. All right. Any other questions? Okay. Let's recap where we were. So last week, we did the derivation of the optimal parameters in a maximum likelihood sense for a linear dynamical system. Right. So we had our state update dynamics process and our observation process.

And these two equations, they had parameters A, C, and then the covariance of WK-1, which is big W and the covariance big Q. All right. And we said if we're given neural data, the YKs and the kinematics, the velocities, the XKs, how do I take this training data and use that to learn A, C, W, and Q. And so last lecture, what we did is we did the same thing that we did in for homework number four, which is that we wrote the likelihood of the dynamical system, the linear dynamical system by writing out its graph structure and then writing out the joint probability of observing all the data given the parameters. And we saw that because of the graph structure, where there are these conditional independencies, the likelihood factorizes into essentially three probabilities, the probability of X1, which we said was going to be a normally distributed random variable. And then a bunch of products of P of XK given XK minus 1. And this had a normal distribution as well as the probability of YKs given XKs. And this also had a normal distribution. So because everything has a normal distribution, we were able to write out the likelihood and then we were able to differentiate it with respect to AC, W, and Q to get the optimal parameters. And this slide here is a summary of what that derivation was. And so we talked about if you had your kinematics data X and your neural data Y and you can catenate them for all time, then these are the equations that give you the best AW and AW, C, and Q. And that completes the training process. So I want to pause and ask if there are any questions from last lecture on the training process of the common filter parameters. All right. So now at the end of last lecture, where we left off was that we are now going to get to the testing phase. So from training, we've learned AW, C, and Q. And now I want to predict how to decode the optimal velocity or how to decode a velocity XHK given all the neural data I've seen thus far from Y1 all the way up until YK. So in homework number four, for a given trial, we just had one neural observation, which are the bin spike counts in some window. And we want to calculate the probability of every single class. And there were eight classes for eight different directions I could choose.

And so for this, we could calculate this straightforwardly. We just have to calculate eight of these probabilities and then pick the biggest one. All right. In the case where now we're controlling a continuous cursor moving on the screen, we're not choosing one out of eight classes. We're decoding a continuous velocity XK. All right. And so what we said last time we would need to do then is we would need to calculate the actual distribution of what the velocity should be XK, what the kinematics should be given all my neural data from time Y1 to YK. All right. And so that distribution could look like this, for example. And this tells me that given my neural data from Y1 to YK, I could expect my velocities to be centered around 10 centimeters per second. And there's a low probability that it's higher and the low probability that it's less than 10 centimeters per second. So likely my velocity is around 10 centimeters per second. And so this is a distribution of what my velocities will be given my neural data. When I decode, I need to pick one single value of my velocity. And at the end of last lecture, what we showed is if you have a distribution over your velocities to pick the one single velocity to decode to move the cursor, we would pick the mean because the mean is the minimizer is the one single value that minimizes the squared error of the random vector of the random vector Z or the random vector representing the kinematics. All right. So that's what we set up last lecture, which is that to go to the testing phase where I get new neural data and I want to move this cursor, what I need to do is I need to calculate the probability of the cursor's kinematics of its velocity, given all my neural data, and then my decode value will just be the mean of this distribution. So that's the setup that we talked about at the end of last lecture. Are there any questions here? Question from Grace. And today you should just be able to unmute yourself.

Okay. I just wanted to ask if you could please repeat that last portion of what you just said. Like we're calculating the probability of the cursor and like finding the mean and stuff. Exactly. So what we're doing here is for every time step k, so at a certain point in time, the time that I'm decoding right now, I'm going to calculate a distribution of what I think my velocities will be given all of my neural data. That's what this pink distribution is here. And so if my pink distribution looked like this, then I would guess that my velocity should be somewhere in the vicinity of 10 centimeters per second. And then I need to actually choose just one velocity to actually move the cursor on the string. And so the velocity that I'm going to choose is going to just be the mean of this distribution. So the decoded velocity will be the distribution mean. So I need to first calculate the distribution. And then after that, I need to take its mean and that gives me my decoded velocity. Not an other question. Yeah, coming. Yeah, so over here, they're minimizing the mean squared error and that gives the mean, right? But let's say you minimize the absolute error instead of the mean squared, then you will get the median of the distribution as the optimizer. So is there any intuitive reason behind this government filter using this mean squared error versus some other error? Yeah, it is straightforward for us to calculate the mean of, actually, it's also straightforward for us to calculate the median of the gas distribution. So actually, in this case, it would be fine to also use absolute error. And you would just need to decode using instead of the mean of the distribution, the median of the distribution.

All right, everyone. We're going to get started for today. So just to announce for today, the first is a reminder that homework number six is due a week from today. And the other is that today we're going to be doing the derivation of the common filter recursion. And this is probably the most challenging derivation in the class. And it's going to piece together a lot of things we've talked about. The derivation is challenging, so you're not going to be tested on reproducing the derivation. But when you look over the derivation, you should be able to understand every step that occurs in the derivation in terms of us knowing the facts for each step. And so again, this derivation will be challenging and you won't be tested on reproducing it. But we really do encourage you to look at the derivation and make sure that you understand every step along the way. So today we should be finishing common filter. And then if we have some time, we're going to start the last topic for the course, which will be dimensionality reduction. And we'll be discussing a technique called PCA, which is principal component analysis, and one of the most commonly used dimensionality reduction techniques. All right. Any questions before we get into the common filter derivation? All right. Question from Andrew.

I'm a question. So this is like the first finding today on common filter and then starting dimensionality reduction. What are we going to be doing during V10? I assume we won't be spending like two and a half lectures on dimensionality reduction. Yeah, that's right. So next week because of the holiday, we only have one vector after this. And so during that lecture, we will finish off PCA. And that'll be likely all will cover for dimensionality reduction in detail. But we may talk about some ideas related to how it's attached to extent PCA to probabilistic PCA as well as vector analysis. I totally forgot about the holiday. Yeah. Yeah. And in a more typical offering of this class, we do get beyond when we get the vector analysis, we also talk about the expectation maximization algorithm, which some of you may be interested in learning. And even though we likely won't get to those this year, we have uploaded those materials into the lectures tab of CCLE. And so if you're interested in looking over that material, that material is available on CCLE. And and TA tonight would be happy to answer any questions about it. All right. Any other questions? Okay. Let's recap where we were. So last week, we did the derivation of the optimal parameters in a maximum likelihood sense for a linear dynamical system. Right. So we had our state update dynamics process and our observation process.

And these two equations, they had parameters A, C, and then the covariance of WK-1, which is big W and the covariance big Q. All right. And we said if we're given neural data, the YKs and the kinematics, the velocities, the XKs, how do I take this training data and use that to learn A, C, W, and Q. And so last lecture, what we did is we did the same thing that we did in for homework number four, which is that we wrote the likelihood of the dynamical system, the linear dynamical system by writing out its graph structure and then writing out the joint probability of observing all the data given the parameters. And we saw that because of the graph structure, where there are these conditional independencies, the likelihood factorizes into essentially three probabilities, the probability of X1, which we said was going to be a normally distributed random variable. And then a bunch of products of P of XK given XK minus 1. And this had a normal distribution as well as the probability of YKs given XKs. And this also had a normal distribution. So because everything has a normal distribution, we were able to write out the likelihood and then we were able to differentiate it with respect to AC, W, and Q to get the optimal parameters. And this slide here is a summary of what that derivation was. And so we talked about if you had your kinematics data X and your neural data Y and you can catenate them for all time, then these are the equations that give you the best AW and AW, C, and Q. And that completes the training process. So I want to pause and ask if there are any questions from last lecture on the training process of the common filter parameters. All right. So now at the end of last lecture, where we left off was that we are now going to get to the testing phase. So from training, we've learned AW, C, and Q. And now I want to predict how to decode the optimal velocity or how to decode a velocity XHK given all the neural data I've seen thus far from Y1 all the way up until YK. So in homework number four, for a given trial, we just had one neural observation, which are the bin spike counts in some window. And we want to calculate the probability of every single class. And there were eight classes for eight different directions I could choose.

And so for this, we could calculate this straightforwardly. We just have to calculate eight of these probabilities and then pick the biggest one. All right. In the case where now we're controlling a continuous cursor moving on the screen, we're not choosing one out of eight classes. We're decoding a continuous velocity XK. All right. And so what we said last time we would need to do then is we would need to calculate the actual distribution of what the velocity should be XK, what the kinematics should be given all my neural data from time Y1 to YK. All right. And so that distribution could look like this, for example. And this tells me that given my neural data from Y1 to YK, I could expect my velocities to be centered around 10 centimeters per second. And there's a low probability that it's higher and the low probability that it's less than 10 centimeters per second. So likely my velocity is around 10 centimeters per second. And so this is a distribution of what my velocities will be given my neural data. When I decode, I need to pick one single value of my velocity. And at the end of last lecture, what we showed is if you have a distribution over your velocities to pick the one single velocity to decode to move the cursor, we would pick the mean because the mean is the minimizer is the one single value that minimizes the squared error of the random vector of the random vector Z or the random vector representing the kinematics. All right. So that's what we set up last lecture, which is that to go to the testing phase where I get new neural data and I want to move this cursor, what I need to do is I need to calculate the probability of the cursor's kinematics of its velocity, given all my neural data, and then my decode value will just be the mean of this distribution. So that's the setup that we talked about at the end of last lecture. Are there any questions here? Question from Grace. And today you should just be able to unmute yourself.

Okay. I just wanted to ask if you could please repeat that last portion of what you just said. Like we're calculating the probability of the cursor and like finding the mean and stuff. Exactly. So what we're doing here is for every time step k, so at a certain point in time, the time that I'm decoding right now, I'm going to calculate a distribution of what I think my velocities will be given all of my neural data. That's what this pink distribution is here. And so if my pink distribution looked like this, then I would guess that my velocity should be somewhere in the vicinity of 10 centimeters per second. And then I need to actually choose just one velocity to actually move the cursor on the string. And so the velocity that I'm going to choose is going to just be the mean of this distribution. So the decoded velocity will be the distribution mean. So I need to first calculate the distribution. And then after that, I need to take its mean and that gives me my decoded velocity. Not an other question. Yeah, coming. Yeah, so over here, they're minimizing the mean squared error and that gives the mean, right? But let's say you minimize the absolute error instead of the mean squared, then you will get the median of the distribution as the optimizer. So is there any intuitive reason behind this government filter using this mean squared error versus some other error? Yeah, it is straightforward for us to calculate the mean of, actually, it's also straightforward for us to calculate the median of the gas distribution. So actually, in this case, it would be fine to also use absolute error. And you would just need to decode using instead of the mean of the distribution, the median of the distribution.

I'm happy to take questions in any order. Hi. I like to ask a question about the question 4 of homework 6. Okay. The comment figure 1. So I understand that on the journal lecture, would you write these formulas to calculate AC and I guess 7Q? But I'm confused about what does it mean to compute the values we calculated into a 5 by 5 matrix for example for 8? Yeah. And then let me just get my pad also. All right. So for part a, we have this vector where we have the x and y positions at time k and then the x and y velocities at time k and then 1. And then what we wanted to do was to fit the a matrix like you mentioned using the equation in class which is essentially the least squares bit.

And so in class we had mentioned and I think we asked you in the homework to just do it for velocities. So what you should do is when you compute a, I think we call it a s. This is a 2 by 2 matrix and it's done via doing the least squares between the a equals x of k times x of k minus 1 pseudo inverse. But now these x's of k is going to be just your 2D velocities. So it's going to be 2 by k minus 1. So after you do this least squares regression, a s will be a 2 by 2 matrix. So then you ask the question what does it mean to impute? What we mean by that is that now the whole a matrix is going to be 1 that is 5 by 5. However we're only going to put in the 2 by 2 matrix here because remember that this a matrix is relating px at time k plus 1, py at time k plus 1, the x at time k plus 1, py at time k plus 1 and 1 to the positions and velocities at time k. And so we want the position equations to obey physics. So the position equation will always be 1, 0, delta t, 0, 0, 1, 0, delta t, 0 and the one will always be equal to 1.

And so what we then want you to do is you take this matrix a s and you plop it over here. And so this 2 by 2 entry here will be a s. Does that answer your question, Sean? Yes. I just have, I'll see you. Why don't you just include, also include the position when computing the matrix. That's a really great question. Yeah. So we could do that. We could do a being 5 by 5 and just stack all the positions and velocities together and do the least squares regression. The thing is that's going to give values in this matrix. And I think the values in this matrix like these will be close to 1 and these will be close to delta t, but they won't be exactly those.

And so by doing the regression over positions and velocities, you're getting values here, which are informative. But you know, you because we know that the position is the integrated velocity and that has to obey the loss of physics. We can put what we know from physics here and our physics knowledge is more accurate than what the least squares regression would pull out. So in that case, because the physics is perfect and the least squares is not, then we use the physics. Yeah, that makes sense. Thank you. Yeah. Great. Great question. Yeah. Professor.

Exactly. Is that a question I'm prone to? Is it OK if I share my screen like the plot? Yeah. Let me go ahead and I'm going to tell anyone who's watching this after. I'll just pause the recordings during share screens because it shows the students code and whatnot and so I want to just be sensitive to that. So I'm going to pause recording now.

I'm happy to take questions in any order. Hi. I like to ask a question about the question 4 of homework 6. Okay. The comment figure 1. So I understand that on the journal lecture, would you write these formulas to calculate AC and I guess 7Q? But I'm confused about what does it mean to compute the values we calculated into a 5 by 5 matrix for example for 8? Yeah. And then let me just get my pad also. All right. So for part a, we have this vector where we have the x and y positions at time k and then the x and y velocities at time k and then 1. And then what we wanted to do was to fit the a matrix like you mentioned using the equation in class which is essentially the least squares bit.

And so in class we had mentioned and I think we asked you in the homework to just do it for velocities. So what you should do is when you compute a, I think we call it a s. This is a 2 by 2 matrix and it's done via doing the least squares between the a equals x of k times x of k minus 1 pseudo inverse. But now these x's of k is going to be just your 2D velocities. So it's going to be 2 by k minus 1. So after you do this least squares regression, a s will be a 2 by 2 matrix. So then you ask the question what does it mean to impute? What we mean by that is that now the whole a matrix is going to be 1 that is 5 by 5. However we're only going to put in the 2 by 2 matrix here because remember that this a matrix is relating px at time k plus 1, py at time k plus 1, the x at time k plus 1, py at time k plus 1 and 1 to the positions and velocities at time k. And so we want the position equations to obey physics. So the position equation will always be 1, 0, delta t, 0, 0, 1, 0, delta t, 0 and the one will always be equal to 1.

And so what we then want you to do is you take this matrix a s and you plop it over here. And so this 2 by 2 entry here will be a s. Does that answer your question, Sean? Yes. I just have, I'll see you. Why don't you just include, also include the position when computing the matrix. That's a really great question. Yeah. So we could do that. We could do a being 5 by 5 and just stack all the positions and velocities together and do the least squares regression. The thing is that's going to give values in this matrix. And I think the values in this matrix like these will be close to 1 and these will be close to delta t, but they won't be exactly those.

And so by doing the regression over positions and velocities, you're getting values here, which are informative. But you know, you because we know that the position is the integrated velocity and that has to obey the loss of physics. We can put what we know from physics here and our physics knowledge is more accurate than what the least squares regression would pull out. So in that case, because the physics is perfect and the least squares is not, then we use the physics. Yeah, that makes sense. Thank you. Yeah. Great. Great question. Yeah. Professor.

Exactly. Is that a question I'm prone to? Is it OK if I share my screen like the plot? Yeah. Let me go ahead and I'm going to tell anyone who's watching this after. I'll just pause the recordings during share screens because it shows the students code and whatnot and so I want to just be sensitive to that. So I'm going to pause recording now.

All right, everyone. We're going to get started for today. So a few announcements. First is a reminder that homework number six is due tonight. I uploaded to grade scope by 1159 p.m. Last night we sent out an announcement on CCLE regarding the final exam and particular details about it. So the first detail is that Tomoy will be holding a final exam review session from 3 to 6 p.m. on Sunday June 6, 2021 at this Zoom link. And Tomoy will be uploading a problem set to CCLE and the solution will be also uploaded after the review session. He will also record the review session for people who can't make it at the time until posted on CCLE. And we highly encourage you to attend the review session. Right? Any questions about the review session? All right, beyond that, we have details about the final exam. So the final exam is in six days on June 8th and is from 3 to 6 p.m. We sent out an email regarding the details, which will be similar to the midterm.

So be checking Piazza because we're going to be posting exam updates there. And we also have a Zoom room where you can ask us questions during this exam time. Right? The final exam is going to cover up to and including everything from last lecture. And so today's lecture, we're going to cover PCA, but there will be no PCA tested on this exam. All right, so everything up to and including last lecture, everything up to and including homework six. That's what is fair again for the final exam. We have prior years as final exams, uploaded to CCLE in the past exams folder. But we want to note that last year we gave the exam in class. And so the final exam last year was an hour or 50 minutes. And it was shorter than a normal final exam, which is three hours. So if you're looking at last year's exam, please keep that in mind that it was for a shorter time slot. And then lastly, just like for the midterm, if you need an alternative exam time, we're happy to accommodate. But please read the instructions in the CCLE announcement and then send me the appropriate email to reschedule for the exam. All right, any questions on anything related to the final exam or any other course logistics for that matter.

All right, then we are going to then go ahead and what we'll do today is we'll talk about. I'll say some videos of the callman filter performance since we spent a lot of time last night during the derivation, but what's come up at level now and see how the callman filter actually does. And then after that, I wanted to introduce this idea of dimensionality reduction and present the mathematical derivation of principal components analysis, which is one of the most simple techniques for dimensionality reduction. But incredibly powerful and like the callman filter, powerful beyond applications and neural data, just generally in data science, PCA can be very helpful. All right, so for the callman filter, we call that as in homework number six, right for the comment filter, we have a linear dynamical system where now we have instead of just one equation relating neural data and kinematics. We have a second equation, which tells us how kinematics evolve through time in principle ways. And this a matrix that dynamics matrix reflected that. And so in the homework, we had you all implement this a matrix where the positions obeyed physics because they are integrative velocities. And then we had you use maximum likelihood estimation to infer the parameters of this little two by two matrix here, which tells us how the velocities at time k, update to the velocities at time k plus one. And this model is inertia, so in the homework, you should have gotten values in this matrix that are below one, but are, but that are not close to zero. They're the closer to one. And that means that the velocity at time k plus one is going to be close to the velocity at time k. And so that means that if you're moving to the right at time k, then this equation is saying at time k plus when you're probably still moving to the right. Okay, and so that's how these velocity terms incorporate a smoothness or inertia. Right. Any questions here. So then after that, we went through the common filter recursion, which we derived last week, and you should have been able to implement the wild loop that runs through these equations and then calculated these m1 and m2 matrices.

Eventually, you could decode kinematics using the equation x k hat equals m1 times x k hat of time k minus one plus m2 times y k. And that's how the common filter uses the m1 matrix, so we pass kinematics and the m2 matrix to consider the current observation, the neural data. Any questions on any setup of the common filter, any part of the derivation, any part of intuition on the common filter? All right. So in homework number six, you all implemented the common filter and we're able to calculate the mean square error. And now show you the video of what the common filter looks like when we ask one of the monkeys to control it, and early in real time. So I'm just waiting for the zoom when they catch up with my eye. Okay. So this video is going to be the vanilla common filter that you all implemented in homework number six. I'm going to bring the same task that we've shown before where his goal is to reach to one of the targets, but if he hovers over any target for 500 milliseconds, it's going to select that target. And if he selects a target that is incorrect, then you'll hear the negative sound, but if he selects the correct target, you'll hear a positive sound. Okay. I think maybe the sound isn't working for this video. I apologize. All right. So 20 trials are so in. We see the success rate. He's over 90% success rate. The bit rate is 2.2 bits per second, which is respectable, but actually less than the winner filter. So looking at this video, either in the chatter, if someone could raise their hand, could you tell me what you feel are the pros and cons of this decoder in terms of how it looks? Yeah. William. Kind of feels like the movements are too big every single time, like, yeah, over shooting.

Yeah, great. Yeah. So William and then Grace wrote something similar in chat, which is looks like they're over shooting. That's exactly right. So it turns out that with the common filter, when we incorporate the inertia, we reduce it incorporated. So when you look at the movements, they are relatively smooth towards the target. You don't see the jitteryness that we saw with optimal linear estimator, for example. The problem is that it's in a way too smooth as if there's too much inertia. So usually when there's a target that's far away, you see that he overshoots it. Although actually two minutes in, which is what let me restrict the video. It turns out that the monkey will learn a good control strategy. So two minutes in, he kind of compensation for this over shooting by by not going as fast. But you can see early on when he's trying to get to a target. He often overshoots it. And that's because there's too much smoothness in the velocity. And so while this incorporates inertia, it causes you to be so much inertia sometimes that that the monkey will overshoot. And then when there are small movements that he needs to make, you can see he goes back and forth around that again, because as far as it's kind of stopped the inertia of the common filter. Any questions there? All right, so we saw this problem of the common filter and we decided to make an innovation on it to make it higher performance. And so we had two ideas, two main ideas to do this. And these comprise what is now called the refit common filter control algorithm. And this is something that we published in Nature Neuroscience in 2012. And so the first idea is less related to the common filter. But it has to do with the training data. So let me talk about that innovation first and then it's related to our second innovation, which helps with this over shooting problem. So let's say that the monkey is starting at a center target and wants to reach to a target that is up into the right. When the monkey makes such a reach, the trajectory isn't the straight line to the target, but when we reach up into the right, we make a curve trajectory because of the biomechanics. And so if you think about how in the homework, the way that we calculated the velocities that we read rest to is that we just took adjacent positions. And then we just did a first order or error approximation of the velocity. So we took the two adjacent positions subtracted them and then divided by T. What this means is that at the very start of the trial early on, even though the monkey intends to go up into the right, the velocities are actually pointing upwards. And at the end of the trial as he gets this target, even though he's again trying to go up into the right, the velocities point just to the right. Whereas we believe the neural data reflects that he wants to always go up into the right, but the movement itself has some of these suboptimalities just due to the way of biomechanics how hands naturally move.

All right, everyone. We're going to get started for today. So a few announcements. First is a reminder that homework number six is due tonight. I uploaded to grade scope by 1159 p.m. Last night we sent out an announcement on CCLE regarding the final exam and particular details about it. So the first detail is that Tomoy will be holding a final exam review session from 3 to 6 p.m. on Sunday June 6, 2021 at this Zoom link. And Tomoy will be uploading a problem set to CCLE and the solution will be also uploaded after the review session. He will also record the review session for people who can't make it at the time until posted on CCLE. And we highly encourage you to attend the review session. Right? Any questions about the review session? All right, beyond that, we have details about the final exam. So the final exam is in six days on June 8th and is from 3 to 6 p.m. We sent out an email regarding the details, which will be similar to the midterm.

So be checking Piazza because we're going to be posting exam updates there. And we also have a Zoom room where you can ask us questions during this exam time. Right? The final exam is going to cover up to and including everything from last lecture. And so today's lecture, we're going to cover PCA, but there will be no PCA tested on this exam. All right, so everything up to and including last lecture, everything up to and including homework six. That's what is fair again for the final exam. We have prior years as final exams, uploaded to CCLE in the past exams folder. But we want to note that last year we gave the exam in class. And so the final exam last year was an hour or 50 minutes. And it was shorter than a normal final exam, which is three hours. So if you're looking at last year's exam, please keep that in mind that it was for a shorter time slot. And then lastly, just like for the midterm, if you need an alternative exam time, we're happy to accommodate. But please read the instructions in the CCLE announcement and then send me the appropriate email to reschedule for the exam. All right, any questions on anything related to the final exam or any other course logistics for that matter.

All right, then we are going to then go ahead and what we'll do today is we'll talk about. I'll say some videos of the callman filter performance since we spent a lot of time last night during the derivation, but what's come up at level now and see how the callman filter actually does. And then after that, I wanted to introduce this idea of dimensionality reduction and present the mathematical derivation of principal components analysis, which is one of the most simple techniques for dimensionality reduction. But incredibly powerful and like the callman filter, powerful beyond applications and neural data, just generally in data science, PCA can be very helpful. All right, so for the callman filter, we call that as in homework number six, right for the comment filter, we have a linear dynamical system where now we have instead of just one equation relating neural data and kinematics. We have a second equation, which tells us how kinematics evolve through time in principle ways. And this a matrix that dynamics matrix reflected that. And so in the homework, we had you all implement this a matrix where the positions obeyed physics because they are integrative velocities. And then we had you use maximum likelihood estimation to infer the parameters of this little two by two matrix here, which tells us how the velocities at time k, update to the velocities at time k plus one. And this model is inertia, so in the homework, you should have gotten values in this matrix that are below one, but are, but that are not close to zero. They're the closer to one. And that means that the velocity at time k plus one is going to be close to the velocity at time k. And so that means that if you're moving to the right at time k, then this equation is saying at time k plus when you're probably still moving to the right. Okay, and so that's how these velocity terms incorporate a smoothness or inertia. Right. Any questions here. So then after that, we went through the common filter recursion, which we derived last week, and you should have been able to implement the wild loop that runs through these equations and then calculated these m1 and m2 matrices.

Eventually, you could decode kinematics using the equation x k hat equals m1 times x k hat of time k minus one plus m2 times y k. And that's how the common filter uses the m1 matrix, so we pass kinematics and the m2 matrix to consider the current observation, the neural data. Any questions on any setup of the common filter, any part of the derivation, any part of intuition on the common filter? All right. So in homework number six, you all implemented the common filter and we're able to calculate the mean square error. And now show you the video of what the common filter looks like when we ask one of the monkeys to control it, and early in real time. So I'm just waiting for the zoom when they catch up with my eye. Okay. So this video is going to be the vanilla common filter that you all implemented in homework number six. I'm going to bring the same task that we've shown before where his goal is to reach to one of the targets, but if he hovers over any target for 500 milliseconds, it's going to select that target. And if he selects a target that is incorrect, then you'll hear the negative sound, but if he selects the correct target, you'll hear a positive sound. Okay. I think maybe the sound isn't working for this video. I apologize. All right. So 20 trials are so in. We see the success rate. He's over 90% success rate. The bit rate is 2.2 bits per second, which is respectable, but actually less than the winner filter. So looking at this video, either in the chatter, if someone could raise their hand, could you tell me what you feel are the pros and cons of this decoder in terms of how it looks? Yeah. William. Kind of feels like the movements are too big every single time, like, yeah, over shooting.

Yeah, great. Yeah. So William and then Grace wrote something similar in chat, which is looks like they're over shooting. That's exactly right. So it turns out that with the common filter, when we incorporate the inertia, we reduce it incorporated. So when you look at the movements, they are relatively smooth towards the target. You don't see the jitteryness that we saw with optimal linear estimator, for example. The problem is that it's in a way too smooth as if there's too much inertia. So usually when there's a target that's far away, you see that he overshoots it. Although actually two minutes in, which is what let me restrict the video. It turns out that the monkey will learn a good control strategy. So two minutes in, he kind of compensation for this over shooting by by not going as fast. But you can see early on when he's trying to get to a target. He often overshoots it. And that's because there's too much smoothness in the velocity. And so while this incorporates inertia, it causes you to be so much inertia sometimes that that the monkey will overshoot. And then when there are small movements that he needs to make, you can see he goes back and forth around that again, because as far as it's kind of stopped the inertia of the common filter. Any questions there? All right, so we saw this problem of the common filter and we decided to make an innovation on it to make it higher performance. And so we had two ideas, two main ideas to do this. And these comprise what is now called the refit common filter control algorithm. And this is something that we published in Nature Neuroscience in 2012. And so the first idea is less related to the common filter. But it has to do with the training data. So let me talk about that innovation first and then it's related to our second innovation, which helps with this over shooting problem. So let's say that the monkey is starting at a center target and wants to reach to a target that is up into the right. When the monkey makes such a reach, the trajectory isn't the straight line to the target, but when we reach up into the right, we make a curve trajectory because of the biomechanics. And so if you think about how in the homework, the way that we calculated the velocities that we read rest to is that we just took adjacent positions. And then we just did a first order or error approximation of the velocity. So we took the two adjacent positions subtracted them and then divided by T. What this means is that at the very start of the trial early on, even though the monkey intends to go up into the right, the velocities are actually pointing upwards. And at the end of the trial as he gets this target, even though he's again trying to go up into the right, the velocities point just to the right. Whereas we believe the neural data reflects that he wants to always go up into the right, but the movement itself has some of these suboptimalities just due to the way of biomechanics how hands naturally move.

All right, everyone. We're going to get started for today. So a few announcements before we begin. I sent out a CCLE announcements with instructions on how to sign up for Piazza and grade scope. And so those are just recapituated here as well as a link to a Python tutorial. If you have only used MATLAB in the past, this tutorial will probably be helpful for you. And then we have also uploaded to CCLE material reading for this class, the lecture notes, and then we also uploaded all the midterms and final exams dating back to 2017. If you're someone who isn't sure if the pre, if you satisfied the prerequisite material, I encourage you to take a look at the midterms and final exams as well as the common filter dot pdf which are probably the most technically demanding for this class. Any questions on any announcement related matters? Any course logistics?

All right, so excuse me. We're going to go ahead and finish off the syllabus. So last time we talked about the grade breakdown for this class and that it was graded on an absolute scale. And I know I went through it a bit quickly at the end, so I just want to put up this slide to ask if there are any questions here on the grade breakdown for the grading scale. All right. So then we had also put up this information about pass no pass or satisfactory on satisfactory grading if you choose to take the class in that manner. We also talked about how for exams during remote learning, the exam are going to be open note open book and you can access your notes and CCLE on your computer, but it's going to be closed internet. And that the TAs and I we are going to perform some analysis on the answers given. And if we suspect anyone collaborating, which are not allowed to do for the exams, we request reserve the right to give a superseding oral exam. Right. And then also if you are in a different time zone, we can make accommodations for you to take the exam at a different time.

And so please send me an email this week if you plan on taking us off on this. We will we use that just to get a sense of how many accommodations we'll need to make and then we're going to send out more details closer to the exam date to handle those accommodations. Any any questions here? All right. I have to slide on academic integrity, which I give in all my classes. And it's my way of saying up front that I care a lot about academic integrity and that we all follow the principles of academic integrity and fairness and respect to our fellow classmates. And so I put up the slide to say that I take this very seriously. And if we catch any students of cheating or violating the principles of academic integrity, that I take that seriously. And I will follow up and report those cases to the dean of the students office. And we will follow their recommendation as they investigate the case and do what they do what they determine us to do. All right. So I just want to put that up front that again. If we if we catch you violating academic integrity, we will follow up on it and report their case to the dean of students. All right. Any questions here?

All right. So with that other course information throughout this class, we're going to cover a wide range of topics, including some intrusion neuroscience, which we'll do for these first two and a half weeks. And then after that, we're going to cover topics in modeling spikes. That's going to be drawn from this theoretical neuroscience textbook, as well as topics from machine learning and statistical signal processing, which we take from this Chris Bishop textbook. And because we didn't want to have students need to to purchase all three books, what we did was we took the excerpts of the chapters that we used for these books and we put those on CCLE. Right. So that material should all be on CCLE. Other notes for this class. So the last two notes that we use in class, I just asked that they not be publicly posted due to matters related to copyright. And so we'll be happy to distribute them in the annotated notes on CCLE. But we just asked that they remain within the class population. Like we said, last time a piazza should be used for almost all major class discussions. And of course, these office hours to get any other questions answered.

But we hope that the piazza form will be lively. And like I mentioned last time, we give bonuses based off of participation on piazza. And so even though you can consider anonymous to classmates, your posting is not anonymous to us. And we make that setting so that we can assign bonuses based off of how much you participate on piazza. And the TAs will be checking piazza also regularly to make sure that any questions that couldn't be answered by students can be answered by teaching staff. If you have a question that isn't appropriate for piazza and it's related to class material, I just asked that you email, Tonmoys, Shashank and I and me together. We do this so that no single TA gets overloaded because in prior classes, sometimes once TA is very responsive and then all the students learn to email that TA all the time and that TA becomes overburdened. And so we just asked that you send us any class related questions to all three of the teaching staff if you don't post it on piazza. And then of course, if you have any personal matters, please email me directly there. Any questions here? All right. Some last notes. I think we mentioned this last time.

It's time consuming to make the transition from that lab to Python. So please factor that into your work. I think it's worth it because Python is the de facto standard for machine learning and signal processing today. I also mentioned this last time this class according to student feedback is a lot of work. And so I want to state this upfront so that you can plan accordingly. We do try to have this class be very fun, but we cover a bunch of topics and test it understanding. So we have seven homework assignments and we're told that those assignments are somewhat time consuming. All right. Like the mentioned piazza should be the primary names of asking and getting questions answered. And we just talked about this on the last slide also so I won't review that again. Any questions here? All right. So with that. Sorry. It looks like I have that was not last notes. I have a few more slides. For those coming with a background in machine learning. I want to say that up front since we start off doing neuroscience and we do derive maximum likelihood solutions for classifiers and regression in this class, which is something that may have seen before.

You may feel the pace of the class is somewhat slow. And then we're going to keep the pace because a lot of people in the class don't have background in machine learning. And I want to make sure that everyone can learn and master the material. And so if you're coming in with the prior background in machine learning, just be aware that the class may feel a bit slower for you. And you can factor that into your decision as you decide what class is to take. And then I like we talked last time. I think we're going to take halfway through lecture because the lectures are fairly long here at UCLA. And in our discussion sections, which we're going to be run live by Tonloi and Shashank. First off, you can attend whatever discussion section you would like. And the TAs will also be recording at least one of the discussion sections to put it on CCLA. And then we have already sent out the P.O.T.S.ing page to send up information so this full of points should not be here. All right, a lot of logistics I just went through any questions on anything that I went through. Okay, so I just want to do brief introductions. So about me and sorry. This is not updated well. I did update the other parts of the slide, but I didn't update this introduction.

This is not my first year at UCLA. This is now my fourth year. And it's my seventh time teaching this class. And so I, I've taught it at Stanford twice with my PhD advisor there and previously taught at UCLA four times. This is a class related very closely to the research that my research group does. And so we care a lot about improving the performance of brain machine interfaces. And then other classes that teach at UCLA include ECU 102 in the fall quarter, so that signals and systems. And then in the winter quarter, I teach a class on neural networks and deep learning. And so with that, I'm going to pass it off to one of our TAs, Tom, why so Tom, why if you can go ahead and unmute yourself. Yeah. Hi, so hello everyone. So my name is Tom, I'm on tour. I will be one of your keys for this quarter. So this is my third time, Tying for this course on neural signal processing and my fifth time, Tying for Jonathan. All of my Tying experience at UCLA has been for Jonathan. I really like Tying for Jonathan and especially for this course. So this course is one of my favorite courses here at UCLA. I took this course first when it was offered for the first time and back in 2017. And I really enjoyed the course material. I also hope that you also enjoyed this course too. So I am a PhD student at UCLA working with Professor Rajudhary and my research in interest, primary lies in reinforcement learning and pattern, exception and dynamic networks. So that's all about me and I hope to have a very enjoyable quarter with all of you. Thank you very much. Great. Thank you, Tom Boyd. And then we have our second TA, Shishank, who won't be able to give an introduction today. We'll ask him to give an introduction on Monday. But this will be Shishank's first time Tying this class here at UCLA and he's of course taken this class before and done, absolutely. And so we'll leave Shishank's introduction for the start of next class on Monday.

All right, everyone. Welcome to each one of two for the fall quarter of the academic year. I'm your professor Jonathan cow. And we also are we also have three TAs here are we not. Go Sh Conway Montsler and Guangwen Zhao right and so I wanted to just start off with a few words about online lecture before we begin. So the first is that as you all know, the lectures, discussions and office hours for this class are going to be carried out on zoom. So lectures and discussions are also going to be recorded and uploaded to CCLA. We encourage you to attend lectures live, which will be Monday Wednesdays, 2 to 350 PM Pacific time, as will aim to have these lectures be interactive and also have an opportunity to ask questions. If you don't want to appear in lecture video, it's fine to opt out, but because we're recording these for the benefit of all students, we asked that you opt out by not attending. This will be the link for lecture for the entire quarter and also be the link that I use for my office hours. Alright, so in addition to that, so by default, everyone in this lecture is muted during by lectures. However, I do want these lectures to be interactive. And so we allow there to be questions and we'll do it through the following mechanism. The first is through the raise hand button. And so if you raise your hand, which I'm sure all of you know how to do, but if not there are instructions here, then when there's a natural breaking point during lecture, then I'll take questions. The other way is through chat functionality. And so our TAs are not on boy and Guangwen who introduced at the end of class. They'll be monitoring the chat. And so if you type in a question into the chat, that will be seen by the TAs and the TAs will be able to answer that question. And we just asked that you also record your question.

We asked you record your question, sorry, that you post your question publicly to everyone so that it would be for the benefit of everyone. And then I just also wanted to mention something about asking questions. This is a large class. I think we have right now on zoom. We have 158 students in here. And I remember being an undergrad and having questions during lecture, but oftentimes being afraid to ask them because I fear that I might ask a stupid question or others might judge me. So I want to say that in this class, the likelihood of stupid questions is very rare. So for the purposes of practice for this class, I'm going to say there are no stupid questions. And I think that if you have a question like that, it's really important to ask it for two reasons. The first is that it's very, there are going to be concepts in this class that builds on top of prior knowledge. And if you aren't following something that's more fundamental, then it's really important to get that addressed so that we can build on that. And you can understand later material. The second is that if you have a question about something that you don't understand is very likely that others in the class also may not have picked that up. And that might be because I didn't explain it well. And so if I ask you a question, you give me an additional opportunity to try to explain a concept. All right. And then the TAs are also going to be operating on this quarter. I put all of their links here for their office hours, as well as for their discussion sections. And we'll talk about logistics there later on in class. All right. Any questions before we start off? All right. Great. So in this first lecture of signals and systems, I wanted to give an overview of what this class is all about. And so we'll also after talking about the high level details of this class, go into the course logistics and the syllabus.

Though I know that this is a required class for many of you. I hope that you'll still have a lot of fun learning the material in this class. I'm obviously biased, but I think that the material here is really interesting and will dovetail well into a lot of your future classes in the right. And again, as I was just saying, please ask questions, even questions that you may think are elementary. Those are the most important ones. All right. All right. So a first question that you might have is this class is called signals and systems. So what are signals and what are systems? To unpack this question, I wanted to take a high level view of what signals and systems are. And so what do we mean when we say signals and systems? Well, at a very high level. We know that our world and our society relies on being able to represent information, to represent the knowledge that we have. And then to to communicate that information knowledge, others to process that information and to operate on that information. And one way in which we can see the importance of this in our society is through technology. And technology is correlated to our ability to do these things to represent information and then also to communicate information. And so we can go back as far as prehistoric times by dining times before we had recorded history to ages of country gatherers where predominantly there, the means of communicating information was through personal interaction. And so you might be able to get some information by meeting up with someone, reading their facial expressions or if they had some form of language by word of math. All right. As civilization developed, we had a major advantage, which was the knowledge or the ability to write things down. And here I'm showing a picture of Egyptian hieroglyphics. But as we were able to write things down, now knowledge could be written down for future generations. And so this allowed information within, gained within a specific generation to propagated future generations.

And we see how information from past generations, for example, the ancient Greek, like the writings of Aristotle, Plato, Socrates, even ancient texts, texts like the Bible, for example. Are all things where we have information about what happened in prior times and, and are able to build off of that information subsequently. See a question quickly. Sorry. I'm looking to see how to get on mute. Melissa, can you unmute? Yeah, I can unmute now. What is the structure of your recorded? I guess the lectures will be recorded and they'll all be uploaded to CCLE. Any other questions? All right. So again, as we're able to write down information, we can now propagate that to future generations, but not everyone had access to these writings. And so another major part of advancement in technology was what I'm showing here, which is a good and bird press. This printing press allowed essentially written down information to be democratized and to be accessible to many people, allowing ages such as the enlightenment where we really saw an explosion and ideas and information. One very important, one very important advance towards modern technology that we know of today was the ability to begin to write down and store information electronically.

So does anyone know what this device I'm showing there is? You can write in the chat if you know. Ryan says battery as several people say battery that exactly what this is. This is the Voltaic pile. It was developed by Alice Andrew Volta and essentially it's a stacking of several electric electrochemical cells and it allowed there to be a voltage now across two terminals, which could be used to power circuits. Later on, Gayord Oom came along and he derived this very important equation V equals I R, which I'll be it simple. If you've taken a circuits class, you know that from V equals I R, we get in for we derived equations and concepts like that in a North team equivalent circuits or care cost voltage and current laws. And then here I'm showing one of the very first transistors, which we know then allowed us to make active circuits and underlie many of the integrated circuits that are in our computer today as well as in analog circuits and devices that we use. And so with this and with electricity, we were able to start to communicate information in new ways. And example of this is. Alexander Graham Bell, one of his first ways in which he transuse voice into electrical signals was he would take. And then he would put a needle in water and that needle would vibrate according to the voice, the sounds that you made with your voice and when the needle vibrate in the water that would change the conductance of water and we know from V equals I R, if you change the conductance or the resistance of water that's going to change the current. And so that current could be transmitted as electrical signal and you can convey the signals from your voice to many people. Right. And so this was a voice to electrical. And so why am I talking about information and how we convey it will it turns out that signals and systems correspond to these two things. And so signals are things that represent information. And so in this class and the signal systems perspective will conceptualize these information or signals as our information and then how information then is changed in process is what we refer to as systems. And as electrical engineers or engineers in general, we tend to think of signals and systems in electromagnetic or computer terms.

All right, everybody. If you're coming from EC-102, my computer is, I hope that this is okay. My computer is still converting the EC-102 video, but I started recording for EC-1809, so hopefully there isn't a negative interaction there. All right. All right, cool. So this is EC-1809, which is the Advanced Honors Seminar. I think most, if not all of you, are probably taking this concurrently with EC-102. Today, we'll just talk about the structure of this class and then introduce the problem that we'll talk about for the rest of this class, which is going to be related to my research. And so a quick few things to get out of the way. The first is for grading. So there are many more students in the class this year than in prior years. What I like to do is I like to have this class be largely interactive. And so this is not the case.

I'll modify things, but you should be able to unmute yourself and talk. What we'll do is we'll still use the raise hand system here, but I won't need to unmute you. And if you want to interject at some point in time, as long as it doesn't become disruptive later on, then that's all good with me. And so I'm happy to have this very open class where you can ask your questions, where we can think of that things together. And I think that that's fitting for such an honor seminar. This class is one unit. And the way I gauge what the work in this class should be for something that's one unit, which is the following. ECE-102 has four units and about, or has seven problem sets. So what I've done for this class is I've designed this class of just have one project, which is given at the end of class. And it's roughly equivalent to doing two problem sets in ECE-102.

And so that'll be the entire work load for this class. Here will be the Zoom link for this class, which we'll use for lecture. I will be recording lectures and also uploading them to CCLE in case people can't make it. And the office hours for this class are just going to be the same as my ECE-102 office hours. And so if you're not taking this class in currently with ECE-102, those office hours are at this link here. And they're going to be on Thursday from 12 to 2 p.m. Okay. Any questions to start off? All right. Yeah, so this class is something where I want to focus a large part of it on how to think independently and how to use tools at your disposal to answer questions of interest. And so towards this end, the structure of this ECE-189 is that we're going to focus on a particular problem.

Hopefully of interest to you, definitely of interest to me, but hopefully I can convince you that it's interesting. It'll be in the area of so-called brain-machine interfaces. And we're going to try to use the tools that we have at our disposal, particularly from EC-102, as well as calculus, to try to solve a problem in this particular area of study in this particular area of brain-machine interfaces. And so the project will be that I'm going to give you some neural signals that were recorded from neurons in the brain. And we're going to ask you to translate those neural signals into movements. That sounds like a daunting problem if you've never been introduced to the area of brain-machine interfaces. But that's what the structure of this seminar is going to be. We're going to discuss what brain-machine interfaces are. We're going to discuss how neurons work. From there, we're going to discuss what kind of tools we need to solve this problem.

That's going to be the major component of this class. The first three weeks of EC-102 are not application-heavy. I mentioned in EC-102 today, that class, the first three weeks are just a lot of math and foundation-building. We're going to spend the first three weeks of this seminar just introducing the background of what brain-machine interfaces are. And then after that, we'll talk about the kind of tools that we'll want to try to solve the problem of decoding neural signals into movements. And then we'll finish off this seminar by just thinking of other problems and how we might solve them with tools we have. And so again, an overall goal of this seminar is to take a question that is probably new to all of you, think about how to approach that question, and then how to break it down so that we can tackle it with the tools that we have. Any questions in terms of course goals or how the ECE189 is structured? I had a question about what you mean by movements.

Is that essentially reading a neural signal? And then corresponding that to what a person, what movement a person would be trying to make and I would give off that signal? Is that okay? Okay, cool. Yes, I'm sorry, what is your name? I try to remember names for this class, and this is smaller than I can manage it. I'm Blake. Okay, thanks Blake. Actually, I realize that it might be more difficult because I don't think I see videos. So I didn't think about this beforehand. You don't have to turn on your videos if you don't want to, but if people want to turn the videos, that could help me to remember your faces. All right, yeah. So Blake, your question is for this particular problem of brain-mishing interfaces, yeah, the movement corresponds to the intended movement that someone might want to make.

And so if you think about someone with paralysis and we'll talk about this a bit later on in this lecture, their brains are totally functioning, but they can't move because for example, their spinal cord is severed, so they can generate the intention to move, but no movement will come out. And so, again, we'll talk about this in a bit more detail, but then for people with paralysis, what we can do is we can try to bypass this broken spinal cord by directly reading out from the brain. And if we can interpret those signals into movements, the movements that they want to make, like, moving my arm to the right or to the left, then we can restore some communication and prevent them to them. Okay, any other questions? Well, yeah. Is this course going to, like, roughly follow what we learned in 102, or is it kind of slightly by itself? It's more by itself.

So the process is going to be motivated based off of material in 102. So we're going to do some filtering of signals, of neural signals, and then decode them, but it's going to be largely sent away. So if you're not taking this class concurrently with 102, that's also fine. Although, if you're not taking it concurrently with 102, ideally, you would have had 102 before. Otherwise, the project, the project would be very difficult. And sorry, just give me a second to see if I can change my view to be the video so that I can see everyone. Let me see if I can just make this to gallery view so that, looks like I'm inside gallery. Okay, and sorry, could we just ask the question there? Oh, Jerry. Okay. Thanks, Jerry. And then I see Bradley has a question, Bradley, could you please unmute yourself and ask?

Yes, so you mentioned that the brain machine interfaces have applications for complete paralysis, but deep does that also have an application for things like essential tremor, where it's like they can move, but it's impaired? That's a great question. It could have application there. If the tremor is due to, for example, Parkinson's disease, then there are better treatments, a treatment alternative, like deep brain stimulation. And I'll show some examples of that in lecture today. In theory, it could be, but we'll also learn, at least for what we'll talk about in lecture, to record from neurons, you have to do neurosurgery. And so there are a lot of costs and risks associated with the system. And to justify those costs and risks, the ability to decode has to be very high, or the tremor has to be completely removed. And I'm not aware of anything aside from deep brain stimulation to address Parkinsonian tremor right now.

Okay, thank you. Thank you very much, Brianna. Can the brain machine interface also affect like pain transmitted, like with fibromyalgia, there is pain that occurs, could that prevent? In theory, yes. So I'm not aware of any studies related to looking at pain pathways. And for example, preserving them, or writing an information to those pathways to prevent the perception of pain. But in theory, that's something that I would call a futuristic brain machine interface. In general, it's very hard to write information into the brain, or to exactly perturb the brain in the way you desire, not just because of the lack of tools, but also because I would say that we understand less than 0.001% of how the brain works. And I'm a computational neuroscientist, that's my field. We understand very little, but we still have made great strides. But then as to how to particularly perturb brain pathways to solve the perception of pain, I'm not aware, I don't know that area too well.

0:00:00
All right, everyone. We're going to get started for today's lecture. So one of the nastiest before we begin, which is that R&OB, R&OB and RTAs are uploaded homework number one to CCLE in the week one materials on Friday of last week. This homework is due this Friday, I'll upload to grade scope by 11.59 p.m. Right? Any questions on any course logistics? All right, so we're going to get right into material then. So last lecture, we had for us to talk about signal operations and properties. We talked about time scaling, reversal and shifting, as well as even in odd signals. And we had finished class talking about periodicity. So today, I want to finish periodicity and then also want to get through material on energy and power signals as well as complex numbers. And hopefully we'll also be able to start some signal models today. So last lecture, we had talked about what a periodic signal is, which is a continuous time signal is periodic. It's an only if there exists a big T0 and this big T0 is called the period of the signal. And if the signal repeats every big T0, then the signal is called periodic. Right? And then we also showed last lecture that if it repeats every big T0 and is periodic, then it'll also repeat every two T0, three T0, four T0, five T0, etc. All right? So I wanted to start off this lecture by just talking about the simplest periodic signal, or one of the simplest periodic signals. And then we'll have a brief poll question after that. So one of the most basic signals in this class that we'll cover is the sign or the cosine wave.

0:02:07
And we're going to be using them extensively in this class. So it's worth reviewing some of their properties. So a cosine is typically written in this way. You'll see it written two ways, actually. It'll be A times cosine omega. That's this discrete letter T minus theta. Or you'll also see it written as A cosine 2 pi f T minus theta. And so omega is, in this case, equal to 2 pi f. And the difference between these is whether we're talking about frequency or angular frequency. So omega is called an angular frequency. And it has units of radians per second. Whereas f is called frequency. And it has units of hertz, which is equal to 1 over seconds. Now, how we relate the frequency to this concept of the period, big T0 is the following. The frequency is equal to 1 over big T0. Where big T0 here is a fundamental period of the signal. So if the signal repeats every one second, big T0 equals one second, then the frequency is 1 hertz. If it's faster and it repeats every 0.5 seconds, then the frequency is 2 hertz. So it happens, it repeats more frequently. And then when we convert it, angular frequency, we just multiply everything by 2 pi. All right. So let me draw up the sine wave. Or we'll do the cosine wave here looks like. This is, hopefully, review for most of you. So if I have a cosine wave, and I'll just draw this following. There are a few terms in this expression that we need to point out.

0:04:22
So you want to know what are a, f, and theta. And to answer these questions and to explore what these terms are, I have to write down a few time points. So let's say that this here, this is equal to 2. So this cosine is going to repeat every two seconds. Right. And then let's say that the amplitude here, let's say that this value is equal to 4. Right. So we know that if we don't have an a here of a is equal to 1 cosine omega T minus theta is a signal that has a peak of 1. And so when we see here, this cosine goes up to 4, that tells us that a is equal to 4. And so a is just an amplitude scaling factor is equal to 4 here. Right. That's here is again the frequency of the signal, which is 1 over big T zero. And so here, if big T zero is equal to 2, as it is, because the signal repeats every two seconds. No matter where I am, I go two seconds down in time and I'm going to be at this same point. Right. So F is going to be equal to 1 over the period, which is 1 half. So the frequency of this signal is is 0.5 hertz. Right. Okay. And then theta here, you'll see is a quantity that's going to look like it's a time scaling factor. Sorry, not a time scaling, a time shifting factor. And so if I subtract theta, right. Last lecture, we talked about how we subtract a number. What we're going to do is we're going to delay the signal. And so cosine, we know, starts at 1 goes to zero, goes to negative 1 et cetera. So this cosine is not shifted in any way. So in this case, theta is equal to zero.

0:06:30
All right. Well, let's say that I did want to shift the cosine. So let's say I wanted to shift this cosine. So it looked like the following. All right. And so this cosine now has its peak occurring at time t equals 1. All right. So I'm going to ask if I want to take this blue signal here and shift it by an amount of theta. So now it's time shifted delayed so that it's peak instead of happening at zero, happens at time one. For what value of theta ought that be? And so take 10 to 15 seconds to think about that. And I'll ask someone to write the answer over chat. All right. So I see several answers in the chat. I see pi. I see pi over 2. I see 1. All right. So the correct answer is pi. And let me explain why that's the case. So the first answer that you might have thought of is that the answer is 1. Because what I'm going to do is I'm going to shift this blue signal over by time one. So if I call this blue signal here x of t and I call this green signal y of t, then your first attempt may be to say, okay, y of t is going to be equal to x of t, which is 4 times cosine of 2 times pi times the frequency, which is 1 half t. And then because it's shifted over by 1, then I should write a minus 1 here. All right. We put a question mark there. Let me simplify this a bit. This is equal to 4 cosine of pi times t minus 1. All right. So you can do a few sanity checks to see if this is correct or not.

0:09:07
If this is correct, then the peak of the cosine should occur at time t equals 1. However, if I plug in time t equals 1 here, so at time t equals 1, when the cosine should have its peak, this function is equal to 4 cosine of pi minus 1. All right. But we know that cosine has its peak when the argument to cosine is 0. Cosine has its peak at time t at when the input is 0, but pi minus 1 is not equal to 0. So this here must be incorrect. All right. So I want so much to write or someone can someone raise their hand and tell me why this is incorrect? Because I did what we taught last vector, right? I shifted the time over by 1. So why didn't this work? Salvador. Hi. So it wouldn't work because pi minus 1 is not 0 or pi, which is at its peak, which is 1. Cosine of 0 is 1. Cosine of pi is 1. It would be somewhere between 0 and 1. Cosine of pi minus 1. Yeah, that's correct. Yeah. So then that's a good explanation for why this is not the correct answer. I'm going to now go to Rampton and I'm going to rephrase my question. So in terms that we know that this is an incorrect answer, why was it incorrect to just subtract one here? And so I'm going to go having ask Rampton. Okay. So because you have to subtract one from the parameter T, meaning that you have to replace T with T minus 1. So that 2 pi times 1 half will be multiplied by T minus 1 and you have to distribute that pi into negative 1 as well.

All right, everyone. We're going to get started now for ECE189. I want to ask if there are any questions on the seminar or even one or two related things before we begin. All right. So we're going to continue where we left off last time, which is last time we start to talk about neurons and how they signal. And so last lecture, we had talked about how neurons essentially have three parts that are important. They have the inputs, which are the dendrites, and they're these arborous life structures. And then there's an integration center, which is called the axon collect. And what this integration center does is it receives voltages from all of these input dendrites and it adds them together. And if that sumed voltage is above a threshold, it's going to send an output called an action potential. And that goes along is axon, which then connects to the dendrites of other neurons. And so the axon, we can think of as the output of the neuron. All right. And we talked about how even though neurons have many different morphologies and shapes and sizes, they are essentially the same in function that they are always going to have inputs coming in on their dendrites. They're going to sum them together. And if it's a big enough value, they're going to fire off an action potential to them downstream neurons. And the complexity then in signaling arises from how we connect neurons, much like how in computer circuits or analog circuits, all transistors operate based off of fundamental principle. And all transistors have per CMOS, the source of draining the gates, but then connect them in special ways. And you have a common source amplifier, or you have a common gate follower, or you have an x-or gate, or an or gate, or an AND gate, etc.

Okay. Any questions here? All right. So we talked about how these action potentials are, all are nothing events, and they look like these spikes over here. And in this sense, we can think of signaling in the nervous system as being digital, right? Either you have no spikes, or else you do have a spike, which you can think of as a one. And this digital signaling allows for high fidelity communication across long distances in your body. And so your brain has to tell your toes how to move, or else you have to be able to feel things like if you step on something pointy, you feel that pain. And that pain should be conveyed to your brain at high fidelity. And that happens because the neurons are going to fire these spike signals, and the spike signals are the digital signal. And as they get transmitted across the nerves in your body, they're going to decay like all signals do. They're going to decay as they travel. However, there's going to be these repeaters in your nervous system called nodes of Rambiae that when the signal is decaying too much, it's going to amplify the signal so that it regenerates the spike. All right. So if you've heard of a motor disorder called multiple gulerosis MS, actually the degeneracy of this disease is that the spikes can't get to the next repeater. And if the spikes die before the next repeater, before the next node of Rambiae, then the signal is lost. And so people who have multiple gulerosis have the degeneracy and not being able to regenerate or re-amplify these spike signals. Any questions? All right. So, I'm on this. Yeah. Okay. Thomas, I think you were having a sorry. Yeah, I think you're on me to be there. Yeah.

Okay. For the second bullet point. Yeah. Thomas, I heard for the second bullet point. I heard for the second bullet point and then I got cut off. Okay. Is it working out? It's working out, I guess. Okay. Yeah. For the second bullet point, what is like highly stare type to mean in this context? Oh, it means the shape is highly stare type. And so the shape is going to look consistent across different neurons. Now, it's not 100% true that all neurons have the exact same shapes in terms of waveform shapes, but they look fairly similar. They will differ. And for example, they're with or actually with is a major one. But that's usually reserved for more advanced neuroscience classes. And so this stereotype refers to this shape. All right. Any other questions? All right. So, we mentioned then that since neurons communicate via these spikes and these spikes are spikes in voltage. What we can do is we can drop an electrode and we can try to record the voltages that these neurons emit. And we mentioned that when you drop an electrode into the brain, there's no guarantee that you get very close to the neuron. So usually what happens is that I have an electrode over here. This is going to be my positive terminal. And I'm going to have some ground electrode that's far away. And so really what I'm measuring, if we assume that the ground electrode stays at some static level, what I'll be measuring is the changes in voltage in this vocal proximity. And even though I'm not right on top of the neuron, if I'm close enough, I'm going to get some detection of a change of voltage whenever there's a spike. But instead of it being 100 millivolts, it's going to be, let's say, 100 microvolts. So, one thousand times less than amplitude.

All right. So then last lecture, I was showing you what raw data looks like coming off from one of these electrodes. We see this slow, unjuating voltage. But then on top of these voltages, we see these big spikes. And these spikes correspond to the neurons that correspond to spikes coming from neurons that we're recording from. And we were unpacking this a little bit. We saw that in this way they form. There are actually spikes of two amplitude. So there are these red spikes here, which have a really high amplitude. And there are these medium amplitude spikes here, showing green. If we just plot them on top of each other, we'll see that they do have different amplitudes. And last lecture, I asked, what does this mean? And you all correctly responded that it means that we're listening to two neurons. So we might have a green neuron and then a red neuron. And what happened is our electrode landed over here. And so even though it's close enough to fear from both neurons, because it's closer to the red neuron, it's action potential, it's spiking pit to pit voltage is going to be higher than for the green neuron. And in this way, one electrode can actually give you measurements from multiple neurons at the same time. I so want to pause here and ask if there are any questions about this. So the way that we usually, what we call this is spikes sorting. And so what we'll usually do is we'll record from these electrodes. And if we see spikes at different amplitudes, we'll talk them about each other and then isolate them into clusters. So here, we'll have a red and a green cluster.

And then those correspond to neurons for whom we can know exactly when they spiked. All right, so from there, we'll get into neural encoding and decoding. This class will primarily be about neural decoding. And we're going to give some more details on how an algorithm works, but then either at the end of the sector or off the next lecture, we'll actually derive the decoder that we're going to be using in this class for the project. All right. And so these neurons, their fundamental currency of information is their spikes. And neurons represent and transmit information by their sequences of spiking. All right. And so this is how information is both encoded from the brain. So encoding means how does how do neurons represent stimuli from the outside world. And so this encoding could be, for example, light, right? You could be looking at a picture and a light of different frequencies is coming into your, as I coming onto your retina, and then being sent into your brain, and then how the neurons represent that light or sound intensity, those would be neural encoding problems. All right. And so in neural encoding, what we try to do is we have a model where the neurons firing rate, so they'll call the neurons, or try the neurons spiking response, why? This is going to be some function of stimuli s. And so that stimuli could be like modatory sound, or again, light or video. All right. And so neural encoding is trying to learn how the neurons represent your stimuli by learning this function path.

All right, everyone. We're going to get started for today. So a few announcements before we begin. I sent out a CCLE announcements with instructions on how to sign up for Piazza and grade scope. And so those are just recapituated here as well as a link to a Python tutorial. If you have only used MATLAB in the past, this tutorial will probably be helpful for you. And then we have also uploaded to CCLE material reading for this class, the lecture notes, and then we also uploaded all the midterms and final exams dating back to 2017. If you're someone who isn't sure if the pre, if you satisfied the prerequisite material, I encourage you to take a look at the midterms and final exams as well as the common filter dot pdf which are probably the most technically demanding for this class. Any questions on any announcement related matters? Any course logistics?

All right, so excuse me. We're going to go ahead and finish off the syllabus. So last time we talked about the grade breakdown for this class and that it was graded on an absolute scale. And I know I went through it a bit quickly at the end, so I just want to put up this slide to ask if there are any questions here on the grade breakdown for the grading scale. All right. So then we had also put up this information about pass no pass or satisfactory on satisfactory grading if you choose to take the class in that manner. We also talked about how for exams during remote learning, the exam are going to be open note open book and you can access your notes and CCLE on your computer, but it's going to be closed internet. And that the TAs and I we are going to perform some analysis on the answers given. And if we suspect anyone collaborating, which are not allowed to do for the exams, we request reserve the right to give a superseding oral exam. Right. And then also if you are in a different time zone, we can make accommodations for you to take the exam at a different time.

And so please send me an email this week if you plan on taking us off on this. We will we use that just to get a sense of how many accommodations we'll need to make and then we're going to send out more details closer to the exam date to handle those accommodations. Any any questions here? All right. I have to slide on academic integrity, which I give in all my classes. And it's my way of saying up front that I care a lot about academic integrity and that we all follow the principles of academic integrity and fairness and respect to our fellow classmates. And so I put up the slide to say that I take this very seriously. And if we catch any students of cheating or violating the principles of academic integrity, that I take that seriously. And I will follow up and report those cases to the dean of the students office. And we will follow their recommendation as they investigate the case and do what they do what they determine us to do. All right. So I just want to put that up front that again. If we if we catch you violating academic integrity, we will follow up on it and report their case to the dean of students. All right. Any questions here?

All right. So with that other course information throughout this class, we're going to cover a wide range of topics, including some intrusion neuroscience, which we'll do for these first two and a half weeks. And then after that, we're going to cover topics in modeling spikes. That's going to be drawn from this theoretical neuroscience textbook, as well as topics from machine learning and statistical signal processing, which we take from this Chris Bishop textbook. And because we didn't want to have students need to to purchase all three books, what we did was we took the excerpts of the chapters that we used for these books and we put those on CCLE. Right. So that material should all be on CCLE. Other notes for this class. So the last two notes that we use in class, I just asked that they not be publicly posted due to matters related to copyright. And so we'll be happy to distribute them in the annotated notes on CCLE. But we just asked that they remain within the class population. Like we said, last time a piazza should be used for almost all major class discussions. And of course, these office hours to get any other questions answered.

But we hope that the piazza form will be lively. And like I mentioned last time, we give bonuses based off of participation on piazza. And so even though you can consider anonymous to classmates, your posting is not anonymous to us. And we make that setting so that we can assign bonuses based off of how much you participate on piazza. And the TAs will be checking piazza also regularly to make sure that any questions that couldn't be answered by students can be answered by teaching staff. If you have a question that isn't appropriate for piazza and it's related to class material, I just asked that you email, Tonmoys, Shashank and I and me together. We do this so that no single TA gets overloaded because in prior classes, sometimes once TA is very responsive and then all the students learn to email that TA all the time and that TA becomes overburdened. And so we just asked that you send us any class related questions to all three of the teaching staff if you don't post it on piazza. And then of course, if you have any personal matters, please email me directly there. Any questions here? All right. Some last notes. I think we mentioned this last time.

It's time consuming to make the transition from that lab to Python. So please factor that into your work. I think it's worth it because Python is the de facto standard for machine learning and signal processing today. I also mentioned this last time this class according to student feedback is a lot of work. And so I want to state this upfront so that you can plan accordingly. We do try to have this class be very fun, but we cover a bunch of topics and test it understanding. So we have seven homework assignments and we're told that those assignments are somewhat time consuming. All right. Like the mentioned piazza should be the primary names of asking and getting questions answered. And we just talked about this on the last slide also so I won't review that again. Any questions here? All right. So with that. Sorry. It looks like I have that was not last notes. I have a few more slides. For those coming with a background in machine learning. I want to say that up front since we start off doing neuroscience and we do derive maximum likelihood solutions for classifiers and regression in this class, which is something that may have seen before.

You may feel the pace of the class is somewhat slow. And then we're going to keep the pace because a lot of people in the class don't have background in machine learning. And I want to make sure that everyone can learn and master the material. And so if you're coming in with the prior background in machine learning, just be aware that the class may feel a bit slower for you. And you can factor that into your decision as you decide what class is to take. And then I like we talked last time. I think we're going to take halfway through lecture because the lectures are fairly long here at UCLA. And in our discussion sections, which we're going to be run live by Tonloi and Shashank. First off, you can attend whatever discussion section you would like. And the TAs will also be recording at least one of the discussion sections to put it on CCLA. And then we have already sent out the P.O.T.S.ing page to send up information so this full of points should not be here. All right, a lot of logistics I just went through any questions on anything that I went through. Okay, so I just want to do brief introductions. So about me and sorry. This is not updated well. I did update the other parts of the slide, but I didn't update this introduction.

This is not my first year at UCLA. This is now my fourth year. And it's my seventh time teaching this class. And so I, I've taught it at Stanford twice with my PhD advisor there and previously taught at UCLA four times. This is a class related very closely to the research that my research group does. And so we care a lot about improving the performance of brain machine interfaces. And then other classes that teach at UCLA include ECU 102 in the fall quarter, so that signals and systems. And then in the winter quarter, I teach a class on neural networks and deep learning. And so with that, I'm going to pass it off to one of our TAs, Tom, why so Tom, why if you can go ahead and unmute yourself. Yeah. Hi, so hello everyone. So my name is Tom, I'm on tour. I will be one of your keys for this quarter. So this is my third time, Tying for this course on neural signal processing and my fifth time, Tying for Jonathan. All of my Tying experience at UCLA has been for Jonathan. I really like Tying for Jonathan and especially for this course. So this course is one of my favorite courses here at UCLA. I took this course first when it was offered for the first time and back in 2017. And I really enjoyed the course material. I also hope that you also enjoyed this course too. So I am a PhD student at UCLA working with Professor Rajudhary and my research in interest, primary lies in reinforcement learning and pattern, exception and dynamic networks. So that's all about me and I hope to have a very enjoyable quarter with all of you. Thank you very much. Great. Thank you, Tom Boyd. And then we have our second TA, Shishank, who won't be able to give an introduction today. We'll ask him to give an introduction on Monday. But this will be Shishank's first time Tying this class here at UCLA and he's of course taken this class before and done, absolutely. And so we'll leave Shishank's introduction for the start of next class on Monday.

All right, everyone, we're going to get started for today. A few in essence before we begin. The first is that homework number one, a reminder is do this Friday, uploaded to grade scope by 11.59 PM. We're also going to release homework number two this Friday. And if you have already submitted homework number one, there are several of you. We ask that you please log in again and assign your pages to questions because when we initially made the assignment, we didn't have the outline. So the outline is there now. And so again, if you've submitted homework number one, please log in again and assign your pages to the question outlines. And then for everyone else who's submitting, please be sure when you log in to assign your pages to questions so that the graders know where to look for your work for each question. I also wanted to answer a question that I saw on Piazza, which is in the homework, there's going to be a signal that you'll see with infinite energy and zero power.

This is the signal one over square root of T, that is in the homework. When you square the signal, it becomes one over T. And we know from high school or college calculus that the harmonic series where you're summing one over T as T goes from one to infinity, even though that decays towards zero, that has an infinite sum or if you were to integrate an infinite area under the curve. And so that's an example of a signal that has infinite energy but zero power. And so last lecture, I said that there are some signals that are neither energy nor power signals. And this is another example of one of those. Okay, any questions on any course logistics before we dive back into material? Excuse me for like assigning the question by outline, just the question number or like part A or part B also? It also includes part A and B. So we created the outline, we'll say it will say one A, one B, etc. And so please assign all of this.

Thanks, Chumlin. Let me give you a. So what you mean is like you you want us to put numbers on each question, right? And you're muted by the way. Sorry. So I ended up using because I forgot to set the mute all to and so thank you Ryan for raising your hand for the question as to what you need to assign. So on grade scope, we have said there's a question one A, one B, one C, etc. And so what you need to do is you need to indicate where on your submitted PDF or your submission to grade scope, which question which work refers to one A, one B, etc. Okay, thank you. All right. Any other questions? All right. So we're going to continue where we left off last time, which is we started to talk about signal models, which are the signals that we will essentially are basic signals that we will use to construct other signals in this class.

And so we talked about our basic cosine wave. And then last lecture, we ended talking about this complex sinusoid, which is this function AE to the J omega T plus theta, which from oilers formula, we can compose at we can decompose as a real part, which is a cosine omega T plus theta as well as an imaginary component, a sine omega T plus theta. And again, with complex numbers, we think of them as a collection of two sets of numbers. In this case, two signals. So the cosine omega T plus theta is this solid line right here. And the second set of signal is the a sine omega T, which is this dotted line. All right. And that's how we should conceptualize such signals in this class. Any questions here? Right. So for, there's also an exponential signal, which is E to the sigma T. You all know what E to the sigma T looks like when sigma is greater than zero, this corresponds to a growing exponential with time.

And when sigma is less than zero, then it's a decay exponential through time. So now what we can do is we can start to combine these signals together. So one thing I could do is I could take a cosine omega T plus theta that's here in this solid line. And then I can multiply that by E to the sigma T, which if sigma is greater than zero, corresponds to a growing exponential. Right. So now E to the sigma T multiplies this cosine. And so each of the sigma T can be thought of as changing the amplitude of this cosine over time. And so sigma is greater than zero, meaning that our exponential signal increases. Then it's slowly going to cause this sinusoid, this cosine, to also increase an amplitude. If sigma was less than zero, then the cosine would be large at negative time and then decrease our damping in the amplitude. And so one common terminology is that this exponential, which essentially sets the amplitude of the cosine, is sometimes called the envelope of this signal because it envelops the signal.

Any questions here? All right. So then we could also have a complex exponential. And so a complex exponential is of the form E. And then it has a purely real part, which is the sigma T component. That's the growing or decaying exponential. So this is equal to a growing or decaying exponential times our complex sinusoid, e to the j omega t. And so what this would look like is a complex sinusoid, again with the real component being this cosine, the dotted line being the imaginary component. And so the solid and dotted line are what you get from e to the j omega t. And then this amplitude is going to be scaled by e to the sigma T. Any questions here? All right. So I'm going to now show you a picture which will return to later on in this class, which is if we have a signal x of t equals e to the sigma plus j omega t, the exact same signal that we had here.

We can see that for different values of sigma and omega and j omega, it's going to have very different behavior. If sigma is bigger than zero, it's going to be a growing complex exponential. If sigma is less than zero, it's going to be a decaying exponential. If omega is small, it's going to be a slow, it's going to be a sinusoid that changes very slowly, where it's omega is a very large number that's going to be a high frequency sinusoid. It's going to have faster oscillations. Right. And so what we can do is we can conceptualize this in a plane where on the x axis, we have the value of sigma. And on the y axis, we have the value of omega. And so like we just said, if you're in the right hand side of the plane, which means that sigma is greater than zero. So here, sigma is greater than zero. This means that the complex exponential grows with time.

And so it's going to be an example like this where we see the, it's going more and more, it's having higher and higher amplitude. Whereas if you're in the left hand side of the plane, so that sigma is less than zero, this is going to correspond to a complex exponential where it decays over time. And then similarly, again, we know that omega here, omega sets the frequency of the sinusoid. And so if omega grows, if you go up on this y axis, that corresponds to faster oscillations because now the frequency of your sinusoid are going to be higher. And so for a complex exponential with some value of sigma and some value of omega, if you plot that sigma and omega somewhere in this plane, you can conceptualize the signal. If the sigma value, if you're at this point of plane, then sigma is negative, so it's going to be a decaying exponential. And the frequency omega is relatively small, so it's going to also weight slowly. Whereas if you're up here, then you're going to have a growing complex sinusoid that has a pretty fast oscillation because you're high on the y axis, you're high on omega. Okay.

All right, everyone. So today we're going to finish going through the sides of this discrete brain machine interface that we started talking about last Monday. And then after that, we'll start doing the tool derivation, which will be used for the project. All right. Before diving in, does anyone have any questions from last week? All right. And then I received a few emails asking about the participation grade for this class, especially some are some are not in the same time zone and therefore can't attend these lectures. And so what this means is for this quarter during the time of COVID, I'm just going to give full participation points with understanding honor system that you'll watch all the seminars, which is typically how I would give the participation points in the past. All right. And so really for this class, you'll be graded on the project, but you'll have received the 80% participation points automatically since this class is now being taught during an extraordinary time. All right. So I want to remind you where we were last Monday, which is we were talking about this delayed reach task where we have a monkey. The monkey touches and holds a center target. And then after that, a target appears somewhere on the screen. In this example, it appears below the center target. And the monkey during this time period develops a plan to reach towards this target. And so from the delay period to the go queue, the monkey is planning to reach to downwards target. And then after if he gets the go queue, then the monkey is free to actually reach to the downward target. And so during this phase, the monkey actually reaches to the downward target. And the reason that we're distinguishing these two is because we want to build a brain-mishing interface where the monkey just plans to reach somewhere and we can decode that immediately and then show that and say, okay, he's thinking about going down.

And the reason that this could be a really cool brain-mishing interface is because you could imagine a system where then someone who is paralyzed is looking at a screen full of targets. And the target has a letter. So this could be a communication prosthesis where they're trying to type. And instead of needing to imagine a reach towards each letter, which would take more time, the person controlling the brain-mishing interface could just plan to reach to each target, plan to reach to the target with a T, then the target with the H, then the target with the E. And we could decode those automatically if we know how to decode planned reaches. Any questions there? All right. So this is a video of the task that I showed last time. I'm just going to show it again to refresh memory. All right. So again, when the target is small, he's planning to that target and then when the target becomes big, he reaches. But that plan of tippy is what we're going to decode. Any questions here? All right. So what we do then is we implant the Utah electrode array. We talked about in a prior seminar lecture into the motor regions of the monkeys brain. And so this area here is the motor cortex. And we're going to aim for a particular area called the pre-motor cortex. The pre-motor cortex is a part of motor cortex. And what pre-motor cortex represents are actions made, are things related to movement that are made prior to actually making the movement. And so plan activity, for example, before you actually make your movement is represented strongly in the pre-motor cortex. All right. So I'm going to then show you what the spikes tend to look like for a typical pre-motor cortex neuron. So this PMD here is an abbreviation for pre-motor cortex. And what we would do is we would have the monkey make many reaches to one target. In this case, let's call it the upright target. And when he makes these reaches, what we're going to do is we're going to record from the neurons on that Utah array. And so what we're going to show here is just one neuron where we do many trials. So remember also last lecture, we talked about how when we want to get the firing rate of a neuron, a measurement, because the neural data is noisy, we need to do repeated trials and keep measuring what the spikes look like to get a less noisy view. And so what happens is we measure from one neuron in every single row of this spike raster that we see here corresponds to a trial. And what you'll see is that in this phase where the monkey is planning, that's when the small target is shown and the monkey plans to it, there is some increase of activity for this neuron. And then when the monkey actually makes the movement, which corresponds to when the go to is given the monkey actually performs a reach, you see all of these neuron, sorry, this one neuron is firing many more spikes and it does so consistently trial after trial. And so if we just calculate from these what the average spikes per second are, what we'll see is that when the monkey plans this upright target, there's a brief increase in activity when he plans and when he moves, there's a big increase in activity that then comes down. Okay, any questions on this plot that I just explained here? Alright, so what we could do is this is for just upright reaches, so this is for upright, we could do this for reaches in all directions. And so I could have the monkey reach up many times and record the activity of this neuron. And what you're going to notice is that when he goes to different directions, whether it be like for example upright versus let's call it left, there is very different to plan activity. So when he goes upright or maybe even right, during the plan activity shown here in green, you see that it increases to some intermediate level.

But when he reaches the left, the plan activity stays low. For up left, it also stays low. And it seems to increase more when you go from a leftward reach towards a rightward reach. Okay, any questions there? Alright, so this is going to be the key feature that we use to then do a decode. Because now if I record from this neuron and I ask and I don't know what target the monkey is planning to reach to, but I record from this neuron and the neuron is quiet since it isn't firing very much, then I can guess that the monkey is probably going to go left or up left or up. But if the monkey if the neuron is firing many spikes per second, then I'm going to guess that the monkey is planning a rightward reach or an upright or a downright reach. Okay, any questions there? Alright, looks for the graph on D. Yeah, looks down like on sort of line on the top. Oh yes, this is showing the monkey's hand position. I think it's showing his X hand position. So this is the X position of his hand. And so it's showing that he starts off in the center. And then when he actually makes this reach up into the right, that his X position is going to increase rapidly and then go to a steady state value. So it's going to increase until it stops here at this X position corresponding to where this target is. Any other questions? Alright, so now we are recording from many neurons with this Utah ray, we get 96 neurons.

And as the monkey is in the baseline state, then in this window, this is going to be the plan period for the lay period. We're going to measure spikes from all these 97 neurons and then the go cue comes and then the monkey is going to make a reach. So this is a reach. And really, the trick is going to be in this plan period, there's some interesting information here that I need to figure out how to decode to predict where the monkey is planning to reach. So let's revisit that neuron that we were just looking at on the prior slide, where remember for the right upright, the right and then maybe the downright target to the neuron fired at a higher level, but for the three targets, like the left, the up left, and the up target, the neuron fired at a lower level shown here in green. So the color reflects how hard the neuron is firing. Right. And so, sorry, I forgot to explain. So this is just looking at the targets in 2D space. So the x axis is x position, the y axis is y position. These are my seven targets that he's reaching to over here, these same seven targets. And we're saying that one way that I can represent the planet of the firing rate is that these targets have a lower firing rate than these targets that have a higher firing rate. Right. And so exactly like we said, if we have this one neuron and I measure that you're that is firing at 100 spikes per second, right. Then I can guess that he's probably reaching to this target here, which corresponds to letter E, because it's going to be E or A. Right. It's not going to be A because A is in this region where it's 40 spikes per second. Okay. Any questions there? All right. So then if you look at this, you can see that there's some ambiguity here. Right. If you measure that the neuron fires at 40 spikes per second, it's going to be very hard to know the monkey was going to see B, A or G, because all of these correspond to when the neuron fires at 40 spikes per second. And so then the way that we get around this is that we don't record just from one neuron. We record from 96 neurons or 100 neurons, 100 electrodes. Right. So each of these will be the tuning curve of one electrode. All right. And if each electrode, if each neuron had the same tuning curve as we show here, we would be totally doomed.

Hi, good work. Hi, I don't know if you can. Good, how are you? I'm good. Happy to take any questions any time. I don't have any questions for regarding the course material. I didn't have a question or two that I wanted to ask. It wasn't related to the course. I'm going to go ahead and wait until the end maybe or something. I'm happy to take those questions. My question was about number two. In part B, it says that the peak to peak amplitude is 110 millivolts for this new alien neuron. I just had a general question. I'm wondering if I'm interpreting the material we had in class correctly. For a regular action potential, it goes from negative 65 millivolts up to is it positive 55?

It goes from the top of the curve to the lowest point. That's correct. We haven't covered this up to the hyperpolarization of the action potential. We have a particular example of the resting potential 50 plus to EK plus. For two B, when they say that the action potential has a 110 millivolts peak to peak, that should be related to part A. You were able to calculate EK plus and ENA plus and you know that the voltages can't go beyond those bounds. If you've calculated in part A, that the range from EK plus to ENA plus is less than 110, then you know that there's a contradiction there. I couldn't understand the relationship between the two parts. I had another question about myelination. Maybe this is not as related to the homework, but what is the difference in terms of specifically demyelination for Parkinson's disease and multiple sclerosis? For Parkinson's disease, so for multiple sclerosis, I believe that, sorry, let me just look at the Parkinson's demyelination. I don't know the answer off the top of my head, but I wonder if for MS, it's for primarily motor neurons. For Parkinson's, Parkinson's is implicated in some of those deep brain areas. I wonder if it has to do with neurons. I think it's the locality of the neurons. Yeah, it's actually specifically, I think this is a stancho Niagara.

That's okay. Or yeah, and the dopamine energy can neurons specifically in that region. Great. Perfect. Thank you for that. Great. All right. I'm not quite sure about like the page 14 of lectures, which is the. I think that I own see. Yeah, I could hold the slide up really quickly. I know exactly what site you're talking about, but just let me. Slide 14 lecture three. He's loading from you right now. Why don't you ask your question while I bring it up? Yeah, so I think you mentioned like the main driver of like how it works is the size, right? It's like the size in a pile.

Energetics is a mix of energetics and size. So for the potassium channel is energetics because the lining side is low energy enough such that sodium will not shed its waters of hydration. But then for the. For the sodium ion channels, which have a high energy, binding site is also size related. Since potassium is bigger and can't pass through. I see. Could you explain again how the energy thing works? I'm not very familiar with all the dining stuff. Yeah, of course. So here's that slide. So what happens is that. For a low energy binding site. So that could be like a binding site to a carbonyl like this oxygen that doesn't have an explicit negative charge like this one is a high energy binding site. But binding to this carbonyl group would be a low energy bonding site because it has a slight negative dipole. But not an explicit negative charge like this. Oh, mine is here. Sorry, let me just see if I can silence this one.

Call from wireless. Sorry. Okay, get someone else picked up. So. If the amino acid has low energy binding site. Yeah, the E in this slide is energy or electric field energy. Sorry. Yeah. Okay. Energy. So if there's a low energy binding site, remember that to pass through it has to shed its waters of hydration and NA plus holds this waters of hydration more closely because it has the same amount of charges potassium but in a smaller. And so NA plus holds many more waters and so if the energy site is low energy, then it's not favorable for it to release all of its waters around it. However, potassium has relatively less water around it. And so it can shed its waters to bind to a low energy binding site. And so that's how K plus can pass through a low energy binding site but NA plus cannot. Does that make sense? Yeah, I'm just thinking about how it works like. Does like the high energy binding site kind of takes the iron out of like the water shell or.

Yeah, that's a picture that you should have here like a when when this NA plus gets sufficiently close. Oh, minus is so attractive that it's going to come down to bind to it, but to bind to it, it has to shed these waters around it so it can make it close bond to it. And so. Yeah. And so. That's that's how the binding site works. And. And the reason. K plus doesn't pass through a high energy binding site is site. Yeah, I believe size is the biggest factor. There may be also things related to confirmation, but. But some textbooks say primarily size. There's one other thing interesting you'll note, which is. I can find it. Yeah, we wrote that K plus channels are 100x more permeable, both the K plus and NA plus. Whereas NA plus channels are only 10 to 20 times more permeable to NA plus and K plus. And so it seems also based off of this that. The selection via the energy site is a stronger filter.

The NA plus channels which are high energy and would cause both NA plus and K plus to shed the waters of hydration. But then K plus is filtered mostly to the size, but then that filtering is not as robust. I see. So you're saying like this property is like way merged from the. Sorry, what were to use there? This is this property is what? This is an emerging property from like the. Energy like by. And the size of the. Iron channel. And the property being that the energy binding is more is better filter. The permeability is like like an observed property of like the energy and size at work. Yes, yes. That energy and the size filtering lead to these select permeabilities. I see. Okay, that makes sense.

All right, everyone. We're going to get started for today. A few instances before we begin. The first is that homework number two was uploaded to CCLE on Friday and it's going to be due this Friday, October 23rd, uploaded to Gravescope by 1159 PM. In general, homework solutions are going to be posted after the late deadline has passed and so the TAs will, they have already uploaded homework number one solutions to CCLE but if not, they will certainly be by the end of today. And then lastly, if you're going to be using late days for an assignment, you don't have to notify us. We keep track of that via the Gravescope portal and we count those late days at the end. We don't have to notify us if you're using a late day. All right, any questions before we begin? All right, so at the end of last lecture, we had to start to talk about systems and so we had defined a system as something that transforms some input signal x of t into an output signal y of t. This should say signal map system. And last lecture, we just went over a few example systems and so I'll just recap one of them. One of them was AM radio where we may have some message xt that conveys information that we want to convey and the AM radio system what it does is it takes your message x of t and will multiply it by a signal cosine 2 pi fct and then y of t then would be the output of our system where again the message the input x of t has been transformed through multiplication by this cosine. All right, so that's just an example system and we'll talk about we'll talk about today several properties of systems. And so on homework number two and throughout the rest of this class will sometimes be asked to show some proper that some systems exhibit various properties and so today we're going to start talking about some of those properties and so a first property is called stability. Okay, and so a system is called bounded input bounded output stable or bibo stable if every bounded input leads to a bounded output. Right, so that's the definition of stability. Let's unpack this and see what it means. So the first thing we want to define is what is a bounded input or a bounded output. All right, so a bounded input is a following. Some input x of t is a bounded input. If there exists a constant n subscript x such that the following is true. The absolute value of x of t is less than or equal to this constant m subscript x which itself is less than infinity and this is true for all time. So let me draw a picture then of what a bounded input, sorry, what a bounded input looks like. So let's say that we had some signal, draw more straight line. Let's say that we have some signal x of t here. x of t is going to be called a bounded input if I can define some constant. And so this constant would take on the value mx on the y axis. This value here is mx. If x of t its magnitude is always less than mx. So if x of t stays below this line then it's going to be a bounded input. And that makes intuitive sense. If bounded means that I can find a constant such that x of t goes no higher than that. And similarly a bounded output is the following y of t is a bounded output. If there exists a constant m y such that similarly y of t is absolute value is less than or equal to m subscript y which is a finite constant for all time. Any questions on the definition of bounded input or output? Alright so then the system is called bivostable when a bounded input meaning that the absolute value of x of t is less than a constant which is less than infinity implies that the absolute value of y t is less than a constant which is less than infinity. So that's what bivostable means. Give me an input that I can bound and it's going to be bivostable if I can also bound the output. Alright so let's go ahead and do some examples. So the first one that we'll do is a and radio where again a and radio means we take some input x of t and the system is I'm going to take x of t and multiply it by cosine of omega ct and together that's going to give me my output y of t.

Right? Let me just go ahead and make my t is copus one second. So tonwards of cosine. Alright so we want to show whether a and radio is bivostable or not. Right? And so if a and radio is bivostable what that means is that if my x of t is bounded then y of t is going to be bounded. Alright? So to show it this is stable I'm going to start with the assumption that x of t is bounded. So I'm going to assume that x of t is bounded. So it's less than some constant and x. Alright? Now if I take this assumption and through math I can show that a y of t is also bounded by some constant. Then I've shown that a and radio is a bivostable system. Right? So let's go ahead and see if we can show this to be true. Right? So if x of t is less than mx then we'll follow mathematical argument. If I were to take the absolute value of both sides I would get that the absolute value of y of t is equal to the absolute value of x of t times cosine omega c times t. Alright? And this we know is equal to the absolute value of x of t times cosine of omega c t. It's absolute values. I can still have the absolute value. Right? Now remember for bivostability I want to show that the absolute value of y t is less than some constant. Alright? So can someone tell me what a next step would be if I want to show that y of t is less than some constant?

Feel free to either raise your hand or write it in the chat. Great. Okay. So Andrew says explain that cosine is bounded by negative one and one. Okay? How on with the same thing? So yes, we know that cosine omega c t this is a function whose maximum value is one and whose minimum value is negative one. And so for and therefore the absolute value of cosine omega c t has to be less than or equal to one. Right? So that means that I can write that this is less than or equal to the absolute value of x t times the maximum value of this term and the maximum value of this term is just equal to one. Okay? And then I'm going to use my last relationship here. Here I have assumed that x of t is bounded so x of t can be written as less than some m x. And so therefore this term absolute value of x of t is also less than or equal to m x. And so this is less than or equal to m x. Right? So we show that as long as x of t is bounded, then when we plug in the algebra for this system, we also get that y of t is less than some constant m x. And therefore y of t is bounded. And since bounded x of t leads to a bounded y of t, we can say therefore a m radio. The a m radio system is stable. Right? Okay, any questions here? All right, no questions. So then I'm going to go on to the square. So the square is y of t equals x square. And so therefore I can write that the absolute value of y of t is equal to the absolute value of x squared of t. Right? And this is equal to the absolute value of x of t squared. All right? And I want to show that the system is by those tables. So I'm going to again assume that x of t is less than or equal to m x. If that's the case, then this expression, the absolute value of y of t is less than or equal to m of x squared, which itself is some finite constant. Right? It's a number of times itself, m x times itself. And so since I can bound y of t by a constant, then y of t is also non infinite. And therefore I can say that this system, the square is also by those tables.

All right, everyone. So it's been two weeks since our last 189 class. I was going to pick off where we left off, but before that, I want to stop to ask if there are any questions about overall class logistics, anything about this class. All right. So what the rest of this class will look like is today, we're going to finish deriving the tools and equations that you need to build a brain machine interface for cursor control. And then next week, we're going to release the project. So next week, I'm going to release the project assignment on CCLE. And what we're going to do is in class, we're going to go through the data together, be sharing my screen. So the project has three tasks. And what I found in the past is that it really helps the students a lot if we do want to pass together. So the project has three tasks and we'll do tasks one together for the project.

And then hopefully that'll give you a pretty good jumping grounds to do the rest of the project. Which again, should not be extremely time consuming. I would say it's about equivalent to two ECLE 102 problem sets. And you all, you have several weeks to do the project. All right. So lastly, left off, we were talking about the problem that we want to solve, which is equivalent to that video that I showed you at the very start of class of the 52 year old women who was controlling a brain computer interface, the cursor on the screen to type on a keyboard. Right. So we said that this is called a regression problem. And what we want to do is we're going to have data where we simultaneously record the position of a cursor on the screen. And the information that we're going to get out is velocity.

So we had this vector x k, we're k denotes time. And x k is going to be a 2d vector that contains the x velocity at time k and the y velocity at time k. And we're going to have x k, x k plus 1. We're going to have this for all time. And simultaneously to this, we're going to have neural data, which are spikes from 192 neurons. And we talked about how this data will become formatted as a spike raster. So again, next week, when we go through the project data together in class, we'll actually see this spike raster matrix where every single road corresponds to a neuron. So this is the spikes of neuron 1, the spikes of neuron 2, the spikes of neuron 3. And every column corresponds to a millisecond in the trial. So this is the first millisecond, the second millisecond, the third millisecond, etc. And what we do to count the neural data is recall we want to get a firing of rate. And so what we do is we count the number of spikes that happen in some window. So last lecture, we said, let's call it 50 milliseconds.

So in 50 milliseconds, I'm going to count how many spikes happened for neuron 1, 3 spikes happened for neuron 2, 3 spikes happened for neuron 3, 0 spikes happened all the way down to 192. All right. And so this is going to be YK, my vector of neuron firing rates at time K. All right. And the goal then of this problem is when we want to build a brain machine interface, we want to calculate some function of Y of K that predicts my velocity X of K. All right. So this is saying, given that I observed some neural data in the future, I want to pass that through some function F that tells me what my velocities should be. And that then lets me do the following. Let's me record a paralyzed person's neural activity. Pass it through a function F to get the velocity of the cursor and then update the cursor's movements on screen. And so that was very yet. We were going to try to learn this function F. And so we talked about just how to do a simple 1D example.

We're going to derive the answer in 1D. And then I'm going to tell you the answer when you have multiple dimensions like 2 and 192. The reason we're going to derive the answer in 1D and then I'm going to tell you the answer for 2 and 192 is because in the 1D case, we're just working with scalars, which we can differentiate. It turns out that you can differentiate with respect to vectors and matrices also, but this requires a bit more formalism. And so in this class, we're going to develop the principles to derive it in 1D. And I'm going to tell you the answer in multiple B, but you'll see that the answer in multiple B is like a multiple dimensional generalization of the 1D example. So in the 1D example, let's say that we just had neural data from neuron 1. And so that's why super-ship 1 of k. This is the neural data from neuron 1 at time k. And on the y-axis, we have the x-flossy at time k.

And then we said we had the monkey or the human do experiments. And at every single point in time, we recorded the number of spikes that neuron 1 fired and the velocity of the cursor. And so this could be for k equals 1. Here for k equals 2, we have this neural activity and this velocity for k equals 3. We have this neural activity and this velocity. And we want to learn a relationship that tells me how to get the x at time k from y1 at time k. So we want to learn some function f that tells me the x at time k from y1 at time k. Any questions here? All right. So last lecture, we decided we would just go with a simple veneer model. And that's what we're going to do in this class. We'll talk about later on in this seminar lecture how to make this non-linear, which is actually very easy after we do this simple veneer example.

So we'll start off with a linear example. And so last lecture, we said that if we model the velocity as a linear function of the neural data, right? So in calculus, we had y equals mx plus b. Here it would be the velocity, kyw is equal to a times the y1k, which is the x axis value, plus some y intercept b. So b here is the y intercept and then a is the slope of this line. And what we want to do is we want to say in our model, if I model it to be this way, I get to choose a and b to make this fit as good as possible. So that when I later on observed neural data, I predict the y velocity well. And so we said, if I choose a and b to be, so if I choose b to be this value and a to be this slope, this red line is a pretty good. And so this is a very bad choice of a and b, whereas this green line here is a very bad choice of a and b. I shouldn't choose b thick and b big and a negative.

And I asked at the end of last lecture, we can obviously see that the red line is better than the blue, sorry, the red line is better than the green line because it passes through more of these data points. These blue data points seem to show an awkward trend. But then if we want to be able to state this mathematically, we have to be able to define how good these lines are via rigorous math. All right. And so the ideas we talked about here are the basic ideas of machine learning. And so I asked class last time, how is it that we know that a is good and b is, sorry, that red is good and green is bad in a mathematical way. And so I'm going to at the end of last lecture said, well, what we could do is we could look at the errors between the blue points and the predictions from the red and the green lines. And so let's say that this point here is my 10th data point. If I had the neural data at this value, right, my red line would predict that the velocity should be this value, whereas my green line would predict that the velocity should be this value, right?

And the red line has a smaller error to the blue point than does the green line. All right. So let's say this blue point was for k equals 10 to 10th data point that we have. This error at salon 10 from my blue line to my, sorry, from my blue dot to my red line is smaller than from my blue dot to my green line. All right. And now it might not always be the case that every single data point is closer to the red and the green. We also, let's say we have this purple data point over here. Let's say that this was the 11 data point. So we have Y1, 11 and then the X time 11, right? This actually has a smaller error to the green line than it does to the red line. Right. So this epsilon 11 is smaller has a smaller error under our green bad model than under our red good model, right?

All right, everyone, we're going to get started for today. So a few in essence, just one announcement actually before we begin, which is a reminder that homework number one is do this one day up the fatigue rate scope. Any questions on any course logistics? Question from Jonathan. Yeah, I don't have a question on administrative stuff, but I have a curiosity on some of the biology. This is an okay time to ask that. Sure. Okay, so one of the things that we've been talking about is myelination of axons and nodes around VA. And I'm curious to know what is the scale of the difference in size between a myelinated section of axon and a node of around VA because a node of around VA can't be like a single point in space. It hasn't have a size.

So do you have any idea of like what's the scale of maybe how many nodes of around VA are on an axon and how much larger the myelination sections are? Yeah, so the myelons used to appear to be one to two millimeters. And then the nodes of around VA, the bare patches are about two microns on length. Oh, excellent. It's right on this slide. Thank you. Great. Yeah, thanks for the question, Jonathan. All right. And then any other questions? All right. So today, we are going to finish in the first half of lecture, the basic neuroscience, and then after that, we're going to move on to talk about experimental setups and get into firing rate statistics.

All right. So just a recap last lecture, we talked about passive properties of neurons and how they have membrane resistance. Those are the ion channels that go from that take ions inside to outside the cell or vice versa. They have a membrane capacitance because the cell wall has positive charges and negative charges separated across two plates, which reminds us of a capacitor. And we talked about how these sets the dynamics over which the membrane voltage can change. And then we also had talked about how propagation happens or the types of parameters were interested in terms of neuron propagation, how there's this internal axial resistance and that along with CM, first the axial resistance and RM dictate how far a charge can propagate and then RAMCM detect RAMCM may affect action potential speed. And so we had also discussed the slide here on action potential velocity and how the action potential velocity is a function of parameters of the cell, including the cells by ammeter as well as the thickness of the cell wall or the cell wall plus myelination.

And I want to pause here and ask if there are any questions recapping anything from last lecture. So Professor, when you were talking about how the action potential speed is correlated to one over RA times CM, do we not take into account RM in this scenario? Yeah, so in this scenario, this has to do, so when we say velocity, we are conceptualizing how along an axon, the action potential spike travels along the length. And so RM, the resistance here is certainly going to affect the voltage, affect how far it propagates. But RM here in terms of time only affects how quickly the voltage will change from inside to outside the cell. But then for action potential speed, we were curious as to how this voltage changes propagating inside the cell. And so that's why the parameters of interest will be the axial resistance and the membrane capacitance, but not the membrane resistance. So the membrane resistance does affect the overall action potential amplitude.

Any other recap questions here? That's a great question, Brandon. All right, and so the last slide that we ended on last time was talking about the nodes of RON-VA, which is how action potentials can propagate over very long distances, even though the voltage is attenuating and can convey that information with high fidelity. And so because information is not certain, the amplitude of the action potential, only on the fact that action potential happened, we learned that the nervous system uses these nodes of RON-VA to essentially regenerate the signal every one to two millimeters. And so at first off, we talked about how the mile in sheep's, what they do is they effectively increase the width of the cell wall. And therefore, they decrease the capacitance because now our positive and minus chargers are further away from each other. This distance here has increased. I think I called this, oh yeah, deep. And so because of this lower capacitance, there is faster propagation.

And also there is less charge that needs to go into filling the capacitor because the capacitors are smaller. And so what this means is that across these mile in intersections, the action potential both travels faster. And even though it attenuates, it attenuates less slowly. And so it's able to make it to the next node of RON-VA, where as long as when we make it to this next node of RON-VA, the voltage is above the threshold needed to start a positive feedback loop, these nodes of RON-VA are filled with a ton of voltage-gated sodium ion channels. And so as long as the voltage is above threshold is going to re-initiate the feedback loop, that then will regenerate the spike and the spike can travel down the mile-innated axon until the next node of RON-VA, etc., etc. Right? And so that's the mechanism by which essentially you have a repeater, this node of RON-VA, you can think of that as a repeater that regenerates their signal every so often and allows you to then convey this action potential over very long distances, including axons that go from your brain all the way down to your toes.

Right? Any questions here? All right. And I saw a question that Chad, a great stature, because of decreased resistance, and Tom William said, reduce capacitance, also reduce resistance, or if you were able to reduce the axon resistance, you would also increase the action potential speed since it's inversely proportional to both of them. But for the particular mile-innation, it's because of the reduced capacitance, like Tom always said. All right. Any questions from any of this recap? Question from Shishank. Prof. Shishank, the technique that you have marked there, isn't it only supposed to be the technique of the mile-in sheet, and are in the charges supposed to be positive on both ends and negative on the interior of the cell wall?

Thank you, Shishank. That's a really great point. I've drawn this wrong. So Shishank is right. D is this distance here. This is not inside and outside. The inside is just inside the cylinder. Thank you for that correction, Shishank. All right. Any other questions here? All right. So now we're going to head on to just the last topic, which is throughout these early lectures, like Kat saying, that we're going to see the action potential at different 10,000 foot view, or 1,000 foot view, et cetera. This is going to be our most in-depth view at the action potential now, and we're going to talk about the key dynamics that be to the action potential shape.

And so we've talked a lot about how action potentials are generated, and we have a hint of several things, and we've talked about how the surprising edge is due to the influx of sodium. And we've talked about how the falling edge is due to the efflux of potassium. It's interesting to think about how they originally came to these conclusions and how they originally mapped out the dynamics of the action potential, which will, again, give us a even clearer picture of what's going on during an action potential being generated. And so there were experiments, which we're going to talk about, but researchers back in the range of the 50s and 60s were interested in learning exactly what types of flow of ions led to action potentials. And they had some clues, for example, if they had low extracellular NA plus potential, and that would be to a low action potential amplitude, which made them think that the rising edge of the action potential is caused by the influx of NA plus. And similarly, they had evidence about K plus being responsible for the falling edge. But then the reason that this is hard to study is because of these voltage gated ion channels.

All right, everyone. We're going to get started for today. A few announcements before we begin. The first is at homework number three with uploaded to CCLE last Friday. It's going to be due this Friday, uploaded to grade scope by 11.59pm. On grade scope, you also have the option of submitting homework regrages. And typically, we're going to open them for one week after we release the homework grades. And so when you submit regrages, that question will go back to the greater, the reader who created that question and the reader will be able to assess for comments and determine whether to give you back points. And so that's how regrages should be handled for this class. All right, we also saw that on Piazza, there was a post about how long the homeworks are taking you. And there's a poll that showed over 30% of students are taking 15 to 20 hours or over 15 hours to do the homework. And so I want to start off by saying the homeworks that we are giving are of similar length and difficulty to the ones that we gave in prior years. However, we know that this year is not normal in particular.

Of course, we're also dealing with the pandemic and with online teaching. And we understand how that could lead to homeworks taking a longer amount of time. Given the poll that was on Piazza, the TAs and I discussed how we responded this. And we propose to do the following, although I'll be happy to take any other feedback. First, although we've released homework number three already, what we're going to do is effectively shorten it to be 80% of the original length by giving you full points to these three questions on the homework. So these three questions comprise 20% of the homework points. And you don't have to do them to receive full credit. And so if you left these questions blank, you'll get the full 20% points on those questions. That said, we still encourage you to understand how these questions are solved and to be able to replicate their arguments because they're very game for the exams. The TAs and I will also look to shorten future homeworks. And so we'll try to write for example, less sub parts for some of the questions. And then the PAs also communicated that feedback received in discussion is that MATLAB is very time consuming. And so we aim to, although we're still starting out the details, we aim to distribute a MATLAB dedicated discussion video each week as well to help with the MATLAB part of the homework. All right. So I wanted to take a pause here and ask if there are any questions about any class related logistics.

Viana. Hi. So you mentioned that those three problems for homework three are still fair game for the exam, even though that they're not graded. And I was wondering, is it possible that even though the homeworks are shorter, we have access to maybe the original problems that would have been on them so we can have additional practice for the exams? That's a great question. I'll discuss that with the TAs. I guess one potential thing that we could do is we could release what the original homework was going to be but then dedicate a subset of the questions to the optional. And so not sure exactly what we'll do there. I'll discuss that with the TAs to figure out what's the best thing going forward. But thanks for that suggestion. Viana. Any other suggestions? All right. And so with that, we're going to get back to material. So in last lecture, we had talked about this concept of the impulse response. And we had this fact that if I have any linear time invariant system, then as long as I know the impulse response, which is how that system responds when I input a delta into the system. And as long as I know this impulse response, I can calculate the output of the system, Y of T. For any input X of T. Again, as long as I know the impulse response. So this impulse response is a whole characterization of the system. And last lecture, we did ride that the way this happens is via this convolution integral. And the solution integral is the manifestation of this fact on the prior slide, where, as long as I know the impulse response, H of T. I can calculate my Y of T.

Given any input and the way that I do that is I complete this convolution integral. And so this convolution integral again, and is usually, we talked about notation last week, or usually, you might see this denoted X star H of T, which is the rigorous notation. But usually in this class, we'll write this as X of T. Convolved with H of T. Since that's how most of the role that had a convenience. Right. So any questions on these concepts? All right. So we talked about the intuitions of what convolution is doing. Admittedly, this integral can be complicated. And so we talked about how to intuit it with this remonion sum slide, which is something that again, we encourage you to review those parts of the lecture videos and materials to make sure you understand those concepts. And we also talked about how to compute it using the flippin drag technique. And so last I left off lecture, we had given these example questions, and we had written the solutions of these convolutions. I'm going to do just one of them to recap how we do the flippin the drag method. But then I want to take any questions on what people, if people had any questions about how to solve these convolutions. Let's say I wanted to convolve this input X of T and this impulse response H of T. And so what I would do is I would take my impulse response. Here in green, and I would flip and drag it.

And so when I flip it, this impulse response ends up being over here. I haven't drag it yet. So it's leading edge corresponds to the impulse response. Flip and drag that time T equals or out. And if I advance this by one second, so that, sorry, if I delayed this by one second, so that now the impulse response I'll draw this in orange was at this location. That would be my flippin drag impulse response at time T equals one. Move it over one second if I moved it over. So it was over here. That would be for T equals to. And then we said for the flippin drag, what we would do is we would multiply the input, which is the black rectangle. And my impulse response. Multiply them together and then find the area under the curve. And that would be my convolution. And so when I just flip my impulse response and I'm at T equals or when I multiply my orange. Sorry, let me actually let me erase this orange one. So it's less confused. When I multiply my green. And I'm at the black rectangle. And my black rectangle, they're not going to overlap. And so they're going to be just a zero signal. And I've integrated that. It's going to be zero. And so at time T equals zero. My convolution is going to be zero. And then if I were to drag this rectangle to the left, meaning that T would be negative. And it would never overlap. And so it would be a zero convolution at the result of the integral of a zero signal would be zero for all this time less than or equal to zero. Now the interesting thing is when I start to drag this rectangle. So it starts to overlap with the black one.

So let's say I dragged it by a time T equals 0.5. Oh, sorry. I wasn't keeping track of my x-axis. This would be 0.25. And earlier when I said earlier when I said that the orange wrecked was over at time one I met time T equals 0.5 because I wasn't paying attention to these axes. Apologies for that. So if I drag it halfway over, which is at T equals 0.25, then when I multiply these two rectangles together, I'm going to get a wreck that has with 0.25 and height of one. Alright, and so at time 0.25, the overlap of these two rectangles when I integrate it will also be 0.25. And so at time T equals 0.25. The area under the curve is 0.25. So as I continue to drag this rectangle to the right as it overlaps this black rectangle, they're going to have more and more overlap leading to a higher and higher integral until at time T equals 0.5. That's this time over here. T equals 0.5. They're fully overlapping. And so when I multiply them and integrate the area under the curve is 0.5. And so this pink point is T equals 0.5. And we talked about last lecture as I drag this rectangle in the trend at which increases is going to be allowing. Alright, and then as it drags out, we're going to have a line decreasing. And then after time T equals one, which is when the rectangle. When the impulse response rectangle is at time. There T equals one. Then they no longer overlap and the integrals is there. So with this same procedure, you should be able to calculate or you may be already calculated the convolution of these three as well. I want to pause here and ask if there are any questions on any of the answers.

All right everyone. So we're going to start off for today for ECU 189. For today, if you go to CCLE, you'll see that in the week. Eight materials, I believe I've uploaded the final project for this class. And what we're going to do today is we're going to go over the project and the data so that you can be prepared to tackle it. The project, you'll see consists of three tasks at the end. And for the purposes of today, we're going to actually already do one of those three tasks and hopefully you'll see that it's not a something. And so to go through and introduce you to the data sets and the code, I'm going to be sharing my net lab screen on my computer. But my computer is right now also compiling the ECU 102 lecture that we just had and also showing my video. And so if it's running to slow, I may turn off my video for just a lecture. Let me go ahead and share my net lab window. Right. Can everyone see a net lab window here? Or can someone give me a thumbs up or I meet yourself and say yes or no? Yes. Okay. Great. Thanks. All right.

So last lecture, we had derived the equation to go from mapping neural data to kinematics to velocities via least squares. There are a few more details in that lecture about training and testing data that we didn't get a chance to talk about yet. However, I thought it would be better to just go over the project data first and if you had time, we'll talk about those things later on. But it's not, we'll cover them next week, but you don't need to know them to do the product. So the goal of today is to really just get you all the, I guess you set up so that you can do the project. So let me just move around windows. Okay. So on CCLE, we put up the 189 project PDF and there's a lot of description in there. We're going to walk through code today that essentially goes through that description. And so please read the description again, even though hopefully I will be clear after we go through some of the code. We gave you a data set, which is this J are 2015 12 of our truncated to dot max file. And so this is going to contain the data recorded from a monkey while the monkey was making reaches and we were recording neural data so that we could get training data to map neural data to reaches. We also uploaded a helper function, then, which is a supporting function that that will use to make our lives simpler. And then the critical thing that should be on CCLE is assignment code plus part one dot M, which walks you through building a decoder. And walk through that today, as well as it does part one of the project. All right. And so, let me just look at part one of the project. Sorry, I should have the PDF open.

Let me just. Part one of the project is to build a decoder with with a low pass filter, which will do in the slides. Part two is to use an intermediate or high pass filter. So it should not be too difficult to generalize the code that we're going to look at today to do part two. And then part three is more open ended. So we give. We give the idea to say what about other features of the neural data like the derivative. And so, and so we'll. We leave that a bit open ended to you all. Okay, so if you were to load, if you were to open the assignment code plus part one, what we have here is a bunch of map code, which walks you through the data set. So we're going to go through that all together now. I can't see the chat and I can't see raised hands. And so if you have a question, just unmute yourself and please, please feel free to just ask it. So what I'm going to do is I'm going to go ahead and load this data. So I'm running this first cell. And what you should see is that it drops. A data variable called big R into our workspace. Right. And so what big R is, is it is an array of structures. And so if I just type R. What you're going to see here is that R is a one by five hundred and six structure ray with these fields. Right. So you may not be familiar with trucks or raising or you supply via familiar with the raising that what this means is that R is something an array that has five hundred six components. So I can reference R of one. This is the first component are I can reference R of two. This would be the second element of R. Now every single element of our itself is a structure. And what a structure is in MATLAB is it's. You can essentially think of it as a data structure that hold some custom data that we wanted to write down. Right. And so first there are five hundred and six of these structures because again R has five hundred and six elements.

So each of these elements, each of these are corresponds to one trial that the monkey did. And so we're giving you a data set where there are five hundred and six trial. And then for every single trial, we write down information. So if I want to access the 10th trial, I would do R of 10. And so what are 10 would show me is information about the trial. And so it would include information like where what was the target that the monkey reached to on this trial. And so if I look at if I asked you what target is the monkey reached to on the 20th trial, you would do our 20 and you would look at the target field here. So again, our 20 is a struct and then our 20 dot target is going to be a 3D vector where the 3D vector tells you the X, the Y and the Z position of the target. And so the position is always going to be minus 70. So we really just care about X and Y. We just care about 2D. And so in this first cell right here, what I ask you to do is I ask you or what we do in the code. I don't ask you to do this. We say what are the targets of the monkey reaches to. And so what I've done here is I'm going to iterate over every single trial. Now R is just going to return 506 a number of trials. So for a for loop over trial, 1 to 506. I'm going to plot the X position of the target and the Y position of the target with a marker. So if I run this cell. I'm running right now and it's normally not the slow, but again, my computer is doing too many things right now. Do people see a figure has appeared? Or do you only see the mat lab? You only see the mat lab. Okay, let me show my entire desktop. I'm running a share screen only shares the current screen that you're on. Yep. Right. So I'm sharing my desktop now.

Let me run this code again. I can see the traffic. All right. So do you all see a plot now that has appeared? Yeah. Yes. So this again is iterating through all 506 trials and it's plotting the target location of that the monkey was reaching to. I can see that there are only nine unique targets. The target is going to be either zero zero and X position. 84.85 comma 84.85. This would be the upper target, which is zero and X position and 120 millimeters and Y position. And so there are only eight unique targets at the monkey reaches to at the periphery and then center target. All right. So those are the targets the monkey reaches to. We also have fields like if I were to do our. We must look at the 20 trial again.

There's a trial like is successful. And this is a Boolean is either one of the monkey successfully acquired a target or zero if he didn't. And so the reason that we have this is because. You can imagine if the monkey was failing a child, we may not want to use that data to learn our model. And so. What I could do is I could define the successor ray, which starts off empty. And then I'm going to loop over all the trials and then every single time. I. In the for loop, I'm going to just copy down the value of. I got it successful, which is going to be one if he was successful and zero if he wasn't. So if I run this code. It's going to loop on through. And if I look at now what success array is, what you're going to see is it's a 506 dimensional. Array or vector vector where every single element is a one. And so if I do the sum of success array to the equal 506 and that tells you that every single trial that I've given you was successful.

All right. We have quite a few people here so I'm happy to do a race and system where if you raise your hand then I can call on each of you and Brandon you can go first, and you should be able to meet yourselves. Yeah, so, Professor cow I was just wondering, um, what's the monkeys name in the video. That monkey was named George. Yeah. And then we'll show you later on when I show you my experimental setup, which was the rig that I had built actually in that same area, but it's a totally modernized for 2D cursor control. You'll see a video later of a monkey called Jenkins. And so usually in the papers, we just write monkey G or monkey J. But yeah, each of the monkeys have had their own unique personalities and whatnot.

Cool. Arthur. Hi, Professor Tao, I had a question on number five on the homework really quickly. Great. Let me just pull it up. One second. Sorry, so the homework is just downloading for me right now. It's taking some time. I'm not sure why it's taking so long. Let me just try to save the pdf. Cannot be opened. Okay, sorry. Let me just open up an old homework number five from homework one from prior year. All right. I wanted to ask about like for the myelin sheets for like part B or does the myelin sheets around the axons and neurons strictly improve the conductance of the action potentials or is there like drawbacks to it? Yeah, so for, Sorry, you're saying this is for 5b, right?

Yeah, because I was wondering, like, or that question was just in general, but for like 5b, I was wondering, like, what does it mean when it says, like, is it worth it? It's like, are we comparing, like, do we want species A versus species B? Or I was just confused about the wording of that. Yeah, so for 5B, a potential con of myelinating is that it takes up more space. And so, looking at the answer in 5A, we wanted you to see that, because we know that action speed is going to increase if we increase the diameter as well. And so both of these things take up more space but which one is better. And from the calculation five a you should have seen that it was better to have myelination, then just the compared to the wider diameter neuron. Yeah. And so therefore, myelin helps.

Can you explain again why, since they're both thickness of like 1000 micrometers, right, when you do the calculation, can you explain why it's better to have the mile and sheath than versus the bigger diameter? So I'm just wondering how to, how to show this without showing the actual answer by sharing my screen. What you should see is that. The other one in in we accept both solutions so in one case you might find that you have in a little are for the radius in the diameter, sorry in the denominator, or else, or else, a radius squared term in both cases, it's the what the neuron that has more myelination is going to get a much bigger change in speed, since you're changing one of the denominators by a factor of 25, compared to about a factor of two, or a factor of four if you had the R squared in the denominator. or four if we had the r squared in the denominator. Okay, thank you. That helps a lot. Okay, great, yeah. All right, while we're on this, can anyone unmute if you have any further questions on question number five and then after that we'll continue to go down the list. I actually had a question on this one as well. Okay. This one is like the last part of five.

Okay. Well, I mean, five A and five C. Five A, do we have to draw an RC model? Sorry, this is for question five A you said? Yes. For question five A, when you say draw an RC model, you mean do you have to draw a resistor and a capacitor circuit? I quite literally do have to draw one because I use like proportionality to reason through it. Yeah, you don't have to draw it. All you have to do is calculate rA times cm. And so I, since I will set the time constant, so you don't have to do any drawing of a model here. Okay, great. And then for 5C, is the y at the end, just a repeat of the first question asking what is the purpose of these nodes?

It is. We should remove that in future homework. Yeah, we're just asking what the purpose of these nodes are and how do they function. Great, thank you. Great, thanks, David. I also had a question on 5A. So for the area for, so both the resistance and the capacitance use an area, and I want to clarify that in this scenario that they're different, right? That is correct. Yeah.

So for the capacitance, the area should be 2 pi r times the length. For the resistance, the area should be a pi r squared. You think you'd draw that out? Yeah, sure. Let me grab my iPad really quickly so that I can share the screen. So, I'm just going to join the Zoom room. Let me share my screen. Let's do one more thing, which is stop the audio of my iPad. All right. Alright, so for 5A, we want to compute an R axial times C membrane.

And in this particular question, we should look at And so our axial is going to refer to this equation, where it's going to be our a which is some row, which is going to be a constant that's the same for for both neurons, and divided by the pie a squared so this will be the surface, the A here would be this radius right here. And the axial resistance is going to be a function of the area of the cylinder. And the intuition for that again was that if we have, if you have the same amount of ions there are less things in the way for your na plus to move through and so if there is more space than the resistance should be lower. And so that was the rationale for how we got this row pi squared. So this quantity is going to equal row times. which was our, where's the slide, yeah, little rA, which was our resistance in a particular, for a particular length in Cm, had the equation rho, rA equals rho over the area, which is pi times R squared.

All right, everyone. We're going to get started for today. So just one announcement. One second. All right, great. Just one announcement before we begin, which is that homework number two is do this Friday uploaded to grade scope by 11.59 PM. Any questions on class logistics? All right, so we're going to continue talking about the impulse response today. And so last lecture, we had started off with the motivation of why an impulse response. And we said, well, oftentimes in life when we are interacting with the system, we may not have the luxury of knowing exactly what the system is. What is the function that it implements? Or maybe we only know it imperfectly. Further, even if we did know what as well as it could take on a complicated form. And so if we don't know what S is, how are we going to calculate what a system does to an input to transform it to an output. And so the impulse response gives us an answer to this question. It says, as long as I know the impulse response, I don't have to know exactly what S is. But if I know it's impulse response, then I'm going to be able to calculate the output, which is my Y of X. For any input given which type Y of T, Y of X. I can calculate the output Y of T for any input X of T. And so though I don't know S, I can get from X of T to Y of T as long as I know what the impulse response is. Right. So this is a very powerful tool for in particular linear time and varying systems. So the last lecture we said, well, what is the impulse response? What it is is if I take some system here, capital H, and I apply an impulse at the input.

I put the input to the system being the direct delta. Then the output of the system is my impulse response. Alright. And so this function here, this is the impulse response. So very straightforward, intuitively again, what's the app on my system when I put an impulse, that's the impulse response. But we'll see that with it, we can do very powerful things. So last lecture I had mentioned this subtlety about the difference in the T's on the left and the right hand side of the equation. I mentioned this because I made this mistake when I was an undergrating this class. And so I just wanted to explain this one more time since just to clarify it. And so if I have my impulse response, H of T, which is the output of my system H when the input is an impulse delta of T, the T on the left hand side for H of T and on the right hand side, this T here are not the same. Right. So what's the difference? So let's take a system where I have an impulse delta of T, that's my input. And it's going through a system H. And now this system H in particular is an integrator. And so the system H is going to integrate this input. We derived either last lecture to the lecture before that the integral of the impulse is the step function. So the impulse response of the integrator system is a step function. So the step function is the output when my input is a delta. Right. So the T on the left hand side, which I'll do here in green, the T on the left hand side refers to the value of the impulse response at a specific value of time.

So let's say that little T is equal to one. Right. So what the T on the left hand side is. This T over here is telling me that I want to go to time T equals one and measure the value of the impulse response. Okay. So this would be the impulse response H at time one. Okay. On the other hand, the T on the right hand side. So the T here is something that varies across all time. Meaning if I want to integrate my impulse, I'll have to know the value of the impulse from negative infinity up to time T. And so in general, the T on the right hand side is going to be a T that isn't just the finite time at one point one time point, but I'll need to know multiple values of what this function X of T or delta T was at multiple times. I need to know that to integrate it. I need to know if value from negative infinity to T. And so the output, the impulse response at a specific time T on the left hand side in here in green is going to depend on the input at several times T on the right. And so in particular, it's going to depend on the value of the input from negative infinity all the way up to time T for this particular integrator system. And so that's why you can't just plug in the same value for T here. Okay, any questions there. All right. So with that, this side again is just explaining what we said on the prior set. I'm putting it here for completion. We have a question from one. This is just more of a clarification. Like it makes sense now the different T's and stuff, but the left hand T is that the same T as the upper bound of the integral that we have inside of the H function right now.

Yes, in this particular example, that is correct. So this one. This T here that says the T in the argument of H is going to be the same T as the upper bound of this integral. I'm sorry, I think my internet went out for like a split second. I think it just did it again. Okay, it's going the T here is the same as the T here. So that's correct. I also just realized that I have a little type of it. I want to correct actually make this actually tell detail. So what you said is correct one. Thank you. And Marga. So why is the in the system is X of TOW detail? How come we're not integrating with respect to T? In this system, we are saying we want to calculate the area under the curve until a time T. So when I do an integral, I could call this whatever variable I want. TOW are just a dummy variable that tells me I'm going to be integrating along the X axis up until sometime two. Okay. Alright. Alright, so then at the end of last lecture, we were also describing a time invariant impulse response for a system that is time invariant. This impulse response will of course also be time invariant, meaning that if I put adults into the system and I get out an impulse response that looks like this. If I have a delay by time TOW sorry for these typos.

If I have a delay the impulse now by a time TOW, then my impulse response is going to be the exact same shape, but now delayed by a time TOW. Okay. And so this is a nice property that happens if we have a time invariant system. Of course, we know delay in the input means corresponding delay in the output and give me one second just to make the T is host. One second. Alright, so that's for a time invariant system. Now we're going to start to see how we can use the impulse response to show this fact that we had on this slide, which is as long, even if I don't know what the system is, as long as I know the impulse response, I can calculate my output for any input. And so before we do that, I just want to give one more terminology thing, which is something that is called extended linearity. This is a very simple idea. It earlier we had our concept of linearity, which is that if I apply a system, H to inputs X one and X to with X one X to being added, then if a system has linearity, sorry, A X one plus B X to if the system has linearity, this is equal to a times H of X one plus B times H of X to. And so I call this linearity, some people call this extended linearity, so this is for terminology. Extended linearity extends this definition of linearity to end input instead of just two. And so for extended linearity, if you have H applied to the sum of, sorry, this is correct. If you have, each applied to the sum of an, an XN, that's going to be equal to the sum of an, right, so this is this is saying that, H applied to A one X one plus A two X to all the way up to A and XN, this is equal to A one H of X one plus A two H of X to all the way up to A and H of X and. You can see definition of linearity applied to and inputs. And then the reason that we talk about this is that there's also continuous version analog, which is instead of having a sum here, we could have an integral, right. And so right here, we're writing linearity in the script form here. It isn't continuous form, which is to say if I take a system H and I apply it to a sum, now represented here as an integral of constants A, tau times. Some X of T minus tau, that's the same thing as taking the sum of my constants A times the outputs of the system applied to X, which is Y.

All right, everyone. I had mentioned, I think, I don't see style here right now. He had a question at the end of 102. When comes an off against question. Yeah, so, I hope everyone had a good Thanksgiving break. And hope most of you were able to take a look at, at least read over the project. So, I know we went over a lot last lecture in terms of just going through the MATLAB data. And so, I want to start off this lecture by just taking any questions you may have on the project setup, the project code, etc. All right, I'm, I, I plan for most of the lecture to the project questions. If there are no questions right now, what I could do is I could at least finish off.

So, let's start with lecture six, where we were talking about these squares from several weeks ago, and then give you some time to also think about any project questions to talk about. So, I'm just curious as to how many people started the project. So, I'm going to put up an anonymous poll. Although, I'm not going to be able to see the responses. So, one of the students left it, one of you will have to write me in the chat. I'm just curious if you started the project and answer yes for yes and no for now. All right, and then can someone tell me what the percentages are? Hey, how can we tell that? Oh, you all can't see it either. I think like the ton, a ton, why and all the other TAs can know we can't because we're not host. Okay, that's, let me see if I can. Let me just answer yes and see for my iPad and see if. She, let me try to launch the poll for my iPad. So, I think that I can see the results on my iPad, but I cannot see it.

I can see it on my computer, poll and progress, posts and panelists cannot. Okay, never mind. So, I don't think I can do this poll. Honestly, who has? I have it. If people are happy to share the, they start the project, you can write yes and chat. I'm not just wanting to get it. I just, I understand if not, it was Thanksgiving. It was Thanksgiving weekend. Okay, so based off of this. The project is doing a week. We'll, we'll give an extension on the project until. A Friday of next week. And I will then take the time to answer any questions you have on the project as well on Monday at next lecture. I just want to make sure you all have an opportunity to ask those questions so that the project is not.

Is not overwhelming. All right, so. I'm going to just. Overview where we were, which is something that you use for the project, which is in the project. I'm going to give you data from a monkey and. The monkey has simultaneously recorded kinematics and neural activity. And in the 189 project, we actually get out this kinematics and that neural activity. So the kinematics were the R dot cursor pause. All right. And then. The neural data is the R dot spike rasters. And so. We also talked about how we've been the data so that we get the. The velocity kinematics every 25 milliseconds. And we similarly get the neural data every 25 milliseconds by counting the number of spikes that occur in a thing.

Right. And so that's our XK and our YK. And then we talked about then. We talked about the, what we want to do is to derive a decoder, the decoder, what we want to do is we want to take new neural data YK and multiply that by a matrix L to get my kinematics, my velocities XK. Right. So I need to learn this matrix L. And we saw that if we set up this question. With this decoder, we got a linear equation X equals L Y. We're big X and big Y. Big X are my neural data's contaminated across all time. And big Y is my neural data can cadmated across all time. Which would be your neural data can cadmated across all time. And then X pin would be your neural data can cadmated across all time. So your X pin again, remember has a 2D velocities. And so we would have a VX and a VY. And you have this for the first time bin.

The second time bin. All the way up to the big K time bin. All right. And in this case, big K in the data set that we gave you is going to be equal to 16 465. And so we have 16,465 X and Y velocities. And then we also have the same thing for neural data. So for neural data, we had 192 neurons. So we have Y1, Y2 all the way to Y192. And then we have this just constant row of 1s that we talked about at the bottom. And we have this at time 1, at time 2. All the way up to time big K. So there's a Y big K. And so this matrix would be 193 by big K, which is 16 465. So then we have this big X equals big L times big Y. And then we told you that the answer, which is found in the analogous way to the least squares example.

We didn't 1D is going to be XY transpose times YY transpose inverse. All right. And we showed you how to do this in that lab. L is equal to X times Y. This apostrophe is a transpose. And then this inverse is this big minus 1. And we do Y times Y transpose. And so in the 189 project code, that is this right here. L equals, so another way to write it is X times pseudo inverse of Y. This PN of Y is equal to this expression Y transpose inverse YY transpose. And so here in the code, we do that exactly L equals X bin times the pseudo inverse of Y bin. And so this gives us our matrix L. And then that matrix L tells us how do we decode new neural data coming in. So now if we were to run an experiment forward, we're trying to decode the intention of someone who's paralyzed. We read out their neural data. And from that neural data, we get a 193 dimensional vector that has the number of spikes on the 192 neuros and our constant one.

And so we'll call this new neural data Y tilde. Okay. And all we do to get the kinematics is we take Y tilde K. And we multiply it. We pre-multiply it by the matrix L. And that will give me my decoded kinematics. And so in the 189 project code. That corresponded to this for loop right here, which starts off by iterating over new test trials, our test. For each new trial, we get out the neural data that we've never seen before. That's why test and we've been it. And then to get out my decoded positions, I do L times Y test. And so that gives me X test, which are my decoded positions. And then, and then I compare those decoded positions eventually, or I guess in the code first, we plot those decoded positions. That was this plot that we saw last time where the center out trials are pretty good, but the center back trials are not good. And then, and then we can compare those to the actual true positions that we recorded in the experiment to see how off we are in that led to our mean square error metric. Okay, so I just want to ask any questions on any of that since that's the key component of this project. All right. So now I want to talk about extensions of this least squares algorithm. So you'll recall all two meetings ago.

All right, everyone. For today, we have two announcements. The first is that homework number one is due today uploaded to Grayscope by 11.59 pm. And this morning, Tonwoye already uploaded homework number two onto CCLE. And homework number two will include a Jupyter notebook, and so it includes Python coding. Again, this is your first time doing Python coding. And you're, for example, transitioning from that laptop to Python, please just budget in some time for that. We have just a few things for the homework. Question one C was about patch clamp, and I had removed some slides on that in the interest of time. So patch clamp is a technique to measure the current through a single antenna. So this is the answer for that question one C. And then in question two G, you'll need to use a technique called least squares, which hopefully you have from a prerequisite class.

And here we're, we're reminding you of that solution. And then in lecture today, we're going to be talking about expectations. In the last question, the homework, you will also have conditional expectations. And so we've given that definition here, but we'll talk about distributions and give a probability refresher today in class. Any questions? All right, so we're going to get back to material. And so last lecture, we had finished the basic neuroscience by all of you part of the class. And now we're getting into actually modeling the action potentials that neurons fire. And we talked about how we might have a task where, for example, and we'll see this in this class, the monkey is controlling a tracer and moving it on a screen. And the spikes are going to be indicative of the movement that the monkey wants to make. And so we will be interested later on and how to interpret these patterns of spikes and use that to decode the movements that the monkey intends to make. And we had given a virtual lab tour last time showing some of the recording setup and whatnot.

All right. Any questions from last lecture in the setup? All right. So broadly, when we look at what spikes mean, they fall into two categories, which are neural encoding and decoding. So neurons, we know that they transmit information by the firing of a sequence of spikes. And it's the pattern at which they fire that encodes information. Remember, it's not the spike shape, but the actual pattern. And these patterns are used to represent all types of information. And so neurons, the visual cortex, they will be involved in coding or encoding. Stimuline the natural world like a light coming into your retina. All right. It can also be audio waves coming into your being processed by your cook. All right. So neural encoding is how we map these external stimuli from the world into a neural response.

We're going to talk about a few encoding models in this class, especially some tuning models. We'll see in later slides. But that'll be the extent to which we talk about neural encoding. And this class will be focused more on neural decoding, which is the map from the neural responses, like spikes, to the stimuli. And the stimuli in this case could be the motor action. So I want to decode how a monkey intends to move his or her arm so that the monkey can move a cursor on the screen or play pong like in that most recent neural link video. All right. So in this case, we attempt to reconstruct this stimulus or the motor action from the spike sequence. And this is what will spend more time extensively discussing during this class. So before that, we'll just talk a bit at a high level about neural encoding. And that's what these next slides will go through. Before I move on, any questions here?

All right. So neural encoding. So in neural encoding, what we want to do is you want to go from an external stimulus to a neural response. So you see, it can be a neural response. And the first thing that we're going to talk about is some of the difficulties in modeling this, which leads to some techniques we see later on. So again, when we do neural encoding, what we want to do is we want to record from a neuron and understand how it represents some external stimulus. And so let's say that the stimulus is audio. And so let's say that you're listening to an orchestra. And so the stimulus would be, for example, let's say you're at the very beginning of the concert and you hear the obo playing obo or violin playing the concert A, which is the 140 Hertz audio wave. All right.

And what you want to know is this audio wave goes into the air, last cochlea. And then eventually the air, the hair cells in the cochlea are going to send information about the sound wave being heard to neurons in the temporal lobe. Right. And so let's say that it sends it to a neuron here, which I just denote by a circle in the temporal lobe. All right. And so ideally we can just record from this neuron and then we would be able to treat a relationship between the frequency of sound heard, the stimuli and the neuron. All right. But it actually isn't that simple. And so one of the first challenges that we'll find is that spike sequences reflect both in intrinsic neural dynamics and temporal characteristics of the stimulus. So temporal characteristics of the stimulus, this just refers to how this stimulus is changing over time.

So let's say instead of just 144, 140 Hertz wave, you're listening to now orchestra music. That's a changing stimulus over time and that's going to be represented in this neuron. Right. So the second thing temporal characteristics of the stimulus, that's just again, relating how the stimulus affects the neurons firing rate. Right. Now what do we mean by intrinsic neural dynamics? What this means is that this neuron isn't in isolation. Rather it's participating in a neural circuit connected to other neurons. And so all these other neurons I'm going to draw also a circles and these all have connections to each other. All right. And then maybe also it turns out that the year cochlea has projections on to some other neurons as well. All right.

So now when I record from this one neuron here and I see that it's neural responses, spike chain changes, I need to understand if the change in this neuron or if this neuron spike train is reflecting just the external stimulus or if it's also reflecting internal dynamics meaning that all these other neurons are also inputs to this neuron and could also cause it to fire. All right. And in practice, of course, it's going to be some mixture of the two. All right. And so that complicates relating how we can map the external stimulus to this single neurons neural response. Right. Okay. Any questions there? All right. So that's the first challenge.

A second challenge is that features of the response could change on the time scale that's faster than the inter spike interval. Right. So first let's define the inter spike interval. The inter spike interval is merely the time in between two spikes and we're going to be talking about this a lot today when we get to post on processes. We know that because neurons have a refractory period that the time in between spikes has to be at least four milliseconds and realistically is often more than 10 to 15 milliseconds more than the absolute more than the relative refractory period. All right. So let's just say the absolute refractory period period of four milliseconds. If a spike fires every four milliseconds, then the most time that it can fire in one second is 250 times. And so we call that 250 hertz. Hertz means a rate.

And so it would be 250 spikes per second. This is spikes per second. So that's the fastest that a neuron can fire. But if I just consider, for example, we were talking about listening to an orchestra and an oboe playing a concert A, right? A concert A is already a 440 hertz signal, meaning that the time between consecutive peaks is around two milliseconds. All right. And so this signal is changing faster than a neuron can spike. Right. And so this poses additional challenges for how such fast changing signals would be represented in the neural system. Okay. Any questions on this challenge? All right.

Hi David. Hi Dr. Cao. How are you doing? How are you? I'm doing well. How are you? I'm doing well as well. I just woke up actually. Okay. I had a couple of questions regarding last homework.

Yes. Also, a question about the last assignment. I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that.

I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that. I'm not sure if you can answer that. questions regarding last homework? Yes. Also a question from lecture. All right, let me pull up the last homework. I ended up submitting last night but I had some conceptual things. Yes. All right, I have the homework up. Great. So this is in reference to the multi-ion species question.

So last time we asked about, I asked about equilibrium versus steady state, and so like you mentioned that equilibrium is a situation where it's like a single ion species that can come to a situation where no ion is really moving. There's no net movement, there's no movement, but like a steady state it's like no net movement. Am I interpreting that correctly? The key difference to the steady state is that in steady state and equilibrium, there is both no net current, but in steady state, you need to put energy into the system. gradients so that you can maintain these unequal drift and diffusion currents for each ion species so that the ion species concentration, the diffusion currents don't reach some steady state value. So still the steady state and equilibrium eventually do come to like a no net movement. Yeah, both of them result in no net current. No net current. Not necessarily. I see now. So you're saying that, okay, that makes sense because with your steady state, you can still have a chemical gradient as we see in the Constant voltage.

Yep, that's right. But to do that you needed to pump and the pump isn't there, and leak channels and sodium channels would still be present, I'm guessing. Yeah. Wouldn't the neuron just equalize or equiliberalize slightly higher? It wouldn't. There would be a...or... It depends. Let me pull up the slides, just so that I can have the diagram to point you to. All right. So Okay. So the reason that we that we still need the pump is that for the K plus channels these three on the left.

Overall K plus is still leaving the cell. And overall, and a plus is entering the cell. So, if the pump wasn't there, then it would reach. Then the diffusion currents in the blue. This would be getting smaller and smaller. Okay. So, So if you were to pump like for any plus ions out and three k plus ions in, then it would reach in a slightly different steady state, and the VM would be different because essentially this thing is saying what the steady state concentration of K plus my sense. Only the, the, the sodium potassium pump is pushing na plus that. And so if you didn't have that you would have a ton of influx of na plus in, and this overall system would reach some different equilibrium would be probably through leak channels, right? Because the sodium potassium voltage channels seem to be a bit more finicky.

It's like they require more force to get through. Yeah. So the channels are primarily K plus, and a few and a plus channels but primarily K plus. The thing is the the new equilibrium if you didn't have this sodium potassium pump would be likely a higher voltage. I'm not sure what the new equilibrium would be without the na plus k plus pump, but it would be a different concentrations and if it were at a higher voltage then, you know, if the nervous system didn't have this na plus k plus pump. I imagine there is an answer. Since, again, yeah, these blue arrows will be changing to reach the actual equilibrium, this blue arrow, either this blue or this orange arrow has to oppose the other one. Yeah. Or like the some of them eventually right. like there would be a constantly changing concentration.

And so that's why I think it's- For each channel. Yeah, for each channel. That's why without the NA plus K plus pump, I think it would just require a bit more thought to think through that hypothetical situation if it would be possible. Yeah. Yeah. But I guess that actually makes a lot more sense as to why it's important that the pump is there.

It's like, without it, it would take a while like without it, it's just natural processes. So it would be it's more efficient for the neuron to like, get there. So they can fire for the get ready to fire for the next round. Yeah, and then it'll interact with other things like if the if the at the equilibrium, if there is an equilibrium without the NA plus k plus pump, and it causes the equilibrium voltage to be for example higher than, then I guess like the the voltage gated ion channels that have evolved in a different way. Because, yeah, so so at least this is a system that we have now. how this, if this would reach a different equilibrium without this pump. Right, okay. And then to clarify about the pump too, the pump is constantly sort of working throughout the whole action potential, its effect is not really observable.

All right, everyone. We're going to get started. So for today, announcements are a reminder that homework number three is to this Friday. And last lecture and on CCLE, we announced that 20% of the homework three questions are going to, you're going to automatically receive full credit for them so you don't have to do them. So be sure to check out the CCLE announcement to make sure you know what those questions are. A heads up, the midterm is not this Monday, but the Monday after November 9, 2020, and it's going to be held during class time. If you're in another time zone and cannot take the midterm during this time, please be sure to have emailed me already. As we said in the beginning of class, all the past exams from prior quarters that I've taught this class are on CCLE. I want you to note that we usually hold the midterm in the week of the Veterans Day holiday and in former years that holiday occurred later on in the quarter.

And so the practice midterms, the last year's midterms, the past year's midterms on CCLE also included material on Fourier transforms, which you will not be tested on in this midterm. So this midterm will only cover material up to and including Fourier series. All right. And so we'll probably finish Fourier series on next lecture or maybe even today's lecture. And then with respect to the timing, we're going to send out an announcement on CCLE closer to the date about the timing of the exam. And when we expect you to finish an upload to grade scope by, right? Any questions on those core statistics? Okay. And then I want to take a poll on the pace of the class. So again, like I mentioned for the homework, this is a unique version of a class where we're teaching this solely online and over zoom. And so I wanted to launch this poll to get your feedback on how the pace of the class is going thus far.

And so I'm going to launch this poll and it's anonymous. Please answer as you feel truly. And then I'm going to ask the TA to send me the results of the poll since I cannot see them right now. All right. And then TA, can you just send me the poll over on the chat when I enough have filtered out? Let me know if I need to end the poll for you to see the values. Or can you see them right now? Yeah, we can see the right now. And 96 out of four, while either two students have answered. And 97, yeah, and keep coming the percentages, please. Okay. One percent of students say it's too slow. Three percent of students say that it's slow.

And 40 percent of students say that it's just a right. And 44 percent of students say it's too fast. And 11 percent of students say it's too fast. Okay. Yeah, I want to say that it's too slow. And 34 percent of students say it's slow. 40 percent of students say it's just a right. Okay. 44 percent say it's fast. And 11 percent say it's too fast. Okay. Thank you. Okay. And the poll now. All right.

So, thanks for this feedback. So it sounds like we're airing on the side of too fast for this class. I will take this into account when trying to explain this material. And again, feel free to stop me for questions. And if you have any suggestions for any particular feedback where we could help to get the pace right, feel free to let me know via email. All right. And thanks for the feedback again. Any questions on material or not material admin and announcements? All right. So we're going to continue where we left off last time. So at the end of last lecture, we were going over the intuition of the Fourier series and why we want it. And we talked about how the Fourier series, they have implications for LTI systems. But they also helped to extract different structure in the signal in particular.

The frequency structure, that is, when I see a signal that looks like this in the time domain on the left. And what kind of sinusoid at what frequencies are they composed of? And if I can see the structure, it can help to give me more intuition or more insight sometimes over what this signal is. And so we've given this example a few times that this is a C major chord in music. And while it looks very complex in the time domain and the frequency domain, it looks very simple and elegant. And so there could be additional information, additional insight, I mean, not information, additional insight from looking at a signal in the frequency domain. All right. So we also give the bottom line last lecture, which I'm just repeating here. We're going to derive all of these results today. And the bottom line is the following. If I have a signal FFT and it's well behaved, we talked about how last time the lecture by this we mean that it's. It doesn't have discontinuities.

There are a few other conditions, which are called the derelict conditions that are beyond the scope of this past. But if you're interested in what well behaved means, please look into that further. If we have a well behaved periodic signal FFT, then we can write its Fourier series as the following. FFT can be written as a sum of complex exponentials each the Jk omega not to. Recall that this is a cosine plus a sign an imaginary sign a J times a sign times a Ck. And really the magic is in what are these Ck's the Ck's tell me how much of each complex exponential I need to how much I need to weigh each complex exponential by so that when they sum together, they give me my original signal FFT. Right. And today we're going to derive what those Ck are. So again, that's a high level of you of Fourier series what the rival of these results. But again, the statement is I can write my function FFT as a sum of complex exponentials. Any questions here? All right. So we last left off lecture with this concept of the eigenfunction. And eigenfunctions we said are these functions where if I have a system a function or a signal is called an eigenfunction. If when I put this signal into the system, I get back out the same signal except that it's scaled by some value a. Right. And so in this case, a is a real number and here it amplified my complex exponential in general. And time why asked this is a clarifying plus and last time a can be complex.

And so it doesn't just have to be a real value, it can be a real plus and imaginary part. So a could equal some x plus j times y or equivalently some r times e to the j data. Right. So it can be a complex number. If you look at the complex number representation as a phaser, what this tells us is that it can get scaled up or down. That's r and then this e to the j data means that it can get phase shifted left or right. The signal can be shifted left or right. Right. And so again, high level. And eigenfunction is when I put that function into the system, I get that function out scaled by a. And now I made this claim at the end of last lecture and I told you we would prove it in this lecture. And this is the first result for LTI systems. The eigenfunction is for LTI systems complex exponentials are eigenfunctions of LTI systems. So if I take any complex exponential. And I put it into an LTI system that complex exponentials going to come on the outside scaled by scaled by some value. All right. Any questions on this concept? Okay. So we're going to go ahead and prove it now.

All right everyone, sorry for a bit of a wait start. Reminder that the project is due this Friday by 11.59pm emailed to my email address here at cowatces.ucla.edu. All right, I want to start off this class going over any questions about the project. I had a question of part three. Part three, yep. So for the suggestion of a decoding from differences, when I sort of had a wide-bend snooved set equal to the formula used left there, I had a matrix that was missing that was shorter by one column, so then the rest of the decoder wasn't working. So I wasn't sure it was sort of alterations to X spin or X test would be required. Yeah, that's a great question, Michael. If you do the, so if we just had data Y1, Y2, let's say we just had five data points and then corresponding kinematics. And Michael is saying that when he does the differences, right, you need two values to calculate a difference.

So his new values would be pairs Y2 minus Y1, Y3 minus Y2, Y4 minus Y3 and then Y5 minus Y4. And now we have five X values, but just four Y values. And so the question is then what alterations are what we make to the X's? I'm curious, has anyone run into this and have an idea or want to share what you did? And this is for the task three of me doing the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, one where the Zh That's a reasonable solution, which is Y2 minus Y1 uses data over a window. Let's say that the bin size was 10 milliseconds, so Y1 and Y2 use data over 0 to 10 milliseconds. And so maybe we use the x value at 5 milliseconds, which could be approximated by taking the average of x1, x2. Since the value at 5 milliseconds would be the average between x1 and x2, the average would be the linear midpoint between a line connecting x1 and x2. So that's one solution. The solution that I would do is I would just take x2, x3, x4, x5. And so I would chop off the first value. That is one other solution. You could use x1, x2, x3, x4.

In essence, this is something that I might think of as like a design choice. The reason that I would use x2, x3, x4, x5 is if I was under the rationale that I should use the most recent data. So if I need to calculate Y2 minus Y1, I've had kinematic data up to time bin 2. And I could say that this is the derivative that corresponds to the data time bin 2 therefore. So like this is the derivative at time 2. So there I'm defining that x prime of t, x prime of t would equal x of t minus x of t minus 1 over delta t. Where you don't need the delta t because the delta t is just a constant. So that's what I would do. But in truth, you could do any of these as long as you give a rationale for what you choose. I should say for this project, you don't have to give a rationale. But in other settings where you make a choice like this is good to make sure that you have a reasonable or a reasonable rationale for your design choice. Great. Any other project questions? Yeah, I think I think I did number three like this. Do we also have to do like the Y2 minus Y1 values for the Y test values? Yes, you do. Yeah, so this is related to a question. I think Brianna asked last week, which is when you make a change to your Y data in training, you want to make sure that that change is replicated everywhere and test as well. But because you want your test data to have the same statistics and distribution as your training data sense, you're expecting that your test data will look like what you change your decoder to do. So when you do these differences or when you do any smoothing, you want to make sure that you also do it to the Y data. Okay, so I think I think I did it right. Question mark. And the like I grafted and the resulting graph was like just a bunch of dots. Yeah, so I think that we said. Yeah, so I think I remember this from last year also. So I put on this question because I was at a conference one year and a researcher at another university told me that they had good results when they when they use the derivative to decode. But I believe that if you just use the derivative to decode, it performs poorly, although someone else can write in chat if you've done this to see if that's actually the case.

And I think that students in the past may have been able to get. Okay, or under the rationale that if I add more features, I can do no worse right at least in training data that we talked about seminar lecture. Some students will do like why then and they can animate D Y bin. And then see at that helps. And so the rationalist follows maybe D Y bin has very little information about the kinematics. And so when you decode just D Y bin on its own, it doesn't do well. But it might still contain information that when combined with your original neural data leads to a better decode. So there's a field of electrical engineering called information theory. And this is sometimes called synergistic information. So very interesting term that says some data may not be linearly related to the kinematics. So somehow if I incorporate this data with another observation, then it could be that the data is more formative and that's called synergistic information. Okay. Did that answer your question Jonathan? I think so. So should I or like am I doing something wrong or like so I'm not doing something wrong if it's just like a bunch of dots. Yeah, so if you got that D Y bin decoded very poorly. First off. And then you went into class right now if you just decode off of D Y bin and you see that it is poor or you've already done it and you've written your report saying I decoded D Y bin and it was really bad. I would give you full credit for for part three. That's sufficient.

And then my description here was to say if you were interested in trying to push it further. You try can tell me in D Y bin as an additional 192 features on top of your original Y bin and maybe that does better than Y bin alone. But answered Jonathan's question if you decoded off of D Y bin and you saw that it was awful and you. Then your conclusion could be if I just decode off of D Y bin, I don't have good performance. Okay, cool. Thank you. I also ran into the problem. So all I changed was the Y bin. I changed Y bin into D Y bin like the with the formula and also Y test into Y D Y test with the formula. And I ran the code and it was like it was seg faulting where I was supposed to calculate mean square error. Oh, not loud was seg faulting or or it was like it says like you access like too many you access out of the array of. I'm not sure if this is just like an answer if I could it the other part wrong the D Y's wrong, but yeah, yeah. Sorry, I'm just curious. Did not lab the matlab crash and you had to reopen it or did it just throw an error? No, it's just through an error is it okay? Okay. Yeah, I have had matlab seg fault in the past, but I found that it usually takes quite a bit to get it to site fault. And so I think that tells me the magnitude of the error. Yeah, so I think that. To debug this. So what I would do is I would go into your for loop and and put a break point so with the visual editor for matlab, you should be able to insert a break point. If not, you can also just insert a statement here that looks at a single trials, you could say like if I equals one meaning the first trial.

All right, everyone, we're going to get started for today. So just one announcement before we begin, which is that as per Tanwei's announcement on CCLE, we extended the homework number two due date to now be due a week from today. So it'll be due Monday, April 26, uploaded to Gradescope by 1159 PM. All right. Excuse me, any questions on any course logistics. Alright, so I want to remind you of where we left off last week which is that last week we started to look at plus on processes as a way to mathematically model. The spikes that neurons fire. Right. And so we're going to define the process more formally today. But what we considered was that there's a timeline on the timeline. They're going to characterize the so called inter spike interval, the time in between spikes and so little t one is the time from the process start to the first spike little t two is the time in between the first and the second spike little t three the time between the second spike in the third spider, etc.

Right. And we said that we would define for this Poisson process, we would define these inter spike intervals to be exponentially distributed with a rate lambda, and that all of these TIs were independently and identically distributed. Right. to define the exponential distribution. And so we set a random variable big T with rate lambda bigger than zero. And this rate lambda has units of spikes per second. This big T is exponentially distributed. If it's density function looks like the following. When T is less than zero, it's zero. And when T is greater than zero, it's this lambda E to the minus lambda T, right?

And it has this shape like in red, right. And then we also mentioned that it could be described by a cumulative distribution function, which is the integral of the probability density function. exponentially distributed random variable, then the probability that big T is greater than some time little t is going to be e to the minus lambda little t. All right, any questions on just any of the setup thus far? All right, hopefully relatively straightforward and you probably encountered the exponential distribution in your first probability class. All right, so last we left off then, we were on this slide where we were going to quantify some statistics of interest for the exponential distribution, in particular the mean and the variance. All right, so the expected value of the random variable t that is exponentially distributed we know follows this formula. And we didn't do this derivation since it's something that you've done in a prior class but we've put it in the online notes.

And so you can see the notes for the integration by parts from which you can derive that the expected value of the exponential distribution, expected value of T is equal to one over lambda. All right. And so we mentioned that, or right at the end we were saying, what does this expected value of T mean in words? And so this expected value of big T, right, big T is a random variable that for the exponential, for the Poisson process is going to be describing the distribution of these inter-spike intervals. And so the expected value of big T is gonna be the expected value of these inter-spike intervals, which means it's going to be the expected amount of time I need to wait before I see my next spike, all right?

And so in words, the expected value of my exponentially distributed random variable is the average time in between spikes, in between events, right? And if this is what our exponential distribution looks like, the expected value is going to be the mean value that my random variable big T is going to take on. It's going to take on low values with high probability and high values with low probability. And so the expected value is going to be somewhere in the middle.

All right. So whenever we see a result like this, it's also good to make sure things make sense. So the first thing that we could check are the units, right? So remember lambda was a rate with units of spikes per second, right? And so we would expect the expected time in between spikes have units of seconds, right? And so one over lambda will have units of seconds per spike, but it'll be the massive time in between spikes. All right, so the units make sense.

And another thing to make sure that makes sense is, what happens if I change lambda, all right? So this distribution in red is this exponential, is this function right here. We saw that at time t equals zero, right? F big T of t is just equal to lambda because I have lambda times e to the zero. So this value right here is lambda. Let's consider that lambda is big. Right so if lambda is big.

This means that my neuron fires many spikes per second, then I rightly should see that the expected the average time between spikes will decrease. If lambda is big my PDF right is going to go up to a larger value of lambda. This will be lambda big. Right. And then remember for the probability density function, the area under the curve has to equal one. So if for lambda being big is starts off higher, it better decay to zero more quickly. And so, if you look at this distribution here in blue, and you ask what's the average value of time, right, then let's say lambda was equal to this value. The distribution starts at a lower value, and the area under the curve is one and so when it exponentially decays it's going to have a more drawn out tail. And here is expected value would be larger.

Right. And that makes sense because if your neuron is firing less spikes per second, we would expect that the time in between spikes should extend. Any questions here or on any intuition? Alright, so the other quantity that would be of interest, that was the mean, would be the variance. And you should recall from your probability class that variance of a random variable is defined as follows. It's going to be the expected value of big T squared, which is called the second moment, minus the expected value of t minus expected value of t squared. And then this quantity here, if you wanted to compute it, it would be the integral from minus infinity to infinity of t squared f t of t dt.

of T squared, F T of T, DT. Whatever is in this expected value bracket is the term that multiplies the PDF in this integral. And we won't do the calculation, but if you do the integration by parts, which again is in the posted lecture notes, you'll get that this is equal to one over lambda squared. You can see that this answer ought to make intuitive sense to what is what this is telling you is that as lambda gets bigger, the variance of my spike times is going to get smaller and smaller. Right. You can see that in the blue, in the blue lambda is small we have a slow decaying PDF like shown here in green, and the spike times can take on values across a much larger range and therefore have greater variance.

Okay. Right. Everyone happy to start office hours, as always, if you want to speak about something that you don't want recorded just let me know and I'm happy to turn off the recording. Okay, Professor. Oh, so I actually had confusion about the, the one that you make the discrete in the class but I think my confusion mainly come from when you said like, it's not because of the law, total probability that we expand the party into the sun. Actually I wrote something. Can I share the screen. Yes, let me, let me make sure it's enabled. You should be able to share now. Okay yeah. Oh sorry, wait a second I think there is a problem on my side. Oh did you guys, can you guys see my screen? I cannot see it. Okay. You may have to hit the share button after you select the window. I made that mistake. Okay. Like, this is what you wrote on the lecture note right.

So, the concrete case is something like this right so TS more than SS minus one s minus two. So, you said is not because of law of probability, but in the class I interpreted it is because of the law of probability that we can write in term of the summation, like this. But, so yeah, any subtlety that I confused myself. Yeah, I'm not sure. I actually have in the past said that is a lot total probability but it's really just a subtlety and definition. The law of total probability takes a, a, and B, and sums over all cases of be to give just the event A happening. In this case, we have two events A and B. We aren't trying to just get the probability of one of the events, which would be the law of total probability, but we are doing something law of total probability ask, which is that we are essentially writing out all of the cases of Tn less than or equal to S out, which gives us a sum.

But, strictly speaking, we're not doing marginalization out of a random variable. We're still calculating the probability of two events here. We're not taking the probability of two events and then marginalizing out one of them. So that's why I said it's not the law of total probability. Okay. Okay. But it seems the calculation only makes sense in this kind of way. Yeah. Yeah. Yeah. So this is a reminiscent of the law of total probability. So we can transform this less than or equal to sign here into the integral over a density.

So the key thing is that tn can be less than or equal to s so we have to consider all possible values of big tn and and changing this tm less than or equal to s into the integral over tm equals t is the is the key insight there. Oh, I see. Yeah, but also I searched on the, I don't know, the Wikipedia, it said like the, there is a continued cases for the, I don't know, the law of probability. It's kind of similar to what in the end you take to the limit and that's something like that. So, yeah. Yeah. I guess I searched in the 10 minute break between the lecture and the office hours. Yeah, so in this case, the the multiplication Can you see my mouse on your screen. Sorry, see what can you see my mouse on your screen. I saw like you draw some like lion dash lion circle before. Okay, when I scroll the screen is gone. Got it. So, um, so I'm going to just annotate it. So this is still the law of total probability, because we are going from two variables, down to one. So, this is a lot of total probability, that's all good, because at this point we're kind of splitting hairs rigorously, it's not. Yeah. Okay, I see. But the intuition over of summing over all possible events that that is applying here.

Okay, thank you. Yeah, let me stop share. And then I saw David, yeah. I was hoping, and I don't need to bother other people, I was out of town, so I didn't see the tour of the lab, which I don't need to bother others. I can come back at another time when everybody's not asking questions. Yeah. Does anyone have any quick questions that we could go over right now?

Or are people fine going with the lab partner. I also realized, actually the monkeys only shown in the beginning of the lab tour so I'm going to record the rest of the lab, I'm going to pause during the monkey part, and I'm going to record the rest of the lab tour so that anyone else who who is curious can see it then. So let me do that again. And then we'll go on to other questions. So, let me just pull up the slides. I almost have it, I think, this keynote presentation. Great, okay, I have it. All right, so I'm just going to pause the recording for the first part of the slides. And then I will resume it after the monkey part is over. Great. So this is the lab tour.

Oh, I need to share the audio. Let me just share my screen one more time. But with the audio shared. audio share. So this is a lab tour from from my PhD advisors lab at Stanford, and it starts off by showing the inside of the lab space. And so, let me sorry let me make sure I did pause the recording. Okay. Yeah, so, I'm here, what you see is a monkey named George, and George is currently sitting in an experimental rig where we're recording from neural data. And he's doing a reaching task. And so, you'll see that he has essentially an implant here. This is dental acrylic that sits on top of his skull.

We do that so that we could fix his head during the experiments, because we want, because essentially the experiment has to be very precisely calibrated the monkey centers to be in a particular position and we also put a juice tube into his mouth so that they receive a juice reward. And the monkey doesn't feel discomfort during this. His head is just fixed into a single location. Neuralink released a video last week where they actually did everything freely and wirelessly. And they had already trained the monkey to hold onto a juice tube, which essentially is the monkey holding his head still in a single area. And so they removed this whole implant part, which is remarkable.

There's actually a couple of CNN and another source that did a commentary on the video over the video that I watched as well as the video. Yeah. Did you watch a Professor Paul Nijikian's by any chance. No, this is getting some traction so I can send that to. He was my colleague during our we did our PhDs together and he goes into a lot of details. If you could send us the link. Thank you. Yeah, let me get that link right now. So that's a Paul new chickens at deconstruction of this. We zoom in on the monkey and this is all the hardware that record from the electrode array and then that sends it out to computers later on to be processed.

0:00:00
All right, everyone. We're going to get started for today. A few announcements. First, homework number four is, do this Friday uploaded to GreatScope. And you'll notice that on the homework, we've designated several questions to be optional. And so those are our questions that can be additional practice for you if you so desire. We are going to be setting up an announcement tonight with several midterm logistics, including the timing of the midterm and Zoom link for where the TA's and I will be in case you have questions about the midterm. And so all of that information is going to go out tonight and an announcement. There are a few things I want to state here in class, which is, I guess, people in different times zone will see this in the video. But if you're taking the midterm at a different time, I know that last week I wrote to send me an email. It turns out I should have provided more detail because it's become a bit haphazard with the emails.

0:01:08
And so here, let me add a bit more structure. Even if you've already emailed me, what I'm saying is, if you cannot take the exam during class time because you're in a different time zone, or if I have approved you to take the exam during a different time already, please send me a new email with the following. The email subject is going to be EC 102 underscore MT underscore reschedge. And that makes sure that I can search everyone and have everyone included. And then in the email, I need you to tell me what time zone you are in. And then the time that you cannot take the exam in specific standard time. If you don't provide this information, then I'm going to assume that any other time other than class time is going to be fine for you. And please send me this information by Friday so that we can reschedule all of these other exams. All right. And then this will be in the announcement that we sent out tonight, which is that Tonmoi is going to hold the midterm review session on Sunday.

0:02:07
And there's going to be a poll that we send out tonight that let's you indicate what times are, what times are available. And then from there, Tonmoi will select the time most students can make. All right. And then I just wanted to chat. Someone asked if this is a standard or daylight or standard time now. So we just had our change of time this past weekend. Okay. Any class announcement, logistic questions? All right. Great. So we're going to get back into material. So last lecture, we spent quite some time talking about the intuition of Fourier series and then also deriving the results of the Fourier series, which is that F of T. If it's a periodic signal with some period big T zero.

0:03:05
Then I can write F of T as a sum of complex exponentials. And last lecture, we converted as a sum of complex exponentials each weighted by some coefficient C k. Right. And so last lecture, we derived what these values C k are and how to find them. And we use this very cool proof where we use this trick where if you integrate and a complex exponential over a period, it equals zero. Except in the case when K equals when the complex exponential has a value of K equals where we're out here. So please review that proof if any of the steps were unclear. All right. So last lecture, we derived how to find these coefficients C k such that when you multiply each of the J k omega and R T, our complex exponentials, they add together to reproduce your periodic signal F of T. All right. So then we ended class last week by going over an example of a square wave where we took the square wave signal right here and we calculated its Fourier series coefficients.

0:04:19
And we derived that C k was equal to one half sink of K over two. All right. And so these C k are going to be these coefficients C k for the square wave. And what this means is that for this square wave, if I wanted to write the square wave as the sum of complex exponentials, then I could write the square wave, F of T, as being equal to the sum from K equals minus infinity to infinity of C k e to the negative J, that's right, e to the J k omega not T. And here again, C k is one half sink K over two. And so this equation, sum from K equals minus infinity to infinity, where C k is one half sink of K over two times this complex exponential e to the J k omega not T. All right. This expression here is going to be the sum of complex exponentials such that when they sum together with these coefficients, one half sink K over two, they add up to the square wave. And so then I showed you some simulations. I'm going to paste this.

0:05:44
So we said, okay, what happens when we only allow one complex exponential frequency? What that means is that we're doing this sum here, except we're doing K equals minus one to K equals one. Right. And so what I would have here is a K equals zero term. Right. The zero term would just be a sink of zero is one and an e to the zero is one. So the C zero term would equal one half and that's this this blue line over here. So C zero equals one half is this blue line. And then I'm going to have a complex exponential with C one times an e to the J omega not T. And so these are complex exponentials with frequency omega not. And here those complex exponentials actually give me this red sinusoid. Right. And so we see if we add our blue line and our red sinusoid together, we approximate the square wave, but not perfectly.

0:07:00
We have overshoot here at the extremities and then we have under shoot along the edges of this square wave. Right. But now if I go ahead and I let you have three complex exponentials of frequencies. So now I have a sum from K equals minus three to plus three of our C ke to the J K omega not T. Now with these additional frequencies, I can start to approximate even better. And as to add more and more complex exponential frequencies all the way up until here I'm showing you 100. You can see the sum of all of these signs and cosines are going to give me a fairly good approximation of the square wave. All right. Okay. So I want to pause and say any questions here. I know we went over this rather quickly at the end of last lecture.

0:07:56
In practice, is there a certain amount of complex exponentials that would be, I guess, quote, unquote, good enough to approximate a certain signal? Because we could never get an infinite amount which would perfectly approximate or perfectly simulate what a signal is. But would there be like a kind of like a certain amount that would approximate it close enough? Yeah, that's a great question. I am not aware, although it may exist and I just may not know it. So if the TAs know, please chime in. I am not aware of a general formula that tells you if you use K complex exponentials, how little your error is going to be. Like me is going to depend on several properties of the signals. For example, discontinuities make it harder to approximate. And so in general, I believe that the answer is a signal dependent. And so I am not aware of any general equation that will tell you how many times you need.

0:09:05
Okay. That makes sense. Thank you. All right. The TAs chime in if you know, if you know more than I do here. All right. Okay. So that's the square wave. Well, what I want to now ask is a question, which is you'll notice that even when we had 100 complex exponential frequencies and my sign waves added together approximate the square wave pretty well, you'll notice that at these discontinuities, they're not perfect. And if you zoom in a bit, you can see that there's a bit of ring. It might be clearer when we have 10 frequencies, which is that at these discontinuities, it seems to overshoot and then ring a bit. And that ringing, if you were to zoom in on this plot, is still visible.

0:09:58
Right. And so I'm going to tell you an answer, which is that even if I were to make this an infinite number of complex exponentials, we would still have this overshoot. It would not perfectly go away. And so this is odd because we did approve where we said that as long as CFK is equal to this expression, that F of t is equal to the sum of the ck times this complex exponentials. And in math equals has a very particular meaning. It means that this is going to the left and the right hand side are going to equal to the same value at every single point in time t. And yet we see that at particular points in time t, in particular these discontinuities, F of t and my square wave and the right hand side, my Fourier series expansion, they are not equal to each other. So this is a hard question, but I want you to think for maybe 20 to 30 seconds about why this might be the case. Why is it that the Fourier series expansion doesn't equal F of t at every time point t, even if we prove that to be the case?

All right, we're going to get started for today. So a few announcements. The first is a reminder that homework number two is do on Monday in five days on April 26th, uploaded to Gradescope by 1159 PM. And then last lecture, someone had asked about the phantom factor of the Pricot G. It's a thousand cerebellum. And from this paper by Brits and Sour Bray and colleagues in their on 2015, they reported that during locomotion, the Pricot G cells actually have a very variable firing rate. And so their phantom factor on the y-axis is variance and on the x-axis is mean. And so the phantom factor was one, then the data points would all lie along the line, meaning that the mean and the variance are always equal. You can see the dots are generally above the line. Each of these dots is one neuron. And so neurons generally have, for Pricot G, neurons, higher variance and higher spike count mean.

And so their phantom factor is indeed greater than one. All right. Okay, any questions on any course with just 64 we get back into material? All right. So our last lecture we defined the Poisson process and we defined it as a process where we had events given by the big T's and the events have exponential into our rival times or ISIs. All right. And so those are these little T's. These are all independent and identically distributed and the distribution is an exponential distribution with parameter lambda. All right. And then we said the Poisson process is that or this expression here, NS, what it does is it accepts the time S and then returns a number of spikes that happened up into, up into including that time.

So if S was here, then the number of spikes would be one. If S is here, the number of spikes would be three. All right. And then last lecture, we spent the majority of lecture proving the main property of the Poisson process, which is that the number of spikes at time S. And so this means the number of spikes going from zero to all the way up until time S in that window. Big N of S is going to be a Poisson distributed random variable with mean lambda times S. Again, S is the enough of time that we're looking at for spikes. All right. And what that means is that I know the exact probability to distribution over the number of spikes I'm going to observe in my window from zero to time S. And so I know the exact probability of observing zero spikes, one spike, two spike, et cetera. And that's computed from this expression right here. Right. Any questions here?

Okay. So lastly left off, we were on property two of the Poisson process. And this was the so-called restart property. And so the property formally said that N of T plus S minus N of S, right, which is the number of spikes that occur in a window between time S and time T plus S over here. The number of spikes in this window is a Poisson process or this end of T plus S minus N of S follows a Poisson process. The number of spikes in this window is going to be a Poisson random variable with lambda times the length of this window, which is little T, right. And it's going to be independent of N of R where R is before S. So the number of spikes that happen in this window and the Poisson process in this window is going to be entirely independent of what has happened all along in the past. We say independence, right. We should be thinking something is independent. For two things are independent.

If knowing one of them does not give you any additional information about the other one, but you didn't already know, right. So when we're saying that the Poisson process from zero to N R is independent of the Poisson process between S and T plus S, what we're saying is that for example, knowing the number of spikes that happen in this window tells me nothing about the number of spikes that are going to happen in my window between S and T plus S. And then we mentioned that we would give the intuition over this property and you're not going to be responsible for the rigorous proof, although we have it on the next page and I'll go through it at a high level. But to show that starting from NS and looking forward to show that we have a Poisson process, right, all we have to do is show that our definition of the Poisson process holds and our definition of the Poisson process is that it's going to be a process where events happen at IID into arrival times or IID, ISIs, each of the ISIs being drawn from an exponential lambda distribution. A question from Andrew.

So, thinking about property to from a biological standpoint, I'm confused how this makes sense because I can't mirror on spikes be affected by some biological processes, how much, how many new trends you have to continue firing after IIDs or listening to a song. If you listen to a chord, if you feel like the first note of a chord, you're expected to hear the second or stuff like memories. If you've experienced something to pass, can't you mirror on fire differently, things like that. So, I guess, come up biological point of view, how the restart property makes sense. That's a great question, Andrew. Yes, so, the restart property in general won't be true for a biological system. The restart property, which is think of as just true for this attraction, which is the Poisson process. And even though it isn't something that will be absolutely true for the biological system, still the approximate, just like, for example, that are inter spike intervals are not exponential, it's one of the modeling things that is a consequence of defining these exponential inter spike intervals that allow us to do math looking at any inter bobble Poisson process.

There are several things about it that are, there are several things about the Poisson process that are non biological, and we'll start to address each of these later on, or we'll talk about some of them. For example, for this Poisson process, we're even assuming a constant rate lambda, right, that the firing rates have a constant rate lambda, but we know the firing rates change through time. And so, that's another place where we will have to make some updates to the model. And so, we'll talk about, for example, in homogeneous Poisson processes later today. But at face level, you're correct that in general, for a biological system, knowing about what's happened in the past could give you additional information about what's going to happen in the future. Okay. Thanks, Andrew. All right. Any other questions here?

All right. So, to show that we have a Poisson process starting at time S, and we have a Poisson process starting at time S, and looking forward, right, all we have to show is that all of the events that happen after time S are IID exponentially distributed, interspinently, happen with IID exponentially distributed interspinally intervals. And we're mostly good because between T4 and T5, we know that this is exponential lambda, between T5 and T6, we know that it's going to have an exponential inter-arrival time. Actually what we don't know is if this first interval over here is this exponential, is this ISI between time S when I restarted my Poisson process, and the next spike event is this ISI exponential with parameter lambda. Because if it is, then every single ISI looking forward is exponential parameter lambda, and that defines a Poisson process. Right? So at the end of last lecture, we gave the intuition for why this is true, which has to do with the memoryless property of the exponential distribution.

That is, the last boss or the last spike came at T3, and I started waiting for my spike, my next spike at time S, or my next plus at time S. The amount of time I have to wait for in the future, the distribution of that is going to be the same as if I had not waited at all. And therefore, this inter-spike interval ends up being exponential, and if this is exponential and everything else is exponential then the line, then looking forward we have the Poisson process. All right. Any questions on the intuition there? All right. So let me just go through this slide at a high level. So at least you can read this slide, and if you're interested in understanding this proof rigorously, then this slide will give you that information. So at the top here, we just have this fact that we've been using last lecture that for an exponentially distributed random variable, the probability that big T is less than little T is each the minus lambda T.

Okay. Hi, Amina. Hello, how are you? Sorry? I said, hello, how are you? Oh, I'm good. How are you doing? Thank you. I just had a couple questions on the homework. Great.

Let me pull it up. All right, I have it up. So I was going through problem 4C, and I had set up the integral in the same way that you did in office hours, but I was looking through Tanmoy's notes after, and I don't think I get the same response. So like, I understand how he went through it, because he did the, he used the equation of the expected, expected value with the summation, and then turns it into an integral but when I try to solve for that with the bounds of being one over lambda to infinity. I get to over lambda is the correct answer. Oh, okay, then I guess I'm misinterpreting. Yeah, I can. I haven't seen Tom boy slides. With, did you say that that was for 40.

For, for, for C I mean sorry. Yeah, it says it on his notes. Okay, let me pull that up really quickly so that I can see what he said. It's the notes from... 4-20 or 4-18? It's the notes from April 20th. Okay. Oh, that's an E, not a C. Oh, sorry. I confused... Oh, yeah. Oh, okay, okay. Okay, that makes sense to me. Great. Yeah. Okay. And so actually for for E.

For you we have to switch to the person process right for you sorry, what is the expected number of spikes that will be fired before one season, ISI, greater than the mean ISI. So, so this one actually requires some thinking outside the box beyond the process. I had it set up as like the expectation of an of s, given, t is less than one over lambda big T is less than one over lambda. Is that what I'm trying to solve for Okay. One piece of greater. So, I believe if you go that route. You.

possible. The expected, you're calculating the expected number of spikes, given that the ISI is less than 1 over lambda. Yes. I believe that is, I believe that's an interesting way to go and I think that, are you able to calculate that expectation? So I didn't go through with it because I didn't even know if I was set up correctly, but that was like my English sense of it. Yeah, I think that at least getting that conditional distribution, that conditional distribution challenging, because you would have a P of NFS, given, T is less than something. And however you split it up, you would, you would have to compute either a probability of an NFS given T or probability of a T given NFS with very conditional probability.

Let me, let me tell you a simpler way to set it up. So, essentially, what you can do is you can consider this as essentially a coin flip. So, you flip a coin and either the spike that comes will have an ISI less than the mean ISI. And so, what you want to know, so let's say that tails is tails is when you see an ISI less than the mean ISI. So you want to know how many tails are going to flip before you get ahead. Does that make sense. Okay, yes. And we know the probability of tails and heads because we calculated it in earlier part, I believe. Probability of T greater than one over lambda, we calculated to be one over E. Yes.

So basically we have coin flips that occur with probability, the tails occurs with probability 1 minus 1 over e and the heads occurs with probability 1 over e. And so if you keep flipping this coin you want to know the expected number of coin flips before you get to the heads. And so this is something that is modeled by what is called the geometric distribution. And so for the geometric distribution, let me just pull up the page here. So in a metric distribution. We are computing the number of coin flips before we get one success. And so, in this case, one minus p. We would have k minus one of them for the success to be on the kid coin flip so the probability that takes cave coin flip to get the success would be this probability. Okay, so resolving for K, which is one over the probability of a success. So it's one over one over e, which is d. Okay, I didn't know where that where his distribution was coming from, but now I realize this geometric.

So, yeah, that's right. Yeah. Okay. And then For 3D, the one where we're modeling the neurons by 50 spikes per second. I just sort of did a calculated the area under the curve for the refractory period, using exponential I just wanted to make sure that that was sort of the correct intuition. that the random variable is less than 0.001. And then I'm just a little confused. I think I'm still a little confused about the concept of combining Poisson processes for part five. So when we're saying the probability that no neurons are detected on either electrode, Would I set that up as like the probability that that n, n one, and the probability that n two equals zero, like it would be a multiplication between the two Poisson processes.

That's what we have in the solution. Let me just read the question really quickly to make sure that we stated that they're independent so that you can do that. Yep. So, in question five it says each neuron spikes independently according to a homogeneous Poisson process. So when you. And a they say what's the probability that no neurons are detected on either electrode. And so that would be a probability that parentheses. And one of t equals zero, and then because they're independent then the and can reduce to just multiplying those two together. Okay, okay, and I was a little confused, so when we set up the Poisson distribution, right? Yeah. So the S represents the number of spikes, that's the unit? No, N represents the number of spikes, and then S represents time, but lambda times S gives you a mean number of spikes.

All right, everyone. We're going to get started. So this is ECE C143A, C243A, Neurostic No Processing. I am your instructor, Jonathan Cowell, and on behalf of RTA's Tonmoie and Shashank and myself, we're excited to be your teaching staff for this quarter as we delve into topics related to neural signal processing. And today we're going to unpack a bit about what that means. We're just going to start off lecture by going over a few quick Zoom guidelines. So if you're taking a class with me before, you know that I'm very happy to answer questions and try to clarify things and that I encourage you to ask questions. If you have a question, very likely another student has a question and it gives me an opportunity to re-explain something or clarify that. And so please ask questions by raising your hand. You won't be able to unmute yourself on your own, but if you raise your hand, I will see that and then be able to unmute you so that you can ask your question. In addition to this, you can ask questions in the chat. So I will not be monitoring the chat, but RTA's Tonmoie and Shashank, they are going to be monitoring the chat continuously. And so if you write questions there, then they'll be able to answer questions in the chat. And then lastly, everything that we do for lecture in terms of everything we present here, as well as the annotated notes, we are going to be uploading those to CSELE. And so if you're not able to view a lecture live, which we do encourage, the lectures you can watch post talk on CSELE as well.

And so like I just mentioned, all lectures, as well as at least one discussion section, and oh, sorry, all lectures, discussions, and office hours will be carried out on Zoom. Lectures and at least one discussion is going to be recorded and uploaded to CSELE. We encourage you to attend live lectures. But like I mentioned, we're going to be recording the live lecture for the people who aren't able to make it to the lecture on time. And so because of that, if you are uncomfortable being recorded in a lecture, these lectures will be recorded for the sake of the entire class. And we ask that you off that of not being recorded by not attending a live lecture. But if that's not a concern for you, again, we encourage you to attend the live lectures. All right. And if there's someone who feels they learn better through live Zoom lectures by having your camera on, I know that I welcomed that. It's a lot better for me than just looking at black boxes with names. All right. And so feel free to do so if you prefer that. All right. And then like I mentioned, during live lectures, we're happy to answer questions. So to do that, you can raise your virtual hand in which case I will ask you to unmute. And then we'll have you ask the question, then I'll answer that. And then the other way is through the chat functionality. And so if you write your question to chat, then Tuan Moai and Tishank will be able to answer questions over the chat. All right. Before we just started, any questions on just any Zoom setup? Reveited things? All right, then. So I wanted to start off this class by giving you a sense of what this class is all about. Because when we hear a title like neural signal processing, maybe we may know what some of those words mean in isolation, but what's they mean when you put them all together? And what is going to be Tuan in this class? All right. So we'll go over through the motivation of this class and essentially the high-level areas that we'll cover. Some high-level thoughts is that first, this class is essentially the brain-meat engineering. So how can we, as people come from electrical engineering, computer science, develop techniques to try to understand how the brain does computation as well as interface with the brain to support human health? The other thing is that I know this class is in elected, and so although there's going to be a bunch of work in this class and we're going to go over this syllabus by the end of class, it's my sincere hope that this class is also fine. And so we'll talk again about what we're going to do in this class, but in this class we'll be playing with neural data actually recorded from the brain and building algorithms to decode that neural data. All right.

And lastly, as I said before, please feel free to ask questions and we'll do our best to answer those. All right. So I thought about what the motivation for this class would be, and there's actually been some recent news that you may know of that provides a pretty good motivation for this class. And so last year a company called Neuralink, which is founded by Elon Musk, held essentially a conference of sorts where they demonstrated some new technology that they are developing to try to interface with the brain. And we'll talk about some of that technology throughout the class. It speaks to the fact that what was previously something that was more in the research domain and the domain of academics is starting to be something embraced by industry, where perhaps next generation of industry is looking towards how do we interface with the brain through new technologies? And how do we use that to both understand the brain and engineer with the brain, build devices that can be either driven by your brain or right into your brain. All right. And so a lot of this builds off of some subtle work beginning in the mid-2000s. And we're going to try to address this through, unpack this through answering this question, what is Neuralink's processing? So again, I mentioned to you earlier, you may know what some of these words mean in isolation. Neural refers to neurons, which are the basic computing elements in the brain, and which we'll talk about. And the first two and a half weeks of this class discuss the basic workings of neurons. Signal processing, you all likely know from one of the first EEClaces E102, where you did a Fourier, and you were able to learn techniques that essentially take signals and extract out features and information from the signals that are relevant to solving a particular application problem. All right. So I have shown here three images. The first is an image of actual neurons in the brain. And what we showed here on this long device here is an electrode. The same type of electrode that you would use to measure the voltage between two points on a circuit. And so here this electrode gets very close to a particular neuron in the brain. And we're going to learn in this class that neurons in the brain actually communicate via electrical principles. And so we'll talk about how neurons actually shuttle ions from outside to inside their cell, allowing the voltage across the neuron to change and how that encodes information. Because the signals transmitted by neurons are fundamentally electrical, we can transduce them into signals that then we can operate on via circuits. And so here we're showing a circuit board that can perform operations on neural signal voltages that we measure from the brain. And then taking those transduced voltages, we can apply them to solve engineering problems.

And so here I'm showing the cover of a seminal paper from 2006 in nature from the Hawkberg group at Massachusetts General Hospital and Brown University, where they had a paralyzed participant named Matt Nagel here. And what they did is they inserted these electrodes into his brain. And although Matt Nagel was paralyzed from the neck down after he suffered a paralysis in a knife injury, they were able to read signals from his brain emitted by these neurons and use that to drive and move artificial curses on the computer screen, essentially giving him control of a computer cursor. And so we'll talk about in this class some of the algorithms that are developed in the service of that. All right. So getting back to this question, what is neural signal processing? So we're going to take a bit of a tour of history right now and then we'll get back to this question. But for millennia, right, and people have sought to understand what gives rise to our ability to perceive the role that around us, to reason about it, and then to act. And these are qualities that make us uniquely human. And so for perception, this refers to the sensory inputs that we regularly receive throughout the day. One example, which I give now because it's something that we may experience later on in this lecture, is when we watch a video, like a video on YouTube, right? So when we watch a video on YouTube, we have visual information, which are the actual images within the video being streamed into our eyes. We also take in auditory information.

All right, everyone. We're going to get started for today. So a few announcements before we begin. I sent out a CCLE announcements with instructions on how to sign up for Piazza and grade scope. And so those are just recapituated here as well as a link to a Python tutorial. If you have only used MATLAB in the past, this tutorial will probably be helpful for you. And then we have also uploaded to CCLE material reading for this class, the lecture notes, and then we also uploaded all the midterms and final exams dating back to 2017. If you're someone who isn't sure if the pre, if you satisfied the prerequisite material, I encourage you to take a look at the midterms and final exams as well as the common filter dot pdf which are probably the most technically demanding for this class. Any questions on any announcement related matters? Any course logistics?

All right, so excuse me. We're going to go ahead and finish off the syllabus. So last time we talked about the grade breakdown for this class and that it was graded on an absolute scale. And I know I went through it a bit quickly at the end, so I just want to put up this slide to ask if there are any questions here on the grade breakdown for the grading scale. All right. So then we had also put up this information about pass no pass or satisfactory on satisfactory grading if you choose to take the class in that manner. We also talked about how for exams during remote learning, the exam are going to be open note open book and you can access your notes and CCLE on your computer, but it's going to be closed internet. And that the TAs and I we are going to perform some analysis on the answers given. And if we suspect anyone collaborating, which are not allowed to do for the exams, we request reserve the right to give a superseding oral exam. Right. And then also if you are in a different time zone, we can make accommodations for you to take the exam at a different time.

And so please send me an email this week if you plan on taking us off on this. We will we use that just to get a sense of how many accommodations we'll need to make and then we're going to send out more details closer to the exam date to handle those accommodations. Any any questions here? All right. I have to slide on academic integrity, which I give in all my classes. And it's my way of saying up front that I care a lot about academic integrity and that we all follow the principles of academic integrity and fairness and respect to our fellow classmates. And so I put up the slide to say that I take this very seriously. And if we catch any students of cheating or violating the principles of academic integrity, that I take that seriously. And I will follow up and report those cases to the dean of the students office. And we will follow their recommendation as they investigate the case and do what they do what they determine us to do. All right. So I just want to put that up front that again. If we if we catch you violating academic integrity, we will follow up on it and report their case to the dean of students. All right. Any questions here?

All right. So with that other course information throughout this class, we're going to cover a wide range of topics, including some intrusion neuroscience, which we'll do for these first two and a half weeks. And then after that, we're going to cover topics in modeling spikes. That's going to be drawn from this theoretical neuroscience textbook, as well as topics from machine learning and statistical signal processing, which we take from this Chris Bishop textbook. And because we didn't want to have students need to to purchase all three books, what we did was we took the excerpts of the chapters that we used for these books and we put those on CCLE. Right. So that material should all be on CCLE. Other notes for this class. So the last two notes that we use in class, I just asked that they not be publicly posted due to matters related to copyright. And so we'll be happy to distribute them in the annotated notes on CCLE. But we just asked that they remain within the class population. Like we said, last time a piazza should be used for almost all major class discussions. And of course, these office hours to get any other questions answered.

But we hope that the piazza form will be lively. And like I mentioned last time, we give bonuses based off of participation on piazza. And so even though you can consider anonymous to classmates, your posting is not anonymous to us. And we make that setting so that we can assign bonuses based off of how much you participate on piazza. And the TAs will be checking piazza also regularly to make sure that any questions that couldn't be answered by students can be answered by teaching staff. If you have a question that isn't appropriate for piazza and it's related to class material, I just asked that you email, Tonmoys, Shashank and I and me together. We do this so that no single TA gets overloaded because in prior classes, sometimes once TA is very responsive and then all the students learn to email that TA all the time and that TA becomes overburdened. And so we just asked that you send us any class related questions to all three of the teaching staff if you don't post it on piazza. And then of course, if you have any personal matters, please email me directly there. Any questions here? All right. Some last notes. I think we mentioned this last time.

It's time consuming to make the transition from that lab to Python. So please factor that into your work. I think it's worth it because Python is the de facto standard for machine learning and signal processing today. I also mentioned this last time this class according to student feedback is a lot of work. And so I want to state this upfront so that you can plan accordingly. We do try to have this class be very fun, but we cover a bunch of topics and test it understanding. So we have seven homework assignments and we're told that those assignments are somewhat time consuming. All right. Like the mentioned piazza should be the primary names of asking and getting questions answered. And we just talked about this on the last slide also so I won't review that again. Any questions here? All right. So with that. Sorry. It looks like I have that was not last notes. I have a few more slides. For those coming with a background in machine learning. I want to say that up front since we start off doing neuroscience and we do derive maximum likelihood solutions for classifiers and regression in this class, which is something that may have seen before.

You may feel the pace of the class is somewhat slow. And then we're going to keep the pace because a lot of people in the class don't have background in machine learning. And I want to make sure that everyone can learn and master the material. And so if you're coming in with the prior background in machine learning, just be aware that the class may feel a bit slower for you. And you can factor that into your decision as you decide what class is to take. And then I like we talked last time. I think we're going to take halfway through lecture because the lectures are fairly long here at UCLA. And in our discussion sections, which we're going to be run live by Tonloi and Shashank. First off, you can attend whatever discussion section you would like. And the TAs will also be recording at least one of the discussion sections to put it on CCLA. And then we have already sent out the P.O.T.S.ing page to send up information so this full of points should not be here. All right, a lot of logistics I just went through any questions on anything that I went through. Okay, so I just want to do brief introductions. So about me and sorry. This is not updated well. I did update the other parts of the slide, but I didn't update this introduction.

This is not my first year at UCLA. This is now my fourth year. And it's my seventh time teaching this class. And so I, I've taught it at Stanford twice with my PhD advisor there and previously taught at UCLA four times. This is a class related very closely to the research that my research group does. And so we care a lot about improving the performance of brain machine interfaces. And then other classes that teach at UCLA include ECU 102 in the fall quarter, so that signals and systems. And then in the winter quarter, I teach a class on neural networks and deep learning. And so with that, I'm going to pass it off to one of our TAs, Tom, why so Tom, why if you can go ahead and unmute yourself. Yeah. Hi, so hello everyone. So my name is Tom, I'm on tour. I will be one of your keys for this quarter. So this is my third time, Tying for this course on neural signal processing and my fifth time, Tying for Jonathan. All of my Tying experience at UCLA has been for Jonathan. I really like Tying for Jonathan and especially for this course. So this course is one of my favorite courses here at UCLA. I took this course first when it was offered for the first time and back in 2017. And I really enjoyed the course material. I also hope that you also enjoyed this course too. So I am a PhD student at UCLA working with Professor Rajudhary and my research in interest, primary lies in reinforcement learning and pattern, exception and dynamic networks. So that's all about me and I hope to have a very enjoyable quarter with all of you. Thank you very much. Great. Thank you, Tom Boyd. And then we have our second TA, Shishank, who won't be able to give an introduction today. We'll ask him to give an introduction on Monday. But this will be Shishank's first time Tying this class here at UCLA and he's of course taken this class before and done, absolutely. And so we'll leave Shishank's introduction for the start of next class on Monday.

